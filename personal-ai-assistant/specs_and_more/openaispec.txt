(Files content cropped to 300k characters, download full ingest to see more)
================================================
FILE: setup_project.sh
================================================
#!/bin/bash

# Personal AI Assistant - Project Setup Script
# This script creates the complete folder structure and initializes files

set -e  # Exit on any error

PROJECT_NAME="personal-ai-assistant"
echo "🚀 Setting up $PROJECT_NAME..."

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Create main project directory
echo -e "${BLUE}📁 Creating project structure...${NC}"
mkdir -p $PROJECT_NAME
cd $PROJECT_NAME

# Backend structure
echo -e "${YELLOW}📂 Creating backend structure...${NC}"
mkdir -p backend/{core,integrations,api,models,services,utils,tasks,tests}
mkdir -p backend/core/{claude_integration,trigger_engine,data_orchestrator}
mkdir -p backend/integrations/{clickup,claude_native}
mkdir -p backend/api/{routes,middleware}
mkdir -p backend/models/{database,schemas}
mkdir -p backend/tests/{unit,integration,fixtures}

# Frontend structure
echo -e "${YELLOW}📂 Creating frontend structure...${NC}"
mkdir -p frontend/src/{components,pages,hooks,services,utils,styles}
mkdir -p frontend/src/components/{common,chat,triggers,insights,integrations}
mkdir -p frontend/public

# Templates and static (for Flask)
mkdir -p templates static

# Infrastructure and docs
mkdir -p {scripts,docs,heroku}
mkdir -p docs/{deployment,architecture,user_guides}

# Create all __init__.py files
echo -e "${YELLOW}🐍 Creating Python package files...${NC}"
find backend -type d -exec touch {}/__init__.py \;

# Create core configuration files
echo -e "${BLUE}⚙️  Creating configuration files...${NC}"

# .env.example
cat > .env.example << 'EOF'
# Flask Configuration
SECRET_KEY=your-secret-key-here
FLASK_ENV=development
DATABASE_URL=postgresql://username:password@localhost/dbname

# Claude API
ANTHROPIC_API_KEY=your-claude-api-key-here

# Google OAuth (for token management)
GOOGLE_CLIENT_ID=your-google-client-id
GOOGLE_CLIENT_SECRET=your-google-client-secret

# ClickUp (optional)
CLICKUP_API_KEY=your-clickup-key-if-needed

# Heroku
PORT=5000
EOF

# requirements.txt
cat > requirements.txt << 'EOF'
# Web Framework
Flask==3.0.0
Flask-Session==0.5.0
Flask-SQLAlchemy==3.1.1
gunicorn==21.2.0

# Claude Integration  
anthropic==0.8.1
httpx==0.26.0

# Database
psycopg2-binary==2.9.9
SQLAlchemy==2.0.23
alembic==1.13.1

# Authentication (Google OAuth)
Flask-Dance==7.0.1
google-auth==2.25.2
google-auth-oauthlib==1.2.0
google-api-python-client==2.111.0

# Task Scheduling & Background Jobs
celery==5.3.0
redis==5.0.1
schedule==1.2.2

# Utilities
python-dotenv==1.0.0
PyYAML==6.0.1
requests==2.31.0
python-dateutil==2.8.2

# Development & Testing
pytest==8.0.2
pytest-flask==1.3.0
pytest-cov==4.1.0

# Production
Werkzeug==3.0.1
EOF

# Procfile for Heroku
cat > Procfile << 'EOF'
web: gunicorn backend.main:app --workers 1 --log-level info
worker: celery -A backend.tasks.celery_app worker --loglevel=info
EOF

# runtime.txt for Heroku
cat > runtime.txt << 'EOF'
python-3.11.6
EOF

# .gitignore
cat > .gitignore << 'EOF'
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Environment
.env
.venv
env/
venv/
ENV/

# IDE
.vscode/
.idea/
*.swp
*.swo

# OS
.DS_Store
Thumbs.db

# Logs
*.log
logs/

# Database
*.db
*.sqlite

# User data
user_data/
temp/

# Node modules (if you add frontend build)
node_modules/
npm-debug.log*

# Flask session
flask_session/

# Heroku
.heroku/
EOF

# Main backend entry point
cat > backend/main.py << 'EOF'
import os
from datetime import timedelta
from flask import Flask, session
from flask_dance.contrib.google import make_google_blueprint
from flask_session import Session
from werkzeug.middleware.proxy_fix import ProxyFix
import tempfile
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def create_app():
    app = Flask(__name__, 
               template_folder='../templates',
               static_folder='../static')
    
    # Configuration
    app.secret_key = os.getenv('SECRET_KEY', 'dev-key-change-in-production')
    app.config['PREFERRED_URL_SCHEME'] = 'https'
    app.config['SESSION_COOKIE_SECURE'] = os.getenv('FLASK_ENV') != 'development'
    app.config['SESSION_COOKIE_SAMESITE'] = 'Lax'
    app.config['SESSION_COOKIE_HTTPONLY'] = True
    app.config['PERMANENT_SESSION_LIFETIME'] = timedelta(days=1)
    app.config['SESSION_TYPE'] = 'filesystem'
    app.config['SESSION_FILE_DIR'] = os.path.join(tempfile.gettempdir(), 'flask_session')
    
    # Initialize extensions
    Session(app)
    app.wsgi_app = ProxyFix(app.wsgi_app, x_proto=1, x_host=1)
    
    # Google OAuth setup
    google_bp = make_google_blueprint(
        client_id=os.getenv('GOOGLE_CLIENT_ID'),
        client_secret=os.getenv('GOOGLE_CLIENT_SECRET'),
        scope=[
            "openid",
            "https://www.googleapis.com/auth/userinfo.email",
            "https://www.googleapis.com/auth/userinfo.profile",
            "https://www.googleapis.com/auth/calendar.readonly",
            "https://www.googleapis.com/auth/gmail.readonly"
        ],
        redirect_to='index'
    )
    app.register_blueprint(google_bp, url_prefix='/login')
    
    # Initialize core services
    from backend.core.claude_integration.claude_client import ClaudeClient
    claude_client = ClaudeClient(api_key=os.getenv('ANTHROPIC_API_KEY'))
    app.claude_client = claude_client
    
    # Register routes
    from backend.api.routes import register_routes
    register_routes(app)
    
    return app

app = create_app()

if __name__ == '__main__':
    port = int(os.getenv('PORT', 5000))
    debug = os.getenv('FLASK_ENV') == 'development'
    app.run(host='0.0.0.0', port=port, debug=debug)
EOF

# Configuration settings
cat > backend/config/settings.py << 'EOF'
import os
from datetime import timedelta

class Config:
    SECRET_KEY = os.getenv('SECRET_KEY', 'dev-key-change-in-production')
    DATABASE_URL = os.getenv('DATABASE_URL', 'sqlite:///app.db')
    
    # Session configuration
    SESSION_TYPE = 'filesystem'
    SESSION_PERMANENT = False
    PERMANENT_SESSION_LIFETIME = timedelta(days=1)
    
    # Claude API
    ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')
    
    # Google OAuth
    GOOGLE_CLIENT_ID = os.getenv('GOOGLE_CLIENT_ID')
    GOOGLE_CLIENT_SECRET = os.getenv('GOOGLE_CLIENT_SECRET')
    
    # User data directory
    USER_DATA_DIR = os.getenv('USER_DATA_DIR', 'user_data')

class DevelopmentConfig(Config):
    DEBUG = True
    FLASK_ENV = 'development'

class ProductionConfig(Config):
    DEBUG = False
    FLASK_ENV = 'production'
EOF

# Claude client (main integration)
cat > backend/core/claude_integration/claude_client.py << 'EOF'
import anthropic
from typing import Dict, List, Optional
import json
import os
from datetime import datetime

class ClaudeClient:
    def __init__(self, api_key: str):
        if not api_key:
            raise ValueError("ANTHROPIC_API_KEY is required")
        
        self.client = anthropic.Anthropic(api_key=api_key)
        self.conversation_history = {}  # Store by user_email
        self.max_history = 20  # Keep last 20 messages per user
    
    def send_message(self, user_email: str, message: str, context_data: Dict = None) -> str:
        """Send message to Claude with user context"""
        
        # Initialize conversation history for new users
        if user_email not in self.conversation_history:
            self.conversation_history[user_email] = []
        
        # Build system prompt with context
        system_prompt = self._build_system_prompt(user_email, context_data)
        
        # Add user message to history
        self.conversation_history[user_email].append({
            "role": "user", 
            "content": message
        })
        
        try:
            # Send to Claude
            response = self.client.messages.create(
                model="claude-3-sonnet-20240229",
                max_tokens=4000,
                system=system_prompt,
                messages=self.conversation_history[user_email]
            )
            
            assistant_response = response.content[0].text
            
            # Add response to history
            self.conversation_history[user_email].append({
                "role": "assistant",
                "content": assistant_response
            })
            
            # Trim history if too long
            if len(self.conversation_history[user_email]) > self.max_history:
                self.conversation_history[user_email] = self.conversation_history[user_email][-self.max_history:]
            
            return assistant_response
            
        except Exception as e:
            return f"Error: {str(e)}"
    
    def _build_system_prompt(self, user_email: str, context_data: Dict = None) -> str:
        """Build system prompt with user context"""
        
        prompt = f"""You are a personalized AI assistant for {user_email}.

You have access to their:
- Gmail (use your native Gmail integration when they ask about emails)
- Google Calendar (use your native Calendar integration for scheduling questions)
- ClickUp tasks and projects (provided in context below)

"""
        
        # Add current context data
        if context_data:
            if context_data.get('tasks_summary'):
                prompt += f"\nCURRENT TASKS FROM CLICKUP:\n{context_data['tasks_summary']}\n"
            
            if context_data.get('calendar_summary'):
                prompt += f"\nCALENDAR SUMMARY:\n{context_data['calendar_summary']}\n"
        
        prompt += """
When users ask about:
- Emails: Use your Gmail integration to check their actual emails
- Calendar/Schedule: Use your Calendar integration to check their actual events  
- Tasks/Projects: Use the ClickUp data provided in context above

Be conversational, helpful, and proactive in suggesting actions based on their data.
"""
        
        return prompt
    
    def clear_history(self, user_email: str):
        """Clear conversation history for a user"""
        if user_email in self.conversation_history:
            del self.conversation_history[user_email]
EOF

# Smart data fetcher
cat > backend/core/data_orchestrator/smart_fetcher.py << 'EOF'
import os
import json
from datetime import datetime
from typing import Dict, Any

class SmartDataFetcher:
    def __init__(self, user_data_dir: str):
        self.user_data_dir = user_data_dir
    
    def fetch_context_for_prompt(self, user_email: str, prompt: str) -> Dict[str, Any]:
        """Intelligently fetch only relevant data based on prompt analysis"""
        
        context = {}
        prompt_lower = prompt.lower()
        
        # Check if prompt needs task data
        task_keywords = ['task', 'todo', 'project', 'clickup', 'deadline', 'due', 'work', 'priority']
        if any(word in prompt_lower for word in task_keywords):
            context['tasks_summary'] = self._get_tasks_context(user_email)
        
        # Check if prompt needs calendar data (Claude will handle this natively)
        calendar_keywords = ['meeting', 'calendar', 'schedule', 'appointment', 'today', 'tomorrow', 'week']
        if any(word in prompt_lower for word in calendar_keywords):
            context['calendar_summary'] = "Calendar data will be accessed via Claude's native integration."
        
        return context
    
    def _get_tasks_context(self, user_email: str) -> str:
        """Get ClickUp tasks context from sync data"""
        try:
            sync_dir = os.path.join(self.user_data_dir, user_email, 'sync')
            tasks_file = os.path.join(sync_dir, 'clickup_summary.txt')
            
            if os.path.exists(tasks_file):
                with open(tasks_file, 'r') as f:
                    content = f.read()
                    return content if content.strip() else "No current task data available."
            
            return "No task data found. Please sync ClickUp in settings."
            
        except Exception as e:
            return f"Error loading tasks: {str(e)}"
EOF

# Route registration
cat > backend/api/routes/__init__.py << 'EOF'
from .main_routes import main_bp
from .chat_routes import chat_bp

def register_routes(app):
    """Register all route blueprints"""
    app.register_blueprint(main_bp)
    app.register_blueprint(chat_bp, url_prefix='/api')
EOF

# Main routes (your existing template routes)
cat > backend/api/routes/main_routes.py << 'EOF'
from flask import Blueprint, render_template, session, redirect, url_for
from flask_dance.contrib.google import google
from flask_dance.consumer import oauth_authorized
from flask_dance.contrib.google import make_google_blueprint

main_bp = Blueprint('main', __name__)

@main_bp.route('/')
def index():
    if 'user_email' not in session:
        return redirect(url_for('google.login'))
    
    return render_template('index.html', name=session.get('user_name'))

@main_bp.route('/settings')
def settings():
    if 'user_email' not in session:
        return redirect(url_for('google.login'))
    
    return render_template('settings.html', name=session.get('user_name'))

@main_bp.route('/logout')
def logout():
    session.clear()
    return redirect(url_for('main.index'))

# OAuth callback handler
@oauth_authorized.connect
def google_logged_in(blueprint, token):
    if not token:
        return False

    resp = blueprint.session.get('/oauth2/v2/userinfo')
    if not resp.ok:
        return False

    google_info = resp.json()
    
    # Store user info in session
    session.clear()
    session['user_email'] = google_info['email']
    session['user_name'] = google_info['name']
    session['google_id'] = google_info['id']
    session['google_token'] = token['access_token']
    session.permanent = True
    
    return False
EOF

# Chat routes
cat > backend/api/routes/chat_routes.py << 'EOF'
from flask import Blueprint, request, jsonify, session, current_app
from backend.core.data_orchestrator.smart_fetcher import SmartDataFetcher
import os

chat_bp = Blueprint('chat', __name__)

@chat_bp.route('/chat', methods=['POST'])
def chat():
    if 'user_email' not in session:
        return jsonify({'error': 'Not authenticated'}), 401
    
    user_email = session['user_email']
    message = request.json.get('message')
    
    if not message:
        return jsonify({'error': 'No message provided'}), 400
    
    try:
        # Get Claude client from app context
        claude_client = current_app.claude_client
        
        # Fetch relevant context based on prompt
        user_data_dir = os.getenv('USER_DATA_DIR', 'user_data')
        data_fetcher = SmartDataFetcher(user_data_dir)
        context = data_fetcher.fetch_context_for_prompt(user_email, message)
        
        # Send to Claude with context
        response = claude_client.send_message(user_email, message, context)
        
        return jsonify({'response': response})
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500
EOF

# Basic HTML template
cat > templates/base.html << 'EOF'
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{% block title %}Personal AI Assistant{% endblock %}</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background-color: #f5f5f5;
            color: #333;
            line-height: 1.6;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }
        .header {
            background-color: #fff;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            margin-bottom: 20px;
            display: flex;
            justify-content: space-between;
            align-items: center;
        }
        .btn {
            background-color: #007bff;
            color: white;
            border: none;
            padding: 8px 16px;
            border-radius: 4px;
            cursor: pointer;
            text-decoration: none;
            display: inline-block;
        }
        .btn:hover {
            background-color: #0056b3;
        }
        .btn-danger {
            background-color: #dc3545;
        }
        .btn-danger:hover {
            background-color: #c82333;
        }
    </style>
    {% block extra_styles %}{% endblock %}
</head>
<body>
    <div class="container">
        {% block content %}{% endblock %}
    </div>
    {% block scripts %}{% endblock %}
</body>
</html>
EOF

# Main chat template
cat > templates/index.html << 'EOF'
{% extends "base.html" %}
{% block title %}Chat - Personal AI Assistant{% endblock %}

{% block extra_styles %}
<style>
    .chat-container {
        background-color: #fff;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        height: 600px;
        display: flex;
        flex-direction: column;
    }
    .messages {
        flex: 1;
        overflow-y: auto;
        padding: 20px;
        display: flex;
        flex-direction: column;
        gap: 10px;
    }
    .message {
        padding: 12px 16px;
        border-radius: 12px;
        max-width: 70%;
        word-wrap: break-word;
    }
    .message.user {
        background-color: #007bff;
        color: white;
        align-self: flex-end;
    }
    .message.assistant {
        background-color: #f1f3f5;
        color: #333;
        align-self: flex-start;
    }
    .input-container {
        padding: 20px;
        border-top: 1px solid #eee;
        display: flex;
        gap: 10px;
    }
    #messageInput {
        flex: 1;
        padding: 12px;
        border: 1px solid #ddd;
        border-radius: 4px;
        font-size: 16px;
    }
    #sendButton {
        background-color: #007bff;
        color: white;
        border: none;
        padding: 12px 24px;
        border-radius: 4px;
        cursor: pointer;
        font-size: 16px;
    }
    #sendButton:hover:not(:disabled) {
        background-color: #0056b3;
    }
    #sendButton:disabled {
        opacity: 0.6;
        cursor: not-allowed;
    }
</style>
{% endblock %}

{% block content %}
<div class="header">
    <h1>Hi {{ name }}! Chat with Claude</h1>
    <div>
        <a href="{{ url_for('main.settings') }}" class="btn">Settings</a>
        <a href="{{ url_for('main.logout') }}" class="btn btn-danger">Logout</a>
    </div>
</div>

<div class="chat-container">
    <div id="messages" class="messages">
        <div class="message assistant">
            Hello! I'm Claude, your personalized AI assistant. I have access to your Gmail, Calendar, and ClickUp data. How can I help you today?
        </div>
    </div>
    
    <div class="input-container">
        <input type="text" id="messageInput" placeholder="Type your message..." autofocus>
        <button id="sendButton">Send</button>
    </div>
</div>

<script>
    const messagesDiv = document.getElementById('messages');
    const messageInput = document.getElementById('messageInput');
    const sendButton = document.getElementById('sendButton');
    
    function addMessage(content, isUser) {
        const messageDiv = document.createElement('div');
        messageDiv.className = `message ${isUser ? 'user' : 'assistant'}`;
        messageDiv.textContent = content;
        messagesDiv.appendChild(messageDiv);
        messagesDiv.scrollTop = messagesDiv.scrollHeight;
    }
    
    async function sendMessage() {
        const message = messageInput.value.trim();
        if (!message) return;
        
        addMessage(message, true);
        messageInput.value = '';
        messageInput.disabled = true;
        sendButton.disabled = true;
        
        try {
            const response = await fetch('/api/chat', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({ message: message })
            });
            
            const data = await response.json();
            
            if (response.ok) {
                addMessage(data.response, false);
            } else {
                addMessage(`Error: ${data.error}`, false);
            }
        } catch (error) {
            addMessage(`Error: ${error.message}`, false);
        } finally {
            messageInput.disabled = false;
            sendButton.disabled = false;
            messageInput.focus();
        }
    }
    
    sendButton.addEventListener('click', sendMessage);
    messageInput.addEventListener('keypress', (e) => {
        if (e.key === 'Enter') {
            e.preventDefault();
            sendMessage();
        }
    });
</script>
{% endblock %}
EOF

# Settings template placeholder
cat > templates/settings.html << 'EOF'
{% extends "base.html" %}
{% block title %}Settings - Personal AI Assistant{% endblock %}

{% block content %}
<div class="header">
    <h1>Settings</h1>
    <div>
        <a href="{{ url_for('main.index') }}" class="btn">Back to Chat</a>
        <a href="{{ url_for('main.logout') }}" class="btn btn-danger">Logout</a>
    </div>
</div>

<div style="background: white; padding: 30px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
    <h2>Integrations</h2>
    <p>Settings page - will be enhanced with ClickUp integration, trigger management, etc.</p>
    <p><strong>User:</strong> {{ name }}</p>
</div>
{% endblock %}
EOF

# Setup script for easy startup
cat > scripts/setup.sh << 'EOF'
#!/bin/bash

echo "🚀 Setting up Personal AI Assistant..."

# Create virtual environment
echo "📦 Creating virtual environment..."
python -m venv venv

# Activate virtual environment
echo "🔌 Activating virtual environment..."
if [[ "$OSTYPE" == "msys" || "$OSTYPE" == "win32" ]]; then
    source venv/Scripts/activate
else
    source venv/bin/activate
fi

# Install dependencies
echo "📚 Installing dependencies..."
pip install --upgrade pip
pip install -r requirements.txt

# Create .env from example
if [ ! -f .env ]; then
    echo "📝 Creating .env file..."
    cp .env.example .env
    echo "⚠️  Please edit .env file with your API keys!"
fi

# Create user data directory
mkdir -p user_data

echo "✅ Setup complete!"
echo ""
echo "Next steps:"
echo "1. Edit .env file with your API keys"
echo "2. Run: python backend/main.py"
echo "3. Visit: http://localhost:5000"
EOF

chmod +x scripts/setup.sh

# Run script
cat > scripts/run.sh << 'EOF'
#!/bin/bash

# Activate virtual environment
if [[ "$OSTYPE" == "msys" || "$OSTYPE" == "win32" ]]; then
    source venv/Scripts/activate
else
    source venv/bin/activate
fi

# Run the application
python backend/main.py
EOF

chmod +x scripts/run.sh

# README
cat > README.md << 'EOF'
# Personal AI Assistant

A Claude-powered personal assistant that integrates with your Gmail, Calendar, and ClickUp to provide intelligent insights and task management.

## Features

- 💬 **Chat with Claude**: Natural conversation with access to your data
- 📧 **Gmail Integration**: Claude can read and analyze your emails
- 📅 **Calendar Integration**: Schedule analysis and meeting insights  
- ✅ **ClickUp Integration**: Task management and project tracking
- 🔄 **Smart Data Fetching**: Only loads relevant data based on your prompts
- 📱 **Proactive Triggers**: Save prompts to run automatically

## Quick Start

1. **Run the setup script:**
   ```bash
   ./scripts/setup.sh
   ```

2. **Configure your API keys in `.env`:**
   ```bash
   ANTHROPIC_API_KEY=your-claude-api-key
   GOOGLE_CLIENT_ID=your-google-client-id
   GOOGLE_CLIENT_SECRET=your-google-client-secret
   ```

3. **Run the application:**
   ```bash
   ./scripts/run.sh
   ```

4. **Visit http://localhost:5000**

## Architecture

- **Backend**: Flask + Claude API
- **Frontend**: HTML/CSS/JavaScript
- **Database**: PostgreSQL (SQLite for development)
- **Deployment**: Heroku-ready

## Development

The project follows a modular architecture:

- `backend/core/claude_integration/` - Claude API client
- `backend/core/data_orchestrator/` - Smart data fetching
- `backend/integrations/` - External service integrations
- `backend/api/routes/` - API endpoints
- `templates/` - HTML templates

## Deployment

Ready for Heroku deployment with included `Procfile` and configuration.
EOF

echo -e "${GREEN}✅ Project setup complete!${NC}"
echo ""
echo -e "${BLUE}📁 Created project structure:${NC}"
tree -L 3 $PROJECT_NAME 2>/dev/null || find $PROJECT_NAME -type d | head -20

echo ""
echo -e "${YELLOW}🚀 Next steps:${NC}"
echo "1. cd $PROJECT_NAME"
echo "2. ./scripts/setup.sh"
echo "3. Edit .env file with your API keys"
echo "4. ./scripts/run.sh"
echo ""
echo -e "${GREEN}🎉 Happy coding!${NC}"



================================================
FILE: personal-ai-assistant/cookies.txt
================================================
# Netscape HTTP Cookie File
# https://curl.se/docs/http-cookies.html
# This file was generated by libcurl! Edit at your own risk.

#HttpOnly_127.0.0.1	FALSE	/	FALSE	1749337646	session	f8a80a97-23e2-4729-9a2c-bf7416b5e16f



================================================
FILE: personal-ai-assistant/debug_gmail_oauth.py
================================================
#!/usr/bin/env python3
"""
Debug script for Gmail OAuth issues
"""

import os
import sys
import json
import requests
from datetime import datetime
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Add the backend directory to the Python path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

print("=== Gmail OAuth Debug Tool ===\n")

def check_token_validity(access_token):
    """Check if an access token is valid by calling Google's tokeninfo endpoint"""
    if not access_token:
        return False, "No access token provided"
    
    try:
        response = requests.get(
            f'https://oauth2.googleapis.com/tokeninfo?access_token={access_token}'
        )
        
        if response.status_code == 200:
            token_info = response.json()
            
            # Check expiry
            expires_in = token_info.get('expires_in', 0)
            if expires_in <= 0:
                return False, "Token is expired"
            
            # Check scopes
            scope = token_info.get('scope', '')
            if 'gmail.readonly' not in scope:
                return False, f"Gmail scope not found. Current scopes: {scope}"
            
            return True, f"Token valid for {expires_in} seconds. Scopes: {scope}"
        else:
            return False, f"Token validation failed: {response.status_code} - {response.text}"
    except Exception as e:
        return False, f"Error checking token: {str(e)}"

def test_gmail_api_direct(access_token):
    """Test Gmail API directly with a simple request"""
    if not access_token:
        return False, "No access token provided"
    
    try:
        headers = {'Authorization': f'Bearer {access_token}'}
        response = requests.get(
            'https://gmail.googleapis.com/gmail/v1/users/me/profile',
            headers=headers
        )
        
        if response.status_code == 200:
            profile = response.json()
            return True, f"Connected to Gmail for: {profile.get('emailAddress', 'Unknown')}"
        else:
            return False, f"Gmail API error: {response.status_code} - {response.text}"
    except Exception as e:
        return False, f"Error calling Gmail API: {str(e)}"

def main():
    # Check if we have an access token stored somewhere
    print("1. Checking for stored access token...")
    
    # Try to read from a test file if it exists
    test_token_file = 'test_token.txt'
    access_token = None
    
    if os.path.exists(test_token_file):
        with open(test_token_file, 'r') as f:
            access_token = f.read().strip()
        print(f"   Found token in {test_token_file}")
    else:
        print(f"   No {test_token_file} found")
        print(f"   To test with a token, save it to {test_token_file}")
    
    if access_token:
        print("\n2. Validating access token...")
        valid, message = check_token_validity(access_token)
        if valid:
            print(f"   ✓ {message}")
        else:
            print(f"   ✗ {message}")
        
        print("\n3. Testing Gmail API directly...")
        success, message = test_gmail_api_direct(access_token)
        if success:
            print(f"   ✓ {message}")
        else:
            print(f"   ✗ {message}")
    
    print("\n=== OAuth Flow Debug Info ===")
    print("\n1. Google Cloud Console Checklist:")
    print("   [ ] Gmail API is enabled")
    print("   [ ] OAuth consent screen is configured")
    print("   [ ] Authorized redirect URIs include:")
    print("       - http://127.0.0.1:8080/login/google/authorized")
    print("       - http://localhost:8080/login/google/authorized")
    print("   [ ] Test users are added (if app is in testing mode)")
    
    print("\n2. Required OAuth Scopes:")
    print("   - openid")
    print("   - email")
    print("   - profile")
    print("   - https://www.googleapis.com/auth/gmail.readonly")
    
    print("\n3. Common Token Issues:")
    print("   - Token expired: Re-authenticate by logging out and in")
    print("   - Missing scopes: User didn't consent to Gmail access")
    print("   - Invalid grant: Token was revoked or is corrupted")
    
    print("\n4. Testing the Full Flow:")
    print("   a. Clear browser cookies for localhost:8080")
    print("   b. Run: python3 backend/main.py")
    print("   c. Visit: http://127.0.0.1:8080/logout (to clear session)")
    print("   d. Visit: http://127.0.0.1:8080/login")
    print("   e. Complete OAuth flow and check for Gmail consent")
    print("   f. Check browser console for errors")
    print("   g. Try syncing emails from Settings page")
    
    print("\n5. Enable Debug Logging:")
    print("   export FLASK_ENV=development")
    print("   export FLASK_DEBUG=1")
    
    print("\n6. Manual Token Test:")
    print("   After logging in, you can extract the token from the Flask session")
    print("   and save it to test_token.txt to run this debug script")

if __name__ == "__main__":
    main() 


================================================
FILE: personal-ai-assistant/debug_insights.py
================================================
#!/usr/bin/env python3
"""
Debug script to check email insights after sync
"""

import os
import sys
import json
import time
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Add the backend directory to the Python path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

print("=== Email Insights Debug Tool ===\n")

# Import Flask app
from backend.main import create_app, sync_status

app = create_app()

print("1. Checking sync_status global variable:")
print(f"   - is_syncing: {sync_status.get('is_syncing', 'Not set')}")
print(f"   - progress: {sync_status.get('progress', 'Not set')}")
print(f"   - user_email: {sync_status.get('user_email', 'Not set')}")
print(f"   - last_sync: {sync_status.get('last_sync', 'Not set')}")
print(f"   - Has email_insights: {'email_insights' in sync_status}")

if 'email_insights' in sync_status:
    insights = sync_status['email_insights']
    print("\n2. Email insights content:")
    print(f"   - Type: {type(insights)}")
    print(f"   - Keys: {list(insights.keys()) if isinstance(insights, dict) else 'Not a dict'}")
    
    if isinstance(insights, dict):
        print(f"   - Status: {insights.get('status', 'No status')}")
        print(f"   - Message: {insights.get('message', 'No message')}")
        print(f"   - Key relationships: {len(insights.get('key_relationships', []))}")
        print(f"   - Active projects: {len(insights.get('active_projects', []))}")
        print(f"   - Action items: {len(insights.get('action_items', []))}")
        print(f"   - Important info: {len(insights.get('important_information', []))}")
        
        # Show sample data if available
        if insights.get('key_relationships'):
            print("\n   Sample key relationship:")
            print(f"   {json.dumps(insights['key_relationships'][0], indent=4)}")

print("\n3. Checking session storage:")
print(f"   - Session directory: {app.config.get('SESSION_FILE_DIR', 'Not set')}")

session_dir = app.config.get('SESSION_FILE_DIR')
if session_dir and os.path.exists(session_dir):
    files = os.listdir(session_dir)
    print(f"   - Session files: {len(files)}")
    
    # Check the most recent session file
    if files:
        latest_file = max([os.path.join(session_dir, f) for f in files], key=os.path.getmtime)
        print(f"   - Latest session: {os.path.basename(latest_file)}")
        print(f"   - Modified: {time.ctime(os.path.getmtime(latest_file))}")

print("\n4. Testing email intelligence module:")
try:
    from backend.core.claude_integration.email_intelligence import EmailIntelligence
    from anthropic import Anthropic
    
    claude_client = Anthropic(api_key=os.environ.get('ANTHROPIC_API_KEY'))
    email_intelligence = EmailIntelligence(claude_client)
    print("   ✓ EmailIntelligence module loaded successfully")
    
    # Check if the module has the right methods
    methods = ['analyze_recent_emails', '_create_relationships_prompt', '_create_patterns_prompt']
    for method in methods:
        if hasattr(email_intelligence, method):
            print(f"   ✓ Method '{method}' exists")
        else:
            print(f"   ✗ Method '{method}' missing")
            
except Exception as e:
    print(f"   ✗ Error loading EmailIntelligence: {str(e)}")

print("\n5. Recommendations:")
print("   - Make sure you're logged in with Gmail OAuth")
print("   - Click 'Sync Emails' in Settings")
print("   - Wait for sync to complete (check progress)")
print("   - Then visit /email-insights")
print("   - Check browser console for JavaScript errors")
print("   - Check Flask logs for server errors") 


================================================
FILE: personal-ai-assistant/debug_live_insights.py
================================================
#!/usr/bin/env python3
"""
Debug script to check live insights data
"""

import sys
sys.path.append('.')

from backend.main import sync_status
import json

print("=== Live Sync Status ===")
print(f"is_syncing: {sync_status.get('is_syncing')}")
print(f"progress: {sync_status.get('progress')}")
print(f"user_email: {sync_status.get('user_email')}")
print(f"last_sync: {sync_status.get('last_sync')}")

if 'email_insights' in sync_status:
    insights = sync_status['email_insights']
    print("\n=== Email Insights ===")
    print(f"Status: {insights.get('status')}")
    print(f"Message: {insights.get('message', 'No message')}")
    
    # Check each category
    for category in ['key_relationships', 'active_projects', 'action_items', 'important_information']:
        if category in insights:
            items = insights[category]
            print(f"\n{category}: {len(items)} items")
            if items and len(items) > 0:
                print(f"First item: {json.dumps(items[0], indent=2)}")
else:
    print("\nNo email_insights in sync_status!")

# Also check if the insights have the right structure
if 'email_insights' in sync_status:
    insights = sync_status['email_insights']
    print("\n=== Insights Structure ===")
    print("Keys:", list(insights.keys())) 


================================================
FILE: personal-ai-assistant/manual_sync_test.py
================================================
#!/usr/bin/env python3
"""
Manual sync test to debug email insights
"""

import os
import sys
from dotenv import load_dotenv
load_dotenv()

# Add the backend directory to the Python path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

print("=== Manual Email Sync Test ===\n")

# Check environment
print("1. Checking environment...")
if not os.environ.get('ANTHROPIC_API_KEY'):
    print("❌ ANTHROPIC_API_KEY not set!")
    exit(1)
else:
    print("✅ ANTHROPIC_API_KEY is set")

# Import modules
print("\n2. Importing modules...")
try:
    from anthropic import Anthropic
    from backend.core.claude_integration.email_intelligence import EmailIntelligence
    print("✅ Modules imported successfully")
except Exception as e:
    print(f"❌ Import error: {e}")
    exit(1)

# Initialize Claude
print("\n3. Initializing Claude client...")
claude_client = Anthropic(api_key=os.environ.get('ANTHROPIC_API_KEY'))
email_intelligence = EmailIntelligence(claude_client)

# Get user input
print("\n4. Enter your Gmail access token (from browser session):")
print("   You can find this by:")
print("   - Open browser DevTools (F12)")
print("   - Go to Application > Cookies")
print("   - Look for session cookie and decode it")
print("   OR just press Enter to skip this test")
access_token = input("Access token: ").strip()

if not access_token:
    print("\nSkipping live test. Would need access token from active session.")
    print("\nTo properly test:")
    print("1. Login to the app")
    print("2. Click 'Sync Emails' in Settings")
    print("3. Watch the Flask terminal for detailed logs")
    print("4. Visit http://127.0.0.1:8080/test-insights to see raw data")
else:
    print("\n5. Testing email analysis...")
    user_email = input("Your email address: ")
    
    try:
        insights = email_intelligence.analyze_recent_emails(user_email, access_token, days_back=7)
        
        print("\n=== Results ===")
        print(f"Status: {insights.get('status')}")
        print(f"Message: {insights.get('message')}")
        print(f"\nKey Relationships: {len(insights.get('key_relationships', []))}")
        if insights.get('key_relationships'):
            print(f"  First: {insights['key_relationships'][0]}")
        
        print(f"\nActive Projects: {len(insights.get('active_projects', []))}")
        if insights.get('active_projects'):
            print(f"  First: {insights['active_projects'][0]}")
            
        print(f"\nAction Items: {len(insights.get('action_items', []))}")
        if insights.get('action_items'):
            print(f"  First: {insights['action_items'][0]}")
            
    except Exception as e:
        print(f"\n❌ Error during analysis: {e}")
        import traceback
        traceback.print_exc() 


================================================
FILE: personal-ai-assistant/Procfile
================================================
web: gunicorn backend.main:app --workers 1 --log-level info
worker: celery -A backend.tasks.celery_app worker --loglevel=info



================================================
FILE: personal-ai-assistant/requirements.txt
================================================
# Web Framework
Flask==3.0.0
Flask-Session==0.5.0
Flask-SQLAlchemy==3.1.1
gunicorn==21.2.0

# Claude Integration (Updated)
anthropic==0.52.1
httpx==0.26.0

# Database
psycopg2-binary==2.9.9
SQLAlchemy==2.0.23

# Authentication
Flask-Dance==7.0.1
google-auth==2.25.2
google-auth-oauthlib==1.2.0
google-api-python-client==2.111.0

# Utilities
python-dotenv==1.0.0
PyYAML==6.0.1
requests==2.31.0
python-dateutil==2.8.2

# Development
pytest==8.0.2
pytest-flask==1.3.0



================================================
FILE: personal-ai-assistant/requirements_new.txt
================================================
alembic==1.13.1
amqp==5.3.1
annotated-types==0.7.0
anthropic==0.52.1
anyio==4.9.0
billiard==4.2.1
blinker==1.9.0
cachelib==0.13.0
cachetools==5.5.2
celery==5.3.0
certifi==2025.4.26
charset-normalizer==3.4.2
click==8.2.1
click-didyoumean==0.3.1
click-plugins==1.1.1
click-repl==0.3.0
coverage==7.8.2
distro==1.9.0
filelock==3.18.0
Flask==3.0.0
Flask-Dance==7.0.1
Flask-Session==0.5.0
Flask-SQLAlchemy==3.1.1
fsspec==2025.5.1
google-api-core==2.25.0rc1
google-api-python-client==2.111.0
google-auth==2.25.2
google-auth-httplib2==0.2.0
google-auth-oauthlib==1.2.0
googleapis-common-protos==1.70.0
gunicorn==21.2.0
h11==0.16.0
hf-xet==1.1.2
httpcore==1.0.9
httplib2==0.22.0
httpx==0.26.0
huggingface-hub==0.32.3
idna==3.10
iniconfig==2.1.0
itsdangerous==2.2.0
Jinja2==3.1.6
jiter==0.10.0
kombu==5.5.3
Mako==1.3.10
MarkupSafe==3.0.2
oauthlib==3.2.2
packaging==25.0
pluggy==1.6.0
prompt_toolkit==3.0.51
proto-plus==1.26.1
protobuf==6.31.1
psycopg2-binary==2.9.9
pyasn1==0.6.1
pyasn1_modules==0.4.2
pydantic==2.11.5
pydantic_core==2.33.2
pyparsing==3.2.3
pytest==8.0.2
pytest-cov==4.1.0
pytest-flask==1.3.0
python-dateutil==2.8.2
python-dotenv==1.0.0
PyYAML==6.0.1
redis==5.0.1
requests==2.31.0
requests-oauthlib==2.0.0
rsa==4.9.1
schedule==1.2.2
six==1.17.0
sniffio==1.3.1
SQLAlchemy==2.0.23
tokenizers==0.21.1
tqdm==4.67.1
typing-inspection==0.4.1
typing_extensions==4.13.2
tzdata==2025.2
uritemplate==4.1.1
urllib3==2.4.0
URLObject==2.4.3
vine==5.1.0
wcwidth==0.2.13
Werkzeug==3.0.1



================================================
FILE: personal-ai-assistant/runtime.txt
================================================
python-3.11.6



================================================
FILE: personal-ai-assistant/test_email_sync.py
================================================
#!/usr/bin/env python3
"""
Test script to verify email sync is working correctly
"""

import requests
import time
import json

BASE_URL = "http://127.0.0.1:8080"

print("=== Email Sync Test ===\n")

print("This test assumes:")
print("1. Flask app is running at http://127.0.0.1:8080")
print("2. You are logged in with Gmail")
print("3. Gmail API is enabled in Google Cloud Console")
print("")

print("Steps to test email sync:")
print("\n1. Make sure the Flask app is running:")
print("   python3 backend/main.py")

print("\n2. Login with Gmail:")
print("   - Visit http://127.0.0.1:8080/login")
print("   - Complete OAuth flow")
print("   - Grant Gmail read permissions")

print("\n3. Start email sync:")
print("   - Visit http://127.0.0.1:8080/settings")
print("   - Click 'Sync Emails'")
print("   - Wait for sync to complete")

print("\n4. View insights:")
print("   - Visit http://127.0.0.1:8080/email-insights")

print("\n=== Common Issues ===")
print("\n1. No insights showing after sync:")
print("   - Check browser console for errors (F12)")
print("   - Check Flask app logs for errors")
print("   - Verify you have emails in the specified date range")

print("\n2. Token expired error:")
print("   - Logout and login again")
print("   - Make sure to grant Gmail permissions")

print("\n3. Gmail API not enabled:")
print("   - Go to Google Cloud Console")
print("   - Enable Gmail API for your project")
print("   - Add your email as a test user if app is in testing mode")

print("\n4. No emails found:")
print("   - Check Settings page for 'Days back' parameter")
print("   - Default is 30 days - increase if needed")

print("\n=== Manual API Test ===")
print("You can test the API directly after logging in:")
print("")
print("# Check sync status:")
print("curl http://127.0.0.1:8080/api/sync-status")
print("")
print("# Get email insights:")
print("curl http://127.0.0.1:8080/api/email-insights") 


================================================
FILE: personal-ai-assistant/test_gmail_integration.py
================================================
#!/usr/bin/env python3
"""
Test script for diagnosing Gmail integration issues
"""

import os
import sys
import json
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Add the backend directory to the Python path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

print("=== Gmail Integration Test ===\n")

# Test 1: Check environment variables
print("1. Checking environment variables...")
required_vars = ['ANTHROPIC_API_KEY', 'GOOGLE_CLIENT_ID', 'GOOGLE_CLIENT_SECRET']
for var in required_vars:
    value = os.environ.get(var)
    if value:
        print(f"   ✓ {var} is set (length: {len(value)})")
    else:
        print(f"   ✗ {var} is NOT set")

# Test 2: Test Claude client
print("\n2. Testing Claude client initialization...")
try:
    from anthropic import Anthropic
    claude_client = Anthropic(api_key=os.environ.get('ANTHROPIC_API_KEY'))
    print("   ✓ Claude client initialized successfully")
    
    # Try a simple test message
    try:
        response = claude_client.messages.create(
            model="claude-3-opus-20240229",
            max_tokens=100,
            messages=[{"role": "user", "content": "Say 'test successful' if you can read this."}]
        )
        print(f"   ✓ Claude test response: {response.content[0].text}")
    except Exception as e:
        print(f"   ✗ Claude test failed: {str(e)}")
except Exception as e:
    print(f"   ✗ Failed to initialize Claude client: {str(e)}")

# Test 3: Test Gmail connector
print("\n3. Testing Gmail connector...")
try:
    from backend.integrations.gmail.gmail_connector import GmailConnector
    print("   ✓ GmailConnector imported successfully")
except Exception as e:
    print(f"   ✗ Failed to import GmailConnector: {str(e)}")

# Test 4: Test Email Intelligence module
print("\n4. Testing Email Intelligence module...")
try:
    from backend.core.claude_integration.email_intelligence import EmailIntelligence
    print("   ✓ EmailIntelligence imported successfully")
    
    # Initialize with Claude client
    if 'claude_client' in locals():
        email_intelligence = EmailIntelligence(claude_client)
        print("   ✓ EmailIntelligence initialized successfully")
except Exception as e:
    print(f"   ✗ Failed to import/initialize EmailIntelligence: {str(e)}")

# Test 5: Manual Gmail API test
print("\n5. Testing manual Gmail API connection...")
print("   To test Gmail API:")
print("   1. Run the Flask app: python3 backend/main.py")
print("   2. Go to http://127.0.0.1:8080/login")
print("   3. Complete OAuth flow")
print("   4. Check Settings page for connection status")
print("   5. Try syncing emails")

# Test 6: Common issues and solutions
print("\n=== Common Issues and Solutions ===")
print("\n1. 'OAuth token issue detected' error:")
print("   - Token may be expired. Try logging out and logging in again.")
print("   - Check that the OAuth scope includes: https://www.googleapis.com/auth/gmail.readonly")

print("\n2. 'Gmail API access not properly configured' error:")
print("   - Enable Gmail API in Google Cloud Console")
print("   - Ensure OAuth consent screen is configured")
print("   - Add test users if app is in testing mode")

print("\n3. 'Permission denied' error:")
print("   - Check OAuth scopes include Gmail access")
print("   - User must consent to Gmail access during login")

print("\n4. No emails found:")
print("   - Check the days_back parameter (default is 30 days)")
print("   - Ensure the Gmail account has emails in that timeframe")

print("\n5. Claude integration issues:")
print("   - Check ANTHROPIC_API_KEY is valid")
print("   - Ensure Claude model name is correct (claude-3-opus-20240229)")
print("   - Check API rate limits")

print("\n=== Next Steps ===")
print("1. Run the Flask app and check browser console for errors")
print("2. Enable debug logging: export FLASK_ENV=development")
print("3. Check logs for specific error messages")
print("4. Test with a fresh OAuth token") 


================================================
FILE: personal-ai-assistant/test_insights_display.html
================================================
<!DOCTYPE html>
<html>
<head>
    <title>Test Insights Display</title>
</head>
<body>
    <h1>Email Insights Test</h1>
    
    <h2>1. Fetch Session Data</h2>
    <button onclick="fetchDebugData()">Get Debug Info</button>
    <pre id="debug-output"></pre>
    
    <h2>2. Test Chat with Email Question</h2>
    <input type="text" id="chat-input" value="Can you see my emails? What are my key relationships?" style="width: 500px;">
    <button onclick="testChat()">Send to Chat</button>
    <pre id="chat-output"></pre>
    
    <h2>3. Raw Insights Data</h2>
    <button onclick="fetchInsights()">Get Raw Insights</button>
    <pre id="insights-output"></pre>
    
    <script>
        async function fetchDebugData() {
            try {
                const response = await fetch('/api/debug-session');
                const data = await response.json();
                document.getElementById('debug-output').textContent = JSON.stringify(data, null, 2);
            } catch (error) {
                document.getElementById('debug-output').textContent = 'Error: ' + error.message;
            }
        }
        
        async function testChat() {
            try {
                const message = document.getElementById('chat-input').value;
                const response = await fetch('/api/chat', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({message: message})
                });
                const data = await response.json();
                document.getElementById('chat-output').textContent = data.response || data.error;
            } catch (error) {
                document.getElementById('chat-output').textContent = 'Error: ' + error.message;
            }
        }
        
        async function fetchInsights() {
            try {
                const response = await fetch('/api/email-insights');
                const data = await response.json();
                document.getElementById('insights-output').textContent = JSON.stringify(data, null, 2);
            } catch (error) {
                document.getElementById('insights-output').textContent = 'Error: ' + error.message;
            }
        }
    </script>
</body>
</html> 


================================================
FILE: personal-ai-assistant/test_oauth.py
================================================
import os
from urllib.parse import urlencode

# Your current credentials
client_id = "177991573576-no5amofsosfbqkrn5sump22vuks25jip.apps.googleusercontent.com"
redirect_uri = "http://localhost:8080/login/google/authorized"

# Construct manual OAuth URL
params = {
    'client_id': client_id,
    'redirect_uri': redirect_uri,
    'scope': 'openid email profile',
    'response_type': 'code',
    'access_type': 'offline'
}

oauth_url = f"https://accounts.google.com/o/oauth2/auth?{urlencode(params)}"
print("Manual OAuth URL:")
print(oauth_url)



================================================
FILE: personal-ai-assistant/.env.example
================================================
# Flask Configuration
SECRET_KEY=your-secret-key-here
FLASK_ENV=development
DATABASE_URL=postgresql://username:password@localhost/dbname

# Claude API
ANTHROPIC_API_KEY=your-claude-api-key-here

# Google OAuth (for token management)
GOOGLE_CLIENT_ID=your-google-client-id
GOOGLE_CLIENT_SECRET=your-google-client-secret

# ClickUp (optional)
CLICKUP_API_KEY=your-clickup-key-if-needed

# Heroku
PORT=5000



================================================
FILE: personal-ai-assistant/.gitignore
================================================
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Environment
.env
.venv
env/
venv/
ENV/

# IDE
.vscode/
.idea/
*.swp
*.swo

# OS
.DS_Store
Thumbs.db

# Logs
*.log
logs/

# Database
*.db
*.sqlite

# User data
user_data/
temp/

# Node modules (if you add frontend build)
node_modules/
npm-debug.log*

# Flask session
flask_session/

# Heroku
.heroku/



================================================
FILE: personal-ai-assistant/backend/__init__.py
================================================



================================================
FILE: personal-ai-assistant/backend/fixed_main.py
================================================
import os
import time
from datetime import datetime, timedelta
from dotenv import load_dotenv
load_dotenv()  # Load environment variables from .env file

from flask import Flask, session, render_template, redirect, url_for, request, jsonify
from flask_dance.contrib.google import make_google_blueprint
from flask_session import Session
from werkzeug.middleware.proxy_fix import ProxyFix
import tempfile
import logging
import threading

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Global variables for tracking sync status
sync_status = {
    'is_syncing': False,
    'progress': 0,
    'user_email': '',
    'sync_type': '',
    'last_sync': None
}

# Initialize Claude client
from anthropic import Anthropic
claude_client = Anthropic(api_key=os.environ.get('ANTHROPIC_API_KEY'))

def create_app():
    app = Flask(__name__, template_folder='../templates', static_folder='../static')
    app.wsgi_app = ProxyFix(app.wsgi_app, x_for=1, x_proto=1, x_host=1, x_prefix=1)
    
    # Configure Flask session
    app.config['SECRET_KEY'] = os.environ.get('SECRET_KEY', 'dev-key-for-testing')
    app.config['SESSION_TYPE'] = 'filesystem'
    app.config['SESSION_FILE_DIR'] = tempfile.gettempdir()
    app.config['SESSION_PERMANENT'] = True
    app.config['PERMANENT_SESSION_LIFETIME'] = timedelta(days=7)
    Session(app)
    
    # Configure Google OAuth
    google_bp = make_google_blueprint(
        client_id=os.environ.get('GOOGLE_CLIENT_ID'),
        client_secret=os.environ.get('GOOGLE_CLIENT_SECRET'),
        scope=[
            'openid',
            'https://www.googleapis.com/auth/userinfo.email',
            'https://www.googleapis.com/auth/userinfo.profile',
            'https://www.googleapis.com/auth/gmail.readonly'
        ],
        redirect_url='/login/google/authorized',
        prefix='/login'
    )
    app.register_blueprint(google_bp, url_prefix='/login')
    
    @app.route('/')
    def index():
        return render_template('index.html', name=session.get('user_name', 'User'))
    
    @app.route('/login')
    def login():
        return redirect(url_for('google.login'))
    
    @app.route('/login/google/authorized')
    def authorized():
        if not google_bp.session.authorized:
            return redirect(url_for('google.login'))
        
        resp = google_bp.session.get('https://www.googleapis.com/oauth2/v1/userinfo')
        if not resp.ok:
            return redirect(url_for('google.login'))
        
        user_info = resp.json()
        session['user_name'] = user_info.get('name', 'User')
        session['user_email'] = user_info.get('email')
        session['google_oauth_token'] = {
            'access_token': google_bp.token['access_token'],
            'refresh_token': google_bp.token.get('refresh_token'),
            'token_type': google_bp.token['token_type'],
            'expires_at': google_bp.token['expires_at']
        }
        
        return redirect(url_for('index'))
    
    @app.route('/chat')
    def chat():
        if 'user_email' not in session:
            return redirect(url_for('google.login'))
        
        return render_template('chat.html', name=session.get('user_name', 'User'))
    
    @app.route('/settings')
    def settings():
        if 'user_email' not in session:
            return redirect(url_for('google.login'))
        
        return render_template('settings.html', 
                              name=session.get('user_name', 'User'),
                              email=session.get('user_email', ''),
                              gmail_connected='google_oauth_token' in session,
                              last_email_sync=session.get('last_email_sync', 'Never'),
                              email_sync_frequency=session.get('email_sync_frequency', 24),
                              email_days_back=session.get('email_days_back', 30),
                              urgent_alerts_enabled=session.get('urgent_alerts_enabled', True))
    
    @app.route('/email-insights')
    def email_insights():
        if 'user_email' not in session or 'google_oauth_token' not in session:
            return redirect(url_for('google.login'))
        
        user_email = session['user_email']
        access_token = session['google_oauth_token']['access_token']
        
        # Check if currently syncing
        global sync_status
        if sync_status['is_syncing'] and sync_status['user_email'] == user_email:
            return render_template('sync_in_progress.html',
                                  name=session.get('user_name', 'User'),
                                  sync_type=sync_status['sync_type'],
                                  progress=sync_status['progress'])
        
        # Check if we need to sync first
        last_sync = session.get('last_email_sync')
        if not last_sync:
            # Redirect to sync emails first
            return render_template('email_insights.html',
                                 name=session.get('user_name', 'User'),
                                 insights="<div class='alert alert-info'>No email insights available yet. Please <a href='/sync-emails'>sync your emails</a> first.</div>")
        
        try:
            # Initialize the EmailIntelligence module
            from backend.core.claude_integration.email_intelligence import EmailIntelligence
            email_intelligence = EmailIntelligence(claude_client)
            
            # Get email insights using the Gmail connector
            insights = email_intelligence.analyze_recent_emails(user_email, access_token, days_back=30)
            
            # Format the insights for display
            formatted_insights = f"""<div class='card mb-4'>
                <div class='card-header bg-primary text-white'>
                    <h2 class='mb-0'>Email Intelligence Report</h2>
                </div>
                <div class='card-body'>
                    <p class='lead'>Analysis of your email communications from the last 30 days</p>
                    
                    {"<div class='alert alert-info'><i class='fas fa-info-circle'></i> " + insights.get('message', '') + "</div>" if insights.get('message') else ""}
                    
                    <div class='card mb-3'>
                        <div class='card-header bg-light'>
                            <h3 class='mb-0'><i class='fas fa-users'></i> Key Relationships</h3>
                        </div>
                        <div class='card-body'>
                            <ul class='list-group list-group-flush'>"""
            
            if insights.get('key_relationships'):
                for relationship in insights.get('key_relationships', []):
                    if isinstance(relationship, dict):
                        name = relationship.get('name', 'Unknown')
                        email = relationship.get('email', '')
                        context = relationship.get('context', '')
                        formatted_insights += f"""<li class='list-group-item'>
                            <strong>{name}</strong> {f"<span class='text-muted'>({email})</span>" if email else ""}
                            <p class='mb-0'>{context}</p>
                        </li>"""
                    else:
                        formatted_insights += f"<li class='list-group-item'>{relationship}</li>"
            else:
                formatted_insights += "<li class='list-group-item'>No key relationships identified</li>"
            
            formatted_insights += """</ul>
                        </div>
                    </div>
                    
                    <div class='card mb-3'>
                        <div class='card-header bg-light'>
                            <h3 class='mb-0'><i class='fas fa-tasks'></i> Active Projects</h3>
                        </div>
                        <div class='card-body'>
                            <ul class='list-group list-group-flush'>"""
            
            if insights.get('active_projects'):
                for project in insights.get('active_projects', []):
                    if isinstance(project, dict):
                        name = project.get('name', 'Unknown')
                        description = project.get('description', '')
                        formatted_insights += f"""<li class='list-group-item'>
                            <strong>{name}</strong>
                            <p class='mb-0'>{description}</p>
                        </li>"""
                    else:
                        formatted_insights += f"<li class='list-group-item'>{project}</li>"
            else:
                formatted_insights += "<li class='list-group-item'>No active projects identified</li>"
            
            formatted_insights += """</ul>
                        </div>
                    </div>
                    
                    <div class='card mb-3'>
                        <div class='card-header bg-light'>
                            <h3 class='mb-0'><i class='fas fa-clipboard-check'></i> Action Items</h3>
                        </div>
                        <div class='card-body'>
                            <ul class='list-group list-group-flush'>"""
            
            if insights.get('action_items'):
                for action in insights.get('action_items', []):
                    if isinstance(action, dict):
                        description = action.get('description', 'Unknown')
                        deadline = action.get('deadline', '')
                        formatted_insights += f"""<li class='list-group-item'>
                            <strong>{description}</strong>
                            {f"<span class='badge bg-warning text-dark'>Due: {deadline}</span>" if deadline else ""}
                        </li>"""
                    else:
                        formatted_insights += f"<li class='list-group-item'>{action}</li>"
            else:
                formatted_insights += "<li class='list-group-item'>No action items identified</li>"
            
            formatted_insights += """</ul>
                        </div>
                    </div>
                    
                    <div class='card mb-3'>
                        <div class='card-header bg-light'>
                            <h3 class='mb-0'><i class='fas fa-info-circle'></i> Important Information</h3>
                        </div>
                        <div class='card-body'>
                            <ul class='list-group list-group-flush'>"""
            
            if insights.get('important_information'):
                for info in insights.get('important_information', []):
                    if isinstance(info, dict):
                        description = info.get('description', '')
                        formatted_insights += f"<li class='list-group-item'>{description}</li>"
                    else:
                        formatted_insights += f"<li class='list-group-item'>{info}</li>"
            else:
                formatted_insights += "<li class='list-group-item'>No important information identified</li>"
            
            formatted_insights += """</ul>
                        </div>
                    </div>
                </div>
            </div>"""
            
            # Update last sync time
            session['last_email_sync'] = datetime.now().strftime("%Y-%m-%d %H:%M")
            
            return render_template('email_insights.html', 
                                  name=session.get('user_name', 'User'),
                                  insights=formatted_insights)
                
        except Exception as e:
            logger.error(f"Email insights error: {str(e)}")
            return jsonify({'error': f'Email insights error: {str(e)}'}), 500
    
    @app.route('/logout')
    def logout():
        session.clear()
        return redirect(url_for('index'))
    
    @app.route('/sync-emails')
    def sync_emails():
        if 'user_email' not in session or 'google_oauth_token' not in session:
            return redirect(url_for('google.login'))
            
        user_email = session['user_email']
        access_token = session['google_oauth_token']['access_token']
        days_back = session.get('email_days_back', 30)
        
        # Start sync in background thread
        def run_sync():
            global sync_status
            sync_status['is_syncing'] = True
            sync_status['progress'] = 0
            sync_status['user_email'] = user_email
            sync_status['sync_type'] = 'Email Intelligence'
            
            try:
                # Initialize the EmailIntelligence module
                import sys
                import os
                # Add the project root to the Python path
                sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
                from core.claude_integration.email_intelligence import EmailIntelligence
                email_intelligence = EmailIntelligence(claude_client)
                
                # Simulate progress updates
                sync_status['progress'] = 10
                time.sleep(1)  # Simulate work
                
                # Fetch emails
                sync_status['progress'] = 30
                time.sleep(1)  # Simulate work
                
                # Analyze emails
                sync_status['progress'] = 60
                email_intelligence.analyze_recent_emails(user_email, access_token, days_back=days_back)
                time.sleep(1)  # Simulate work
                
                # Scan for urgent emails
                sync_status['progress'] = 80
                email_intelligence.scan_urgent_emails(user_email, access_token, hours_back=24)
                time.sleep(1)  # Simulate work
                
                # Identify key contacts
                sync_status['progress'] = 90
                email_intelligence.identify_key_contacts(user_email)
                time.sleep(1)  # Simulate work
                
                # Complete
                sync_status['progress'] = 100
                sync_status['last_sync'] = datetime.now().strftime("%Y-%m-%d %H:%M")
                # Store last sync time in session for email insights page
                session['last_email_sync'] = datetime.now().strftime("%Y-%m-%d %H:%M")
                
            except Exception as e:
                logger.error(f"Email sync error: {str(e)}")
            finally:
                sync_status['is_syncing'] = False
        
        # Start sync thread if not already syncing
        global sync_status
        if not sync_status['is_syncing']:
            sync_thread = threading.Thread(target=run_sync)
            sync_thread.daemon = True
            sync_thread.start()
            # Show sync progress page
            return render_template('sync_in_progress.html',
                                 name=session.get('user_name', 'User'),
                                 sync_type='Email Intelligence',
                                 progress=0)
        else:
            return jsonify({'error': 'Sync already in progress'}), 400
            
    @app.route('/api/sync-status')
    def get_sync_status():
        global sync_status
        # If sync is complete, redirect to email insights
        if not sync_status['is_syncing'] and sync_status['progress'] == 100:
            # Reset progress to avoid repeated redirects
            sync_status['progress'] = 0
            return jsonify({
                'is_syncing': False,
                'progress': 100,
                'user_email': sync_status['user_email'],
                'sync_type': sync_status['sync_type'],
                'redirect': '/email-insights'
            })
        return jsonify({
            'is_syncing': sync_status['is_syncing'],
            'progress': sync_status['progress'],
            'user_email': sync_status['user_email'],
            'sync_type': sync_status['sync_type']
        })
            
    @app.route('/api/save-preferences', methods=['POST'])
    def save_preferences():
        if 'user_email' not in session:
            return jsonify({'success': False, 'error': 'Not logged in'}), 401
            
        try:
            data = request.json
            
            # Save preferences to session
            session['email_sync_frequency'] = int(data.get('email_sync_frequency', 24))
            session['email_days_back'] = int(data.get('email_days_back', 30))
            session['urgent_alerts_enabled'] = bool(data.get('urgent_alerts_enabled', True))
            
            return jsonify({'success': True})
        except Exception as e:
            logger.error(f"Error saving preferences: {str(e)}")
            return jsonify({'success': False, 'error': str(e)}), 500
            
    @app.route('/disconnect-gmail')
    def disconnect_gmail():
        if 'google_oauth_token' in session:
            del session['google_oauth_token']
        return redirect(url_for('settings'))
    
    return app

if __name__ == '__main__':
    app = create_app()
    app.run(host='0.0.0.0', port=8080, debug=True)



================================================
FILE: personal-ai-assistant/backend/main.py
================================================
import os
import sys
import time
import pathlib
import secrets
import requests
from datetime import datetime, timedelta
from sqlalchemy import create_engine
from dotenv import load_dotenv
from werkzeug.utils import secure_filename
# Import SQLAlchemy components
from sqlalchemy.orm import sessionmaker

# Add the project root directory to Python's import path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))  

load_dotenv()  # Load environment variables from .env file

from flask import Flask, session, render_template, redirect, url_for, request, jsonify, send_file
from flask_session import Session
from werkzeug.middleware.proxy_fix import ProxyFix
import tempfile
import logging
import threading

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Global variables for tracking sync status
sync_status = {
    'is_syncing': False,
    'progress': 0,
    'user_email': '',
    'sync_type': '',
    'last_sync': None
}

# Initialize Claude client
from anthropic import Anthropic
claude_client = Anthropic(api_key=os.environ.get('ANTHROPIC_API_KEY'))

# Initialize database URL
# Define a global database URL with an absolute path
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATABASE_PATH = os.path.join(BASE_DIR, 'chief_of_staff.db')
database_url = os.environ.get('DATABASE_URL', f'sqlite:///{DATABASE_PATH}')

def create_app():
    app = Flask(__name__, template_folder='../templates', static_folder='../static')
    app.wsgi_app = ProxyFix(app.wsgi_app, x_for=1, x_proto=1, x_host=1, x_prefix=1)
    
    # Configure Flask session
    app.config['SECRET_KEY'] = os.environ.get('SECRET_KEY', 'dev-key-for-testing')
    app.config['SESSION_TYPE'] = 'filesystem'
    
    # Create a dedicated directory for session files
    session_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', 'flask_session')
    os.makedirs(session_dir, exist_ok=True)
    app.config['SESSION_FILE_DIR'] = session_dir
    
    app.config['SESSION_PERMANENT'] = True
    app.config['PERMANENT_SESSION_LIFETIME'] = timedelta(days=7)
    Session(app)
    
    # Google OAuth configuration
    GOOGLE_CLIENT_ID = os.environ.get('GOOGLE_CLIENT_ID')
    GOOGLE_CLIENT_SECRET = os.environ.get('GOOGLE_CLIENT_SECRET')
    GOOGLE_AUTH_URI = 'https://accounts.google.com/o/oauth2/auth'
    GOOGLE_TOKEN_URI = 'https://oauth2.googleapis.com/token'
    GOOGLE_REDIRECT_URI = 'http://127.0.0.1:8080/login/google/authorized'
    
    @app.route('/')
    def index():
        return render_template('index.html', name=session.get('user_name', 'User'))
    
    @app.route('/login')
    def login():
        # Only clear session if user is not already logged in
        if 'user_email' not in session or 'google_oauth_token' not in session:
            logger.info("User not logged in, clearing any partial session data")
            for key in list(session.keys()):
                if key.startswith('google_') or key in ['user_name', 'user_email']:
                    del session[key]
        else:
            logger.info(f"User already logged in as {session.get('user_email')}")
            return redirect(url_for('settings'))
        
        # Generate a secure state token
        state = secrets.token_urlsafe(16)
        session['oauth_state'] = state
        
        # Build the authorization URL
        auth_params = {
            'client_id': GOOGLE_CLIENT_ID,
            'redirect_uri': GOOGLE_REDIRECT_URI,
            'scope': 'openid email profile https://www.googleapis.com/auth/gmail.readonly',
            'access_type': 'offline',
            'response_type': 'code',
            'state': state,
            'prompt': 'consent'
        }
        
        auth_url = f"{GOOGLE_AUTH_URI}?" + '&'.join([f"{k}={v}" for k, v in auth_params.items()])
        logger.info("Starting OAuth flow with state: " + state)
        return redirect(auth_url)
    
    @app.route('/login/google/authorized')
    def authorized():
        # Verify state parameter to prevent CSRF
        state = request.args.get('state')
        stored_state = session.get('oauth_state')
        
        if not state or state != stored_state:
            logger.error(f"State mismatch: received {state}, expected {stored_state}")
            return redirect(url_for('index'))
        
        # Clear the state from session
        if 'oauth_state' in session:
            del session['oauth_state']
        
        # Exchange authorization code for tokens
        code = request.args.get('code')
        if not code:
            logger.error("No authorization code received")
            return redirect(url_for('index'))
        
        token_params = {
            'client_id': GOOGLE_CLIENT_ID,
            'client_secret': GOOGLE_CLIENT_SECRET,
            'code': code,
            'redirect_uri': GOOGLE_REDIRECT_URI,
            'grant_type': 'authorization_code'
        }
        
        try:
            # Exchange code for token
            token_response = requests.post(GOOGLE_TOKEN_URI, data=token_params)
            token_data = token_response.json()
            
            if 'error' in token_data:
                logger.error(f"Token exchange error: {token_data['error']}")
                return redirect(url_for('index'))
            
            # Store token in session
            session['google_oauth_token'] = {
                'access_token': token_data['access_token'],
                'refresh_token': token_data.get('refresh_token'),
                'token_type': token_data['token_type'],
                'expires_at': int(time.time()) + token_data['expires_in']
            }
            
            # Get user info
            headers = {'Authorization': f"Bearer {token_data['access_token']}"}
            user_info_response = requests.get('https://www.googleapis.com/oauth2/v1/userinfo', headers=headers)
            user_info = user_info_response.json()
            
            session['user_name'] = user_info.get('name', 'User')
            session['user_email'] = user_info.get('email')
            
            logger.info(f"Successfully authenticated user: {session['user_email']}")
            return redirect(url_for('index'))
        except Exception as e:
            logger.error(f"OAuth callback error: {str(e)}")
            return redirect(url_for('index'))
    
    @app.route('/chat')
    def chat():
        if 'user_email' not in session:
            return redirect(url_for('login'))
        
        return render_template('chat.html', name=session.get('user_name', 'User'))
    
    @app.route('/settings')
    def settings():
        if 'user_email' not in session:
            return redirect(url_for('login'))
        
        user_email = session.get('user_email')
        
        # Get sync status
        global sync_status
        current_sync_status = None
        if sync_status['is_syncing'] and sync_status['user_email'] == user_email:
            current_sync_status = sync_status
        
        # Initialize intelligence service for this request
        from services.intelligence_service import IntelligenceService
        from models.database.insights_storage import UserIntelligence, EmailSyncStatus
        intelligence_service = IntelligenceService(database_url, claude_client)
        
        # Get user preferences
        session_db = intelligence_service.SessionLocal()
        try:
            user_intel = session_db.query(UserIntelligence).filter_by(user_email=user_email).first()
            preferences = user_intel.personal_knowledge.get('preferences', {}) if user_intel else {}
        finally:
            session_db.close()
        
        # Initialize structured knowledge service
        from services.structured_knowledge_service import StructuredKnowledgeService
        structured_knowledge_service = StructuredKnowledgeService(intelligence_service.SessionLocal)
        
        # Get structured knowledge
        projects = structured_knowledge_service.get_projects(user_email)
        goals = structured_knowledge_service.get_goals(user_email)
        knowledge_files = structured_knowledge_service.get_knowledge_files(user_email)
        
        return render_template('settings.html', 
                               user_email=user_email,
                               sync_status=current_sync_status,
                               preferences=preferences,
                               projects=projects,
                               goals=goals,
                               knowledge_files=knowledge_files,
                               email_sync_frequency=session.get('email_sync_frequency', 24),
                               email_days_back=session.get('email_days_back', 30),
                               urgent_alerts_enabled=session.get('urgent_alerts_enabled', True))
    
    @app.route('/email-insights')
    def email_insights():
        if 'user_email' not in session:
            return redirect(url_for('login'))
        
        user_email = session['user_email']
        
        # Initialize intelligence service using the global database_url
        # Initialize intelligence service for this request
        from services.intelligence_service import IntelligenceService
        from models.database.insights_storage import UserIntelligence
        intelligence_service = IntelligenceService(database_url, claude_client)
        
        # Check if a sync is in progress for this user
        global sync_status
        if sync_status.get('user_email') == user_email and sync_status.get('is_syncing', False):
            # Redirect to sync progress page if sync is in progress
            return render_template('sync_in_progress.html',
                                name=session.get('user_name', 'User'),
                                sync_type='Email Intelligence',
                                progress=sync_status.get('progress', 0))
        
        # Get insights from database
        insights = intelligence_service.get_user_insights(user_email)
        
        if insights.get('status') == 'no_data':
            return render_template('email_insights.html',
                                name=session.get('user_name', 'User'),
                                insights="<div class='alert alert-info'>No email insights available yet. Please <a href='/sync-emails'>sync your emails</a> first.</div>")
        
        # Debug logging
        logger.info(f"Insights keys: {list(insights.keys())}")
        logger.info(f"Key relationships count: {len(insights.get('key_relationships', []))}")
        
        # Set the last sync time in the session for display
        if 'generated_at' in insights:
            session['last_email_sync'] = insights['generated_at']
        

        

        

        

        

        

        

        
        # Pass the raw insights data to the template
        return render_template('email_insights.html', 
                            name=session.get('user_name', 'User'),
                            insights=insights)
    
    @app.route('/logout')
    def logout():
        session.clear()
        logger.info("User logged out")
        return redirect(url_for('index'))
    
    @app.route('/sync-emails', methods=['GET', 'POST'])
    def sync_emails():
        logger.info(f"Sync emails route called with method: {request.method}")
        
        if 'user_email' not in session or 'google_oauth_token' not in session:
            logger.warning("User not authenticated, redirecting to login")
            return redirect(url_for('login'))
            
        user_email = session['user_email']
        access_token = session['google_oauth_token']['access_token']
        days_back = session.get('email_days_back', 30)
        
        # Check if force_full_sync was requested
        force_full_sync = request.args.get('force_full_sync', 'false').lower() == 'true'
        
        logger.info(f"Starting email sync for {user_email} with {days_back} days back, force_full_sync={force_full_sync}")
        
        # Initialize intelligence service using the global database_url
        # Initialize intelligence service for this request
        from services.intelligence_service import IntelligenceService
        from models.database.insights_storage import UserIntelligence
        intelligence_service = IntelligenceService(database_url, claude_client)
        
        # Update global sync status
        global sync_status
        sync_status = {
            'user_email': user_email,
            'is_syncing': True,
            'progress': 0,
            'sync_type': 'Email Intelligence',
            'start_time': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
        # Start sync in background thread
        def run_sync():
            global sync_status
            try:
                logger.info("Starting email sync in background thread")
                
                # Process and store insights
                result = intelligence_service.process_and_store_email_insights(
                    user_email, 
                    access_token, 
                    days_back,
                    force_full_sync
                )
                
                logger.info(f"Email sync completed with result: {result}")
                
                # Update sync status with results
                sync_status['is_syncing'] = False
                sync_status['progress'] = 100
                sync_status['completed_at'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                sync_status['email_insights'] = result
                
            except Exception as e:
                logger.error(f"Error in background sync thread: {str(e)}")
                # Update sync status with error
                sync_status['is_syncing'] = False
                sync_status['progress'] = 0
                sync_status['error'] = str(e)
        
        # Start sync thread
        sync_thread = threading.Thread(target=run_sync)
        sync_thread.daemon = True
        sync_thread.start()
        logger.info("Sync thread started successfully")
        
        # Show sync progress page
        return render_template('sync_in_progress.html',
                            name=session.get('user_name', 'User'),
                            sync_type='Email Intelligence',
                            progress=0)
            
    @app.route('/disconnect-gmail')
    def disconnect_gmail():
        if 'google_oauth_token' in session:
            del session['google_oauth_token']
        if 'last_email_sync' in session:
            del session['last_email_sync']
            
        # Redirect to settings page
        return redirect(url_for('settings'))
    
    @app.route('/api/sync-status')
    def api_sync_status():
        global sync_status
        
        if 'user_email' not in session:
            return jsonify({'error': 'Not authenticated'}), 401
            
        # Only return sync status for the current user
        if sync_status.get('user_email') == session.get('user_email'):
            # If sync is complete, update session with insights
            if not sync_status.get('is_syncing') and sync_status.get('progress') == 100:
                if 'email_insights' in sync_status:
                    session['email_insights'] = sync_status['email_insights']
                    session['last_email_sync'] = sync_status.get('last_sync', datetime.now().strftime("%Y-%m-%d %H:%M"))
                
            return jsonify({
                'is_syncing': sync_status.get('is_syncing', False),
                'progress': sync_status.get('progress', 0),
                'sync_type': sync_status.get('sync_type', ''),
                'redirect': '/email-insights' if not sync_status.get('is_syncing') and sync_status.get('progress') == 100 else None
            })
        else:
            # No sync status for this user
            # Instead of redirecting to settings, redirect to email-insights
            # This prevents the redirect loop when returning from settings page
            return jsonify({
                'is_syncing': False,
                'progress': 0,
                'sync_type': '',
                'redirect': '/email-insights'
            })
    
    @app.route('/api/save-preferences', methods=['POST'])
    def save_preferences():
        if 'user_email' not in session:
            return jsonify({'success': False, 'error': 'Not logged in'}), 401
            
        try:
            data = request.json
            
            # Save preferences to session
            session['email_sync_frequency'] = int(data.get('email_sync_frequency', 24))
            session['email_days_back'] = int(data.get('email_days_back', 30))
            session['urgent_alerts_enabled'] = bool(data.get('urgent_alerts_enabled', True))
            
            return jsonify({'success': True})
        except Exception as e:
            logger.error(f"Error saving preferences: {str(e)}")
            return jsonify({'success': False, 'error': str(e)}), 500
    
    @app.route('/api/chat', methods=['POST'])
    def api_chat():
        """Handle chat messages and get responses from Claude."""
        if 'user_email' not in session:
            return jsonify({'error': 'Not authenticated'}), 401
        
        try:
            data = request.json
            if not data or 'message' not in data:
                return jsonify({'error': 'No message provided'}), 400
            
            user_message = data['message']
            logger.info(f"Chat request from {session['user_email']}: {user_message[:50]}...")
            
            # Get context from session if available
            email_insights = session.get('email_insights', {})
            user_name = session.get('user_name', 'User')
            user_email = session.get('user_email', 'user@example.com')
            
            # Build a more detailed context for Claude
            context_parts = [f"You are an AI Chief of Staff assistant for {user_name} ({user_email})."]
            
            if email_insights and email_insights.get('status') != 'error':
                context_parts.append("\nBased on recent email analysis, here's what I know:")
                
                # Add key relationships
                if email_insights.get('key_relationships'):
                    context_parts.append("\n**Key Relationships:**")
                    for rel in email_insights['key_relationships'][:5]:  # Top 5
                        if isinstance(rel, dict):
                            context_parts.append(f"- {rel.get('name', 'Unknown')} ({rel.get('email', '')}): {rel.get('context', '')}")
                        else:
                            context_parts.append(f"- {rel}")
                
                # Add active projects
                if email_insights.get('active_projects'):
                    context_parts.append("\n**Active Projects:**")
                    for proj in email_insights['active_projects'][:5]:  # Top 5
                        if isinstance(proj, dict):
                            context_parts.append(f"- {proj.get('name', 'Unknown')}: {proj.get('description', '')}")
                        else:
                            context_parts.append(f"- {proj}")
                
                # Add action items
                if email_insights.get('action_items'):
                    context_parts.append("\n**Action Items:**")
                    for action in email_insights['action_items'][:5]:  # Top 5
                        if isinstance(action, dict):
                            context_parts.append(f"- {action.get('description', 'Unknown')} (Due: {action.get('deadline', 'No deadline')})")
                        else:
                            context_parts.append(f"- {action}")
                
                # Add important information
                if email_insights.get('important_information'):
                    context_parts.append("\n**Important Information:**")
                    for info in email_insights['important_information'][:3]:  # Top 3
                        if isinstance(info, dict):
                            context_parts.append(f"- {info.get('description', '')}")
                        else:
                            context_parts.append(f"- {info}")
                
                context_parts.append(f"\nThis information is based on analyzing {user_name}'s emails from the last 30 days.")
            else:
                context_parts.append("\nNo email insights are currently available. The user may need to sync their emails first.")
            
            context = "\n".join(context_parts)
            
            # Log context for debugging
            logger.info(f"Context length: {len(context)} characters")
            logger.info(f"Has insights: {'email_insights' in session and bool(email_insights)}")
            
            # Send message to Claude
            try:
                response = claude_client.messages.create(
                    model="claude-3-opus-20240229",
                    max_tokens=2000,
                    temperature=0.7,
                    system=context,
                    messages=[{"role": "user", "content": user_message}]
                )
                
                # Extract the response text
                assistant_message = response.content[0].text
                
            except AttributeError:
                # Fallback for older SDK versions
                logger.info("Using fallback Claude client interface for chat")
                response = claude_client.completions.create(
                    model="claude-3-opus-20240229",
                    max_tokens=2000,
                    temperature=0.7,
                    system=context,
                    prompt=user_message
                )
                assistant_message = response.completion
            
            logger.info(f"Claude response: {assistant_message[:50]}...")
            
            return jsonify({
                'response': assistant_message,
                'status': 'success'
            })
            
        except Exception as e:
            logger.error(f"Chat API error: {str(e)}")
            import traceback
            logger.error(f"Traceback: {traceback.format_exc()}")
            return jsonify({
                'error': f'Failed to process chat: {str(e)}',
                'status': 'error'
            }), 500
    
    @app.route('/test-insights')
    def test_insights():
        """Test page for debugging insights display"""
        if 'user_email' not in session:
            return redirect(url_for('login'))
        return send_file('../test_insights_display.html')
    
    @app.route('/api/debug-session')
    def debug_session():
        """Debug endpoint to check session data"""
        if 'user_email' not in session:
            return jsonify({'error': 'Not authenticated'}), 401
        
        # Get insights from session
        email_insights = session.get('email_insights', {})
        
        # Check structure
        debug_info = {
            'user_email': session.get('user_email'),
            'last_sync': session.get('last_email_sync', 'Never'),
            'has_insights': 'email_insights' in session,
            'insights_keys': list(email_insights.keys()) if email_insights else [],
            'insights_summary': {
                'key_relationships': len(email_insights.get('key_relationships', [])),
                'active_projects': len(email_insights.get('active_projects', [])),
                'action_items': len(email_insights.get('action_items', [])),
                'important_information': len(email_insights.get('important_information', []))
            } if email_insights else {},
            'sample_relationship': email_insights.get('key_relationships', [{}])[0] if email_insights.get('key_relationships') else None,
            'insights_status': email_insights.get('status', 'unknown')
        }
        
        return jsonify(debug_info)
    
    # API routes for structured knowledge
    @app.route('/api/projects', methods=['GET', 'POST'])
    def api_projects():
        if 'user_email' not in session:
            return jsonify({'error': 'Not authenticated'}), 401
        
        user_email = session.get('user_email')
        
        # Initialize intelligence service
        from services.intelligence_service import IntelligenceService
        intelligence_service = IntelligenceService(database_url, claude_client)
        
        # Initialize structured knowledge service
        from services.structured_knowledge_service import StructuredKnowledgeService
        structured_knowledge_service = StructuredKnowledgeService(intelligence_service.SessionLocal)
        
        if request.method == 'GET':
            projects = structured_knowledge_service.get_projects(user_email)
            return jsonify(projects)
        
        elif request.method == 'POST':
            project_data = request.json
            if not project_data or 'name' not in project_data:
                return jsonify({'error': 'Project name is required', 'success': False}), 400
            
            project = structured_knowledge_service.create_project(user_email, project_data)
            return jsonify({'success': True, 'project': project})
    
    @app.route('/api/projects/<project_id>', methods=['GET', 'PUT', 'DELETE'])
    def api_project(project_id):
        if 'user_email' not in session:
            return jsonify({'error': 'Not authenticated'}), 401
        
        user_email = session.get('user_email')
        
        # Initialize intelligence service
        from services.intelligence_service import IntelligenceService
        intelligence_service = IntelligenceService(database_url, claude_client)
        
        # Initialize structured knowledge service
        from services.structured_knowledge_service import StructuredKnowledgeService
        structured_knowledge_service = StructuredKnowledgeService(intelligence_service.SessionLocal)
        
        if request.method == 'GET':
            project = structured_knowledge_service.get_project(user_email, project_id)
            if not project:
                return jsonify({'error': 'Project not found'}), 404
            return jsonify(project)
        
        elif request.method == 'PUT':
            project_data = request.json
            if not project_data:
                return jsonify({'error': 'No data provided', 'success': False}), 400
            
            project = structured_knowledge_service.update_project(user_email, project_id, project_data)
            if not project:
                return jsonify({'error': 'Project not found', 'success': False}), 404
            return jsonify({'success': True, 'project': project})
        
        elif request.method == 'DELETE':
            success = structured_knowledge_service.delete_project(user_email, project_id)
            if not success:
                return jsonify({'error': 'Project not found', 'success': False}), 404
            return jsonify({'success': True})
    
    @app.route('/api/goals', methods=['GET', 'POST'])
    def api_goals():
        if 'user_email' not in session:
            return jsonify({'error': 'Not authenticated'}), 401
        
        user_email = session.get('user_email')
        
        # Initialize intelligence service
        from services.intelligence_service import IntelligenceService
        intelligence_service = IntelligenceService(database_url, claude_client)
        
        # Initialize structured knowledge service
        from services.structured_knowledge_service import StructuredKnowledgeService
        structured_knowledge_service = StructuredKnowledgeService(intelligence_service.SessionLocal)
        
        if request.method == 'GET':
            goals = structured_knowledge_service.get_goals(user_email)
            return jsonify(goals)
        
        elif request.method == 'POST':
            goal_data = request.json
            if not goal_data or 'title' not in goal_data:
                return jsonify({'error': 'Goal title is required', 'success': False}), 400
            
            goal = structured_knowledge_service.create_goal(user_email, goal_data)
            return jsonify({'success': True, 'goal': goal})
    
    @app.route('/api/goals/<goal_id>', methods=['GET', 'PUT', 'DELETE'])
    def api_goal(goal_id):
        if 'user_email' not in session:
            return jsonify({'error': 'Not authenticated'}), 401
        
        user_email = session.get('user_email')
        
        # Initialize intelligence service
        from services.intelligence_service import IntelligenceService
        intelligence_service = IntelligenceService(database_url, claude_client)
        
        # Initialize structured knowledge service
        from services.structured_knowledge_service import StructuredKnowledgeService
        structured_knowledge_service = StructuredKnowledgeService(intelligence_service.SessionLocal)
        
        if request.method == 'GET':
            goal = structured_knowledge_service.get_goal(user_email, goal_id)
            if not goal:
                return jsonify({'error': 'Goal not found'}), 404
            return jsonify(goal)
        
        elif request.method == 'PUT':
            goal_data = request.json
            if not goal_data:
                return jsonify({'error': 'No data provided', 'success': False}), 400
            
            goal = structured_knowledge_service.update_goal(user_email, goal_id, goal_data)
            if not goal:
                return jsonify({'error': 'Goal not found', 'success': False}), 404
            return jsonify({'success': True, 'goal': goal})
        
        elif request.method == 'DELETE':
            success = structured_knowledge_service.delete_goal(user_email, goal_id)
            if not success:
                return jsonify({'error': 'Goal not found', 'success': False}), 404
            return jsonify({'success': True})
    
    @app.route('/api/knowledge-files', methods=['GET', 'POST'])
    def api_knowledge_files():
        if 'user_email' not in session:
            return jsonify({'error': 'Not authenticated'}), 401
        
        user_email = session.get('user_email')
        
        # Initialize intelligence service
        from services.intelligence_service import IntelligenceService
        intelligence_service = IntelligenceService(database_url, claude_client)
        
        # Initialize structured knowledge service
        from services.structured_knowledge_service import StructuredKnowledgeService
        structured_knowledge_service = StructuredKnowledgeService(intelligence_service.SessionLocal)
        
        if request.method == 'GET':
            files = structured_knowledge_service.get_knowledge_files(user_email)
            return jsonify(files)
        
        elif request.method == 'POST':
            if 'file' not in request.files:
                return jsonify({'error': 'No file part', 'success': False}), 400
            
            file = request.files['file']
            if file.filename == '':
                return jsonify({'error': 'No selected file', 'success': False}), 400
            
            if not structured_knowledge_service.allowed_file(file.filename):
                return jsonify({'error': 'File type not allowed', 'success': False}), 400
            
            description = request.form.get('description', '')
            category = request.form.get('category', 'general')
            
            # Initialize structured knowledge service for this request
            from services.structured_knowledge_service import StructuredKnowledgeService
            structured_knowledge_service = StructuredKnowledgeService(intelligence_service.SessionLocal)
            file_data = structured_knowledge_service.upload_knowledge_file(user_email, file, description, category)
            
            if not file_data:
                return jsonify({'error': 'Failed to upload file', 'success': False}), 500
            
            return jsonify({'success': True, 'file': file_data})
    
    @app.route('/api/knowledge-files/<file_id>', methods=['GET', 'DELETE'])
    def api_knowledge_file(file_id):
        if 'user_email' not in session:
            return jsonify({'error': 'Not authenticated'}), 401
        
        user_email = session.get('user_email')
        
        # Initialize intelligence service
        from services.intelligence_service import IntelligenceService
        intelligence_service = IntelligenceService(database_url, claude_client)
        
        # Initialize structured knowledge service
        from services.structured_knowledge_service import StructuredKnowledgeService
        structured_knowledge_service = StructuredKnowledgeService(intelligence_service.SessionLocal)
        
        if request.method == 'GET':
            file_data = structured_knowledge_service.get_knowledge_file(user_email, file_id)
            if not file_data:
                return jsonify({'error': 'File not found'}), 404
            return jsonify(file_data)
        
        elif request.method == 'DELETE':
            success = structured_knowledge_service.delete_knowledge_file(user_email, file_id)
            if not success:
                return jsonify({'error': 'File not found', 'success': False}), 404
            return jsonify({'success': True})
    
    @app.route('/api/knowledge-files/<file_id>/view', methods=['GET'])
    def api_view_knowledge_file(file_id):
        if 'user_email' not in session:
            return jsonify({'error': 'Not authenticated'}), 401
        
        user_email = session.get('user_email')
        
        # Initialize intelligence service for this request
        from services.intelligence_service import IntelligenceService
        intelligence_service = IntelligenceService(database_url, claude_client)
        
        # Get file data from database
        session_db = intelligence_service.SessionLocal()
        try:
            file = session_db.query(KnowledgeFile).filter_by(user_email=user_email, id=file_id).first()
            if not file or not os.path.exists(file.file_path):
                return jsonify({'error': 'File not found'}), 404
            
            return send_file(file.file_path, 
                           download_name=file.original_filename,
                           as_attachment=False)
        finally:
            session_db.close()
    
    return app

if __name__ == '__main__':
    app = create_app()
    app.run(host='0.0.0.0', port=8080, debug=True)


================================================
FILE: personal-ai-assistant/backend/main.py.broken
================================================
import os
import time
import pathlib
import secrets
import requests
from datetime import datetime, timedelta
from dotenv import load_dotenv
load_dotenv()  # Load environment variables from .env file

from flask import Flask, session, render_template, redirect, url_for, request, jsonify
from flask_session import Session
from werkzeug.middleware.proxy_fix import ProxyFix
import tempfile
import logging
import threading

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Global variables for tracking sync status
sync_status = {
    'is_syncing': False,
    'progress': 0,
    'user_email': '',
    'sync_type': '',
    'last_sync': None,
    'email_insights': None
}

# Initialize Claude client
from anthropic import Anthropic
claude_client = Anthropic(api_key=os.environ.get('ANTHROPIC_API_KEY'))

def create_app():
    app = Flask(__name__, template_folder='../templates', static_folder='../static')
    app.wsgi_app = ProxyFix(app.wsgi_app, x_for=1, x_proto=1, x_host=1, x_prefix=1)
    
    # Configure Flask session
    app.config['SECRET_KEY'] = os.environ.get('SECRET_KEY', 'dev-key-for-testing')
    app.config['SESSION_TYPE'] = 'filesystem'
    
    # Create a dedicated directory for session files
    session_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), '..', 'flask_session')
    os.makedirs(session_dir, exist_ok=True)
    app.config['SESSION_FILE_DIR'] = session_dir
    
    app.config['SESSION_PERMANENT'] = True
    app.config['PERMANENT_SESSION_LIFETIME'] = timedelta(days=7)
    Session(app)
    
    # Google OAuth configuration
    GOOGLE_CLIENT_ID = os.environ.get('GOOGLE_CLIENT_ID')
    GOOGLE_CLIENT_SECRET = os.environ.get('GOOGLE_CLIENT_SECRET')
    GOOGLE_AUTH_URI = 'https://accounts.google.com/o/oauth2/auth'
    GOOGLE_TOKEN_URI = 'https://oauth2.googleapis.com/token'
    GOOGLE_REDIRECT_URI = 'http://127.0.0.1:8080/login/google/authorized'
    
    @app.route('/')
    def index():
        return render_template('index.html', name=session.get('user_name', 'User'))
    
    @app.route('/login')
    def login():
        # Only clear session if user is not already logged in
        if 'user_email' not in session or 'google_oauth_token' not in session:
            logger.info("User not logged in, clearing any partial session data")
            for key in list(session.keys()):
                if key.startswith('google_') or key in ['user_name', 'user_email']:
                    del session[key]
        else:
            logger.info(f"User already logged in as {session.get('user_email')}")
            return redirect(url_for('settings'))
        
        # Generate a secure state token
        state = secrets.token_urlsafe(16)
        session['oauth_state'] = state
        
        # Build the authorization URL
        auth_params = {
            'client_id': GOOGLE_CLIENT_ID,
            'redirect_uri': GOOGLE_REDIRECT_URI,
            'scope': 'openid email profile https://www.googleapis.com/auth/gmail.readonly',
            'access_type': 'offline',
            'response_type': 'code',
            'state': state,
            'prompt': 'consent'
        }
        
        auth_url = f"{GOOGLE_AUTH_URI}?" + '&'.join([f"{k}={v}" for k, v in auth_params.items()])
        logger.info("Starting OAuth flow with state: " + state)
        return redirect(auth_url)
    
    @app.route('/login/google/authorized')
    def authorized():
        # Verify state parameter to prevent CSRF
        state = request.args.get('state')
        stored_state = session.get('oauth_state')
        
        if not state or state != stored_state:
            logger.error(f"State mismatch: received {state}, expected {stored_state}")
            return redirect(url_for('index'))
        
        # Clear the state from session
        if 'oauth_state' in session:
            del session['oauth_state']
        
        # Exchange authorization code for tokens
        code = request.args.get('code')
        if not code:
            logger.error("No authorization code received")
            return redirect(url_for('index'))
        
        token_params = {
            'client_id': GOOGLE_CLIENT_ID,
            'client_secret': GOOGLE_CLIENT_SECRET,
            'code': code,
            'grant_type': 'authorization_code',
            'redirect_uri': GOOGLE_REDIRECT_URI
        }
        
        try:
            token_response = requests.post(GOOGLE_TOKEN_URI, data=token_params)
            token_data = token_response.json()
            
            if 'error' in token_data:
                logger.error(f"Error exchanging code for token: {token_data['error']}")
                return redirect(url_for('index'))
            
            # Store the token in session
            session['google_oauth_token'] = token_data
            
            # Get user info
            user_info_response = requests.get(
                'https://www.googleapis.com/oauth2/v3/userinfo',
                headers={'Authorization': f"Bearer {token_data['access_token']}"}
            )
            user_info = user_info_response.json()
            
            session['user_name'] = user_info.get('name', 'User')
            session['user_email'] = user_info.get('email', '')
            
            # Set default preferences
            if 'email_sync_frequency' not in session:
                session['email_sync_frequency'] = 24  # Default to daily
            if 'email_days_back' not in session:
                session['email_days_back'] = 30  # Default to 30 days
            if 'urgent_alerts_enabled' not in session:
                session['urgent_alerts_enabled'] = True  # Enable by default
            
            logger.info(f"User authenticated: {session['user_email']}")
            return redirect(url_for('settings'))
            
        except Exception as e:
            logger.error(f"Error in OAuth flow: {str(e)}")
            return redirect(url_for('index'))
    
    @app.route('/chat')
    def chat():
        if 'user_email' not in session:
            return redirect(url_for('login'))
        return render_template('chat.html', name=session.get('user_name', 'User'))
    
    @app.route('/settings')
    def settings():
        if 'user_email' not in session:
            return redirect(url_for('login'))
        
        # Check if Gmail is connected
        gmail_connected = 'google_oauth_token' in session
        
        # Get last sync time
        last_sync = session.get('last_email_sync', None)
        
        # Get sync status for the current user
        current_sync_status = None
        if sync_status.get('user_email') == session.get('user_email'):
            current_sync_status = {
                'is_syncing': sync_status.get('is_syncing', False),
                'progress': sync_status.get('progress', 0),
                'sync_type': sync_status.get('sync_type', '')
            }
        
        # Get user preferences
        email_sync_frequency = session.get('email_sync_frequency', 24)
        email_days_back = session.get('email_days_back', 30)
        urgent_alerts_enabled = session.get('urgent_alerts_enabled', True)
        
        return render_template('settings.html', 
                               name=session.get('user_name', 'User'),
                               email=session.get('user_email', ''),
                               gmail_connected=gmail_connected,
                               last_sync=last_sync,
                               sync_status=current_sync_status,
                               email_sync_frequency=email_sync_frequency,
                               email_days_back=email_days_back,
                               urgent_alerts_enabled=urgent_alerts_enabled)
    
    @app.route('/email-insights')
    def email_insights():
        if 'user_email' not in session:
            logger.warning("User not authenticated, redirecting to login")
            return redirect(url_for('login'))
        
        # Check if we need to sync first
        last_sync = session.get('last_email_sync')
        logger.info(f"Last sync from session: {last_sync}")
        if not last_sync:
            logger.warning("No last_sync in session, redirecting to settings")
            return redirect(url_for('settings'))
        
        # Get insights from sync_status if available for this user
        user_email = session.get('user_email')
        insights = None
        
        logger.info(f"sync_status keys: {list(sync_status.keys())}")
        logger.info(f"sync_status user_email: {sync_status.get('user_email')}, current user: {user_email}")
        logger.info(f"'email_insights' in sync_status: {'email_insights' in sync_status}")
        logger.info(f"'email_insights' in session: {'email_insights' in session}")
        
        if sync_status.get('user_email') == user_email and 'email_insights' in sync_status:
            insights = sync_status.get('email_insights')
            session['email_insights'] = insights
            logger.info(f"Using email insights from sync_status: {type(insights)}")
            if insights:
                logger.info(f"Insights keys: {list(insights.keys()) if isinstance(insights, dict) else 'not a dict'}")
        elif 'email_insights' in session:
            # Use insights from session if available
            insights = session['email_insights']
            logger.info(f"Using email insights from session: {type(insights)}")
            if insights:
                logger.info(f"Insights keys: {list(insights.keys()) if isinstance(insights, dict) else 'not a dict'}")
        else:
            # If no insights available, redirect to settings
            logger.warning("No insights available, redirecting to settings")
            return redirect(url_for('settings'))
        
        return render_template('email_insights.html', 
                               name=session.get('user_name', 'User'),
                               email=user_email,
                               insights=insights,
                               last_sync=last_sync)
    
    @app.route('/logout')
    def logout():
        session.clear()
        return redirect(url_for('index'))
    
    @app.route('/sync-emails', methods=['GET', 'POST'])
    def sync_emails():
        global sync_status
        logger.info(f"Sync emails route called with method: {request.method}")
        
        if 'user_email' not in session or 'google_oauth_token' not in session:
            logger.warning("User not authenticated, redirecting to login")
            return redirect(url_for('login'))
            
        user_email = session['user_email']
        access_token = session['google_oauth_token']['access_token']
        days_back = session.get('email_days_back', 30)
        
        logger.info(f"Starting email sync for {user_email} with {days_back} days back")
        
        # Initialize sync status
        sync_status['is_syncing'] = True
        sync_status['progress'] = 0
        sync_status['user_email'] = user_email
        sync_status['sync_type'] = 'Email Intelligence'
        
        # Copy session data to local variables before starting the thread
        # to avoid "working outside of request context" errors
        user_email_copy = user_email
        access_token_copy = access_token
        days_back_copy = days_back
        user_name_copy = session.get('user_name', 'User')
        
        # Start sync in background thread
        def run_sync():
            global sync_status
            try:
                logger.info("Starting email sync in background thread")
                
                # Initialize the EmailIntelligence module
                import sys
                import os
                # Add the project root to the Python path
                sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
                
                # Update progress
                sync_status['progress'] = 10
                logger.info(f"Sync progress: 10%")
                
                # Import the EmailIntelligence class
                from backend.core.claude_integration.email_intelligence import EmailIntelligence
                
                # Initialize email intelligence module
                email_intelligence = EmailIntelligence(claude_client)
                sync_status['progress'] = 30
                logger.info(f"Sync progress: 30%")
                
                # Simulate progress updates
                for i in range(4, 8):
                    time.sleep(1)  # Simulate work
                    sync_status['progress'] = i * 10
                    logger.info(f"Sync progress: {i * 10}%")
                
                # Analyze emails using the native Gmail API via GmailConnector
                logger.info(f"Using access token of length: {len(access_token_copy) if access_token_copy else 'None'} to fetch emails")
                
                # Validate token format
                if access_token_copy and len(access_token_copy) > 20:  # Simple validation that token exists and has reasonable length
                    logger.info("Access token validation passed, proceeding with email analysis")
                    insights = email_intelligence.analyze_recent_emails(user_email_copy, access_token_copy, days_back=days_back_copy)
                else:
                    logger.error(f"Invalid access token format for {user_email_copy}")
                    insights = {
                        "status": "error",
                        "message": "Invalid or missing access token. Please re-authenticate with Gmail."
                    }
                
                sync_status['progress'] = 80
                logger.info(f"Sync progress: 80%")
                
                # Log the insights structure
                logger.info(f"Insights type: {type(insights)}")
                if isinstance(insights, dict):
                    logger.info(f"Insights keys: {list(insights.keys())}")
                    
                    # Make sure insights has a status field
                    if 'status' not in insights:
                        insights['status'] = 'success'
                    
                    # Store real insights in sync_status
                    sync_status['email_insights'] = insights
                    sync_status['last_sync'] = datetime.now().strftime("%Y-%m-%d %H:%M")
                    sync_status['progress'] = 100
                    
                    # Also update session directly
                    try:
                        with app.app_context():
                            from flask import session as flask_session
                            flask_session['email_insights'] = insights
                            flask_session['last_email_sync'] = sync_status['last_sync']
                            logger.info("Updated session with insights data")
                    except Exception as session_err:
                        logger.error(f"Could not update session from thread: {str(session_err)}")
                    
                    logger.info("Email sync completed successfully with real data")
                else:
                    logger.error(f"Invalid insights format: {insights}")
                    sync_status['status'] = 'failed'
                    sync_status['email_insights'] = {'status': 'success', 'message': 'No emails found in the specified time period'}
            
            except Exception as e:
                logger.error(f"Error in background sync thread: {str(e)}")
                sync_status['status'] = 'failed'
                sync_status['email_insights'] = {'status': 'failed', 'message': f'Error: {str(e)}'}
            finally:
                # Always mark sync as complete in finally block
                sync_status['is_syncing'] = False
            
        # Start sync thread
        sync_thread = threading.Thread(target=run_sync)
        sync_thread.daemon = True
        sync_thread.start()
        logger.info("Sync thread started successfully")
            
        # Redirect to sync progress page
        return render_template('sync_in_progress.html',
                             name=session.get('user_name', 'User'),
                             sync_type='Email Intelligence',
                             progress=0)
    
    @app.route('/get-sync-status')
    def get_sync_status():
        if 'user_email' not in session:
            return redirect(url_for('login'))
                
        # Only return sync status for the current user
        if sync_status.get('user_email') == session.get('user_email'):
            return jsonify({
                'is_syncing': sync_status.get('is_syncing', False),
                'progress': sync_status.get('progress', 0),
                'sync_type': sync_status.get('sync_type', '')
            })
        else:
            return jsonify({
                'is_syncing': False,
                'progress': 0,
                'sync_type': ''
            })
    
    @app.route('/save-preferences', methods=['POST'])
    def save_preferences():
        if 'user_email' not in session:
            return jsonify({'success': False, 'error': 'Not authenticated'}), 401
                
        try:
            data = request.get_json()
                
            # Update session with new preferences
            session['email_sync_frequency'] = int(data.get('email_sync_frequency', 24))
            session['email_days_back'] = int(data.get('email_days_back', 30))
            session['urgent_alerts_enabled'] = bool(data.get('urgent_alerts_enabled', True))
                
            return jsonify({'success': True})
        except Exception as e:
            logger.error(f"Error saving preferences: {str(e)}")
            return jsonify({'success': False, 'error': str(e)}), 500
                
    @app.route('/disconnect-gmail')
    def disconnect_gmail():
        if 'google_oauth_token' in session:
            del session['google_oauth_token']
        if 'last_email_sync' in session:
            del session['last_email_sync']
                
        # Redirect to settings page
        return redirect(url_for('settings'))
            
    @app.route('/api/sync-status')
    def api_sync_status():
        global sync_status
            
        if 'user_email' not in session:
            logger.warning("User not authenticated in api_sync_status")
            return jsonify({'error': 'Not authenticated'}), 401
                
        current_user = session.get('user_email')
        logger.info(f"api_sync_status called for user: {current_user}")
        logger.info(f"sync_status user_email: {sync_status.get('user_email')}")
        logger.info(f"sync_status progress: {sync_status.get('progress')}")
        logger.info(f"sync_status is_syncing: {sync_status.get('is_syncing')}")
            
        # Only return sync status for the current user
        if sync_status.get('user_email') == current_user:
            # If sync is complete, update session with insights
            if not sync_status.get('is_syncing') and sync_status.get('progress') == 100:
                insights = sync_status.get('email_insights')
                if insights:
                    logger.info(f"Updating session with insights of type: {type(insights)}")
                    if isinstance(insights, dict):
                        logger.info(f"Insights keys: {list(insights.keys())}")
                    session['email_insights'] = insights
                    session['last_email_sync'] = sync_status.get('last_sync', datetime.now().strftime("%Y-%m-%d %H:%M"))
                    logger.info(f"Session updated with insights and last_sync: {session['last_email_sync']}")
                else:
                    logger.warning("No insights found in sync_status to update session")
            
            return jsonify({
                'is_syncing': sync_status.get('is_syncing', False),
                'progress': sync_status.get('progress', 0),
                'sync_type': sync_status.get('sync_type', ''),
                'redirect': '/email-insights' if not sync_status.get('is_syncing') and sync_status.get('progress') == 100 else None
            })
        else:
            # No sync status for this user
            logger.warning(f"No sync status for user {current_user}")
            return jsonify({
                'is_syncing': False,
                'progress': 0,
                'sync_type': '',
                'redirect': '/settings'
            })
            
    @app.route('/api/email-insights')
    def api_email_insights():
        if 'user_email' not in session:
            return jsonify({'error': 'Not authenticated'}), 401
                
        # Check if we need to sync first
        last_sync = session.get('last_email_sync')
        if not last_sync:
            return jsonify({
                'status': 'no_data',
                'message': 'No email insights available yet. Please sync your emails first.'
            })
            
        # Get insights from session
        insights = session.get('email_insights', {})
            
        # Add last sync time to the response
        insights['last_sync'] = last_sync
        insights['status'] = 'success'
            
        return jsonify(insights)
    
    return app

if __name__ == '__main__':
    app = create_app()
    app.run(host='0.0.0.0', port=8080, debug=True)



================================================
FILE: personal-ai-assistant/backend/api/__init__.py
================================================



================================================
FILE: personal-ai-assistant/backend/api/email_intelligence.py
================================================
"""
API routes for email intelligence.
"""

import logging
from typing import Dict, List, Any, Optional
from fastapi import APIRouter, Depends, HTTPException, BackgroundTasks
from sqlalchemy.orm import Session

from backend.models.database.database import get_db
from backend.services.email_intelligence_service import EmailIntelligenceService
from backend.core.claude_integration.claude_client import ClaudeClient
from backend.api.auth import get_current_user

# Create router
router = APIRouter(
    prefix="/api/email-intelligence",
    tags=["email-intelligence"],
    responses={404: {"description": "Not found"}},
)

logger = logging.getLogger(__name__)

# Helper function to get email intelligence service
def get_email_intelligence_service(
    db: Session = Depends(get_db),
    claude_client: ClaudeClient = Depends(lambda: ClaudeClient)
) -> EmailIntelligenceService:
    return EmailIntelligenceService(db, claude_client)


@router.post("/business-intelligence-sync")
async def run_business_intelligence_sync(
    background_tasks: BackgroundTasks,
    days_back: int = 30,
    service: EmailIntelligenceService = Depends(get_email_intelligence_service),
    current_user: Dict[str, Any] = Depends(get_current_user)
):
    """
    Run business intelligence sync to analyze emails from the last N days.
    This is a long-running task, so it runs in the background.
    """
    user_email = current_user["email"]
    
    # Run in background task
    background_tasks.add_task(
        service.run_business_intelligence_sync,
        user_email=user_email,
        days_back=days_back
    )
    
    return {
        "status": "processing",
        "message": f"Business intelligence sync started for the last {days_back} days"
    }


@router.post("/scan-urgent-emails")
async def scan_urgent_emails(
    background_tasks: BackgroundTasks,
    hours_back: int = 24,
    service: EmailIntelligenceService = Depends(get_email_intelligence_service),
    current_user: Dict[str, Any] = Depends(get_current_user)
):
    """
    Scan for urgent emails from the last N hours.
    This is a long-running task, so it runs in the background.
    """
    user_email = current_user["email"]
    
    # Run in background task
    background_tasks.add_task(
        service.scan_for_urgent_emails,
        user_email=user_email,
        hours_back=hours_back
    )
    
    return {
        "status": "processing",
        "message": f"Urgent email scan started for the last {hours_back} hours"
    }


@router.post("/update-person-profile/{contact_email}")
async def update_person_profile(
    contact_email: str,
    background_tasks: BackgroundTasks,
    service: EmailIntelligenceService = Depends(get_email_intelligence_service),
    current_user: Dict[str, Any] = Depends(get_current_user)
):
    """
    Update the profile for a specific person.
    This is a long-running task, so it runs in the background.
    """
    user_email = current_user["email"]
    
    # Run in background task
    background_tasks.add_task(
        service.update_person_profile,
        user_email=user_email,
        contact_email=contact_email
    )
    
    return {
        "status": "processing",
        "message": f"Person profile update started for {contact_email}"
    }


@router.post("/update-key-contacts")
async def update_key_contacts(
    background_tasks: BackgroundTasks,
    service: EmailIntelligenceService = Depends(get_email_intelligence_service),
    current_user: Dict[str, Any] = Depends(get_current_user)
):
    """
    Identify and update profiles for key contacts.
    This is a long-running task, so it runs in the background.
    """
    user_email = current_user["email"]
    
    # Run in background task
    background_tasks.add_task(
        service.update_key_contacts,
        user_email=user_email
    )
    
    return {
        "status": "processing",
        "message": "Key contacts update started"
    }


@router.get("/business-intelligence")
async def get_latest_business_intelligence(
    service: EmailIntelligenceService = Depends(get_email_intelligence_service),
    current_user: Dict[str, Any] = Depends(get_current_user)
):
    """
    Get the latest business intelligence for the current user.
    """
    user_email = current_user["email"]
    result = service.get_latest_business_intelligence(user_email)
    
    if result["status"] == "not_found":
        raise HTTPException(status_code=404, detail="No business intelligence found")
    elif result["status"] == "error":
        raise HTTPException(status_code=500, detail=result["message"])
    
    return result


@router.get("/urgent-alerts")
async def get_pending_urgent_alerts(
    service: EmailIntelligenceService = Depends(get_email_intelligence_service),
    current_user: Dict[str, Any] = Depends(get_current_user)
):
    """
    Get pending urgent email alerts for the current user.
    """
    user_email = current_user["email"]
    alerts = service.get_pending_urgent_alerts(user_email)
    return {"alerts": alerts, "count": len(alerts)}


@router.post("/mark-alert-read/{alert_id}")
async def mark_alert_as_read(
    alert_id: int,
    service: EmailIntelligenceService = Depends(get_email_intelligence_service),
    current_user: Dict[str, Any] = Depends(get_current_user)
):
    """
    Mark an urgent email alert as read.
    """
    result = service.mark_alert_as_read(alert_id)
    
    if result["status"] == "not_found":
        raise HTTPException(status_code=404, detail="Alert not found")
    elif result["status"] == "error":
        raise HTTPException(status_code=500, detail=result["message"])
    
    return result


@router.get("/person-profile/{contact_email}")
async def get_person_profile(
    contact_email: str,
    service: EmailIntelligenceService = Depends(get_email_intelligence_service),
    current_user: Dict[str, Any] = Depends(get_current_user)
):
    """
    Get the profile for a specific person.
    """
    user_email = current_user["email"]
    result = service.get_person_profile(user_email, contact_email)
    
    if result["status"] == "not_found":
        raise HTTPException(status_code=404, detail="Person profile not found")
    elif result["status"] == "error":
        raise HTTPException(status_code=500, detail=result["message"])
    
    return result



================================================
FILE: personal-ai-assistant/backend/api/middleware/__init__.py
================================================



================================================
FILE: personal-ai-assistant/backend/api/routes/__init__.py
================================================



================================================
FILE: personal-ai-assistant/backend/config/settings.py
================================================
import os
from datetime import timedelta

class Config:
    SECRET_KEY = os.getenv('SECRET_KEY', 'dev-key-change-in-production')
    DATABASE_URL = os.getenv('DATABASE_URL', 'sqlite:///app.db')
    
    # Session configuration
    SESSION_TYPE = 'filesystem'
    SESSION_PERMANENT = False
    PERMANENT_SESSION_LIFETIME = timedelta(days=1)
    
    # Claude API
    ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')
    
    # Google OAuth
    GOOGLE_CLIENT_ID = os.getenv('GOOGLE_CLIENT_ID')
    GOOGLE_CLIENT_SECRET = os.getenv('GOOGLE_CLIENT_SECRET')
    
    # User data directory
    USER_DATA_DIR = os.getenv('USER_DATA_DIR', 'user_data')

class DevelopmentConfig(Config):
    DEBUG = True
    FLASK_ENV = 'development'

class ProductionConfig(Config):
    DEBUG = False
    FLASK_ENV = 'production'



================================================
FILE: personal-ai-assistant/backend/core/__init__.py
================================================



================================================
FILE: personal-ai-assistant/backend/core/claude_integration/__init__.py
================================================



================================================
FILE: personal-ai-assistant/backend/core/claude_integration/claude_client.py
================================================
import anthropic
from typing import Dict, Optional
import os

class ClaudeClient:
    def __init__(self, api_key: str):
        if not api_key:
            raise ValueError("ANTHROPIC_API_KEY is required")
        
        self.client = anthropic.Anthropic(api_key=api_key)
        self.conversation_history = {}  # Store by user_email
        self.max_history = 20  # Keep last 20 messages per user
    
    def send_message(self, user_email: str, message: str) -> str:
        """Send message to Claude with user context"""
        
        # Initialize conversation history for new users
        if user_email not in self.conversation_history:
            self.conversation_history[user_email] = []
        
        # Build system prompt with user context
        system_prompt = f"""You are a personalized AI assistant for {user_email}.

You have access to their:
- Gmail (use your native Gmail integration when they ask about emails)
- Google Calendar (use your native Calendar integration for scheduling questions)
- ClickUp tasks and projects (coming soon)

When users ask about:
- Emails: Use your Gmail integration to check their actual emails
- Calendar/Schedule: Use your Calendar integration to check their actual events  
- General questions: Provide helpful, conversational responses

Be conversational, helpful, and proactive. You can access their real data when relevant.
"""
        
        # Add user message to history
        self.conversation_history[user_email].append({
            "role": "user", 
            "content": message
        })
        
        try:
            # Send to Claude
            response = self.client.messages.create(
                model="claude-3-sonnet-20240229",
                max_tokens=4000,
                system=system_prompt,
                messages=self.conversation_history[user_email]
            )
            
            assistant_response = response.content[0].text
            
            # Add response to history
            self.conversation_history[user_email].append({
                "role": "assistant",
                "content": assistant_response
            })
            
            # Trim history if too long
            if len(self.conversation_history[user_email]) > self.max_history:
                self.conversation_history[user_email] = self.conversation_history[user_email][-self.max_history:]
            
            return assistant_response
            
        except Exception as e:
            return f"I'm having trouble connecting right now. Error: {str(e)}"
    
    def clear_history(self, user_email: str):
        """Clear conversation history for a user"""
        if user_email in self.conversation_history:
            del self.conversation_history[user_email]
EOF


================================================
FILE: personal-ai-assistant/backend/core/claude_integration/email_intelligence.py
================================================
"""
Email Intelligence Module using Claude for email analysis with data from GmailConnector.

This module provides functionality for:
1. Business Intelligence Sync - Analyzing emails from the last 30 days
2. Real-time Alert System - Scanning recent emails for urgent items
3. People Intelligence - Building profiles based on email interactions
"""

import json
import logging
import traceback
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple

from backend.integrations.gmail.gmail_connector import GmailConnector
import anthropic
from anthropic.types import ContentBlockDeltaEvent
import os

logger = logging.getLogger(__name__)

class EmailIntelligence:
    def __init__(self, claude_client):
        """
        Initialize the Email Intelligence module with a Claude client.
        
        Args:
            claude_client: An instance of the Claude client with API access
        """
        self.claude_client = claude_client
    
    def analyze_recent_emails(self, user_email: str, access_token: str = None, days_back: int = 30, previous_insights: Dict[str, Any] = None, structured_knowledge: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        Analyze emails from the last N days to extract business intelligence using multiple targeted prompts.
        Uses the Gmail API to fetch real emails via GmailConnector.
        
        Args:
            user_email: The email of the user whose emails to analyze
            access_token: OAuth access token for Gmail API
            days_back: Number of days back to analyze (default: 30)
            previous_insights: Previously generated insights to build upon (default: None)
            
        Returns:
            Dict containing analysis results with key insights from multiple specialized prompts
        """
        logger.info(f"Analyzing emails from last {days_back} days for {user_email}")
        analysis_type = "incremental" if previous_insights else "full"
        logger.info(f"Performing {analysis_type} analysis")
        
        try:
            # Validate we have an access token
            if not access_token:
                logger.error(f"No access token provided for {user_email}")
                return {
                    "status": "error",
                    "message": "No access token provided for Gmail API",
                    "key_relationships": [],
                    "active_projects": [],
                    "communication_patterns": {},
                    "action_items": [],
                    "important_information": []
                }
                
            # Initialize Gmail connector with the access token
            gmail = GmailConnector(access_token)
            
            # Test the connection
            if not gmail.test_connection():
                logger.error(f"Failed to connect to Gmail API for {user_email}")
                return {
                    "status": "error",
                    "message": "Failed to connect to Gmail API",
                    "key_relationships": [],
                    "active_projects": [],
                    "communication_patterns": {},
                    "action_items": [],
                    "important_information": []
                }
            
            # Fetch real emails using the Gmail API
            logger.info(f"Fetching emails from Gmail API for {user_email}")
            email_summaries = gmail.get_recent_emails(days_back=days_back, max_results=50)  # Reduced from 100 to 50
            
            if not email_summaries:
                logger.warning(f"No emails found for {user_email} in the last {days_back} days")
            else:
                logger.info(f"Successfully fetched {len(email_summaries)} emails for {user_email}")
                
                # Truncate email bodies to avoid token limit
                for email in email_summaries:
                    if 'body' in email and len(email['body']) > 1000:
                        email['body'] = email['body'][:1000] + "... [truncated]"
                    
                    # Also limit subject and sender info
                    if 'subject' in email and len(email['subject']) > 200:
                        email['subject'] = email['subject'][:200] + "..."
            
            # Create combined results dictionary
            combined_results = {
                "status": "success",
                "message": "Analysis completed successfully"
            }
            
            # Log structured knowledge if available
            if structured_knowledge:
                projects_count = len(structured_knowledge.get('projects', []))
                goals_count = len(structured_knowledge.get('goals', []))
                knowledge_files_count = len(structured_knowledge.get('knowledge_files', []))
                logger.info(f"Using structured knowledge: {projects_count} projects, {goals_count} goals, {knowledge_files_count} knowledge files")
            
            # Get relationships analysis
            relationships_prompt = self._create_relationships_prompt(user_email, email_summaries, previous_insights, structured_knowledge)
            relationships_response = self._get_structured_response(user_email, relationships_prompt, "key_relationships", days_back)
            combined_results["key_relationships"] = relationships_response.get("key_relationships", [])
            
            # Get projects analysis
            projects_prompt = self._create_projects_prompt(user_email, email_summaries, previous_insights, structured_knowledge)
            projects_response = self._get_structured_response(user_email, projects_prompt, "active_projects", days_back)
            combined_results["active_projects"] = projects_response.get("active_projects", [])
            
            # Get communication patterns analysis
            patterns_prompt = self._create_patterns_prompt(user_email, email_summaries, previous_insights, structured_knowledge)
            patterns_response = self._get_structured_response(user_email, patterns_prompt, "communication_patterns", days_back)
            combined_results["communication_patterns"] = patterns_response.get("communication_patterns", {})
            
            # Get action items analysis
            actions_prompt = self._create_actions_prompt(user_email, email_summaries, previous_insights, structured_knowledge)
            actions_response = self._get_structured_response(user_email, actions_prompt, "action_items", days_back)
            combined_results["action_items"] = actions_response.get("action_items", [])
            
            # Get important information analysis
            info_prompt = self._create_info_prompt(user_email, email_summaries, previous_insights, structured_knowledge)
            info_response = self._get_structured_response(user_email, info_prompt, "important_information", days_back)
            combined_results["important_information"] = info_response.get("important_information", [])
            
            logger.info(f"Successfully analyzed emails for {user_email} using multiple targeted prompts")
            return combined_results
            
        except Exception as e:
            logger.error(f"Error analyzing emails for {user_email}: {str(e)}")
            return {
                "status": "error",
                "message": f"Error analyzing emails: {str(e)}",
                "key_relationships": [],
                "active_projects": [],
                "communication_patterns": {},
                "action_items": [],
                "important_information": []
            }
    
    def _create_relationships_prompt(self, user_email: str, email_summaries: List[Dict], previous_insights: Dict[str, Any] = None, structured_knowledge: Dict[str, Any] = None) -> str:
        """Create a prompt for analyzing key relationships from emails."""
        # Create a more concise summary focusing on sender information
        concise_summaries = []
        for email in email_summaries[:30]:  # Limit to 30 most recent emails
            concise_summaries.append({
                'sender': email.get('sender', 'Unknown'),
                'subject': email.get('subject', '')[:100],  # Limit subject length
                'date': email.get('date', ''),
                'snippet': email.get('body', '')[:200] if 'body' in email else ''  # Use snippet instead of full body
            })
        
        # Include previous relationships if available
        previous_relationships_text = ""
        if previous_insights and 'key_relationships' in previous_insights and previous_insights['key_relationships']:
            previous_relationships_text = f"""
            IMPORTANT: Here are the key relationships identified from previous email analysis. 
            Build upon and update this information with the new email data:
            {json.dumps(previous_insights['key_relationships'], indent=2)}
            """
        
        # Include structured knowledge about projects and goals if available
        structured_knowledge_text = ""
        if structured_knowledge:
            projects = structured_knowledge.get('projects', [])
            goals = structured_knowledge.get('goals', [])
            
            if projects or goals:
                structured_knowledge_text = "IMPORTANT: Consider the following user-defined projects and goals when analyzing relationships:\n"
                
                if projects:
                    structured_knowledge_text += "\nProjects:\n"
                    for project in projects:
                        structured_knowledge_text += f"- {project.get('name')}: {project.get('description')}\n"
                        if project.get('stakeholders'):
                            structured_knowledge_text += f"  Stakeholders: {', '.join(project.get('stakeholders'))}\n"
                
                if goals:
                    structured_knowledge_text += "\nGoals:\n"
                    for goal in goals:
                        structured_knowledge_text += f"- {goal.get('title')}: {goal.get('description')}\n"
        
        return f"""
        Analyze the following email summaries from {user_email} to identify key relationships.
        
        {previous_relationships_text}
        
        {structured_knowledge_text}
        
        Email data (showing sender, subject, date, and brief snippet):
        {json.dumps(concise_summaries, indent=2)}
        
        Provide a comprehensive analysis of key relationships in JSON format with the following structure:
        {{
            "key_relationships": [
                {{
                    "name": "Person's Name",
                    "email": "person@example.com",
                    "role": "Their professional role or relationship",
                    "importance": "High/Medium/Low",
                    "recent_interactions": "Brief summary of recent interactions",
                    "action_needed": "Any follow-up needed (or null if none)"
                }}
            ]
        }}
        
        Include at least 5-10 key relationships if they exist in the data, ordered by importance.
        If a person appears in both the previous relationships and the new emails, merge the information to create a more complete profile that builds upon the existing knowledge.
        """
    
    def _create_projects_prompt(self, user_email: str, email_summaries: List[Dict], previous_insights: Dict[str, Any] = None, structured_knowledge: Dict[str, Any] = None) -> str:
        """Create a prompt for analyzing active projects from emails."""
        # Create a more concise summary focusing on project-related information
        concise_summaries = []
        for email in email_summaries[:30]:  # Limit to 30 most recent emails
            concise_summaries.append({
                'sender': email.get('sender', 'Unknown'),
                'subject': email.get('subject', '')[:100],  # Limit subject length
                'date': email.get('date', ''),
                'snippet': email.get('body', '')[:200] if 'body' in email else ''  # Use snippet instead of full body
            })
        
        # Include previous projects if available
        previous_projects_text = ""
        if previous_insights and 'active_projects' in previous_insights and previous_insights['active_projects']:
            previous_projects_text = f"""
            IMPORTANT: Here are the active projects identified from previous email analysis. 
            Build upon and update this information with the new email data, tracking progress and changes in status:
            {json.dumps(previous_insights['active_projects'], indent=2)}
            """
        
        # Include structured knowledge about projects if available
        structured_knowledge_text = ""
        if structured_knowledge:
            projects = structured_knowledge.get('projects', [])
            goals = structured_knowledge.get('goals', [])
            knowledge_files = structured_knowledge.get('knowledge_files', [])
            
            if projects:
                structured_knowledge_text += "\nIMPORTANT: The user has manually defined the following projects. Use this information as a foundation and update with any new details from emails:\n"
                for project in projects:
                    structured_knowledge_text += f"\n- Project: {project.get('name')}\n"
                    structured_knowledge_text += f"  Description: {project.get('description')}\n"
                    structured_knowledge_text += f"  Status: {project.get('status')}\n"
                    structured_knowledge_text += f"  Priority: {project.get('priority')}\n"
                    if project.get('stakeholders'):
                        structured_knowledge_text += f"  Stakeholders: {', '.join(project.get('stakeholders'))}\n"
                    if project.get('keywords'):
                        structured_knowledge_text += f"  Keywords: {', '.join(project.get('keywords'))}\n"
        
            if goals:
                structured_knowledge_text += "\nIMPORTANT: Consider these user goals when analyzing projects:\n"
                for goal in goals:
                    structured_knowledge_text += f"- {goal.get('title')}: {goal.get('description')}\n"
        
        return f"""
        Analyze the following email summaries from {user_email} to identify active projects and initiatives.
        
        {previous_projects_text}
        
        {structured_knowledge_text}
        
        Email data:
        {json.dumps(concise_summaries, indent=2)}
        
        Provide a comprehensive analysis of active projects in JSON format with the following structure:
        {{
            "active_projects": [
                {{
                    "name": "Project Name",
                    "description": "Brief description of the project",
                    "status": "Current status (e.g., In Progress, Planning, Completed)",
                    "key_stakeholders": ["Person1", "Person2"],
                    "priority": "High/Medium/Low",
                    "next_steps": "Upcoming actions or milestones"
                }}
            ]
        }}
        
        Include at least 3-7 active projects if they exist in the data, ordered by priority.
        If a project appears in both the previous projects and the new emails, merge the information to create a more complete profile, updating status and progress based on the new information.
        Track how projects evolve over time, noting any changes in status, priority, or stakeholders.
        """
    
    def _create_patterns_prompt(self, user_email: str, email_summaries: List[Dict], previous_insights: Dict[str, Any] = None, structured_knowledge: Dict[str, Any] = None) -> str:
        """Create a prompt for analyzing communication patterns from emails."""
        # Create concise summaries for pattern analysis
        concise_summaries = []
        for email in email_summaries[:30]:  # Limit to 30 most recent emails
            concise_summaries.append({
                'sender': email.get('sender', 'Unknown'),
                'date': email.get('date', ''),
                'subject': email.get('subject', '')[:100],
                'is_unread': email.get('is_unread', False)
            })
        
        # Include previous patterns if available
        previous_patterns_text = ""
        if previous_insights and 'communication_patterns' in previous_insights and previous_insights['communication_patterns']:
            previous_patterns_text = f"""
            IMPORTANT: Here are the communication patterns identified from previous email analysis. 
            Build upon and update this information with the new email data:
            {json.dumps(previous_insights['communication_patterns'], indent=2)}
            """
        
        # Include structured knowledge about relationships and projects if available
        structured_knowledge_text = ""
        if structured_knowledge:
            projects = structured_knowledge.get('projects', [])
            
            if projects:
                structured_knowledge_text += "\nIMPORTANT: Consider these user-defined projects when analyzing communication patterns:\n"
                for project in projects:
                    if project.get('stakeholders'):
                        structured_knowledge_text += f"- Project '{project.get('name')}' involves stakeholders: {', '.join(project.get('stakeholders'))}\n"
        
        return f"""
        Analyze the following email summaries from {user_email} to identify communication patterns and preferences.
        
        {previous_patterns_text}
        
        {structured_knowledge_text}
        
        Email data:
        {json.dumps(concise_summaries, indent=2)}
        
        Provide a comprehensive analysis of communication patterns in JSON format with the following structure:
        {{
            "communication_patterns": {{
                "most_frequent_contacts": [
                    {{
                        "name": "Contact Name",
                        "email": "contact@example.com",
                        "frequency": "Number of interactions"
                    }}
                ],
                "busiest_times": {{
                    "days_of_week": ["Monday", "Thursday"],
                    "times_of_day": ["Morning", "Evening"]
                }},
                "response_patterns": {{
                    "average_response_time": "X hours/days",
                    "most_responsive_to": ["Person1", "Person2"],
                    "least_responsive_to": ["Person3", "Person4"]
                }},
                "communication_style": {{
                    "email_length": "Short/Medium/Long",
                    "formality_level": "Formal/Casual/Mixed",
                    "common_phrases": ["Phrase1", "Phrase2"]
                }}
            }}
        }}
        
        If there are patterns in both the previous analysis and the new emails, merge the information to create a more comprehensive understanding of communication habits over time.
        """
    
    def _create_actions_prompt(self, user_email: str, email_summaries: List[Dict], previous_insights: Dict[str, Any] = None, structured_knowledge: Dict[str, Any] = None) -> str:
        """Create a prompt for identifying action items from emails."""
        # Create concise summaries focusing on actionable content
        concise_summaries = []
        for email in email_summaries[:30]:  # Limit to 30 most recent emails
            concise_summaries.append({
                'subject': email.get('subject', '')[:100],
                'sender': email.get('sender', 'Unknown'),
                'date': email.get('date', ''),
                'snippet': email.get('body', '')[:300] if 'body' in email else ''  # Slightly longer for action items
            })
        
        # Include previous action items if available
        previous_actions_text = ""
        if previous_insights and 'action_items' in previous_insights and previous_insights['action_items']:
            previous_actions_text = f"""
            IMPORTANT: Here are the action items identified from previous email analysis. 
            Build upon this list, remove completed items, and add new items from the recent emails:
            {json.dumps(previous_insights['action_items'], indent=2)}
            """
        
        # Include structured knowledge about projects and goals if available
        structured_knowledge_text = ""
        if structured_knowledge:
            projects = structured_knowledge.get('projects', [])
            goals = structured_knowledge.get('goals', [])
            
            if projects or goals:
                structured_knowledge_text += "\nIMPORTANT: Consider these user-defined projects and goals when identifying action items:\n"
                
                if projects:
                    structured_knowledge_text += "\nProjects:\n"
                    for project in projects:
                        structured_knowledge_text += f"- {project.get('name')}: {project.get('description')}\n"
                        structured_knowledge_text += f"  Status: {project.get('status')}, Priority: {project.get('priority')}\n"
                
                if goals:
                    structured_knowledge_text += "\nGoals:\n"
                    for goal in goals:
                        structured_knowledge_text += f"- {goal.get('title')}: {goal.get('description')}\n"
                        if goal.get('timeframe'):
                            structured_knowledge_text += f"  Timeframe: {goal.get('timeframe')}\n"
                        if goal.get('success_metrics'):
                            structured_knowledge_text += f"  Success metrics: {goal.get('success_metrics')}\n"
        
        return f"""
        Analyze the following email summaries from {user_email} to identify action items and follow-ups needed.
        
        {previous_actions_text}
        
        {structured_knowledge_text}
        
        Email data:
        {json.dumps(email_summaries, indent=2)}
        
        Provide a comprehensive list of action items in JSON format with the following structure:
        {{
            "action_items": [
                {{
                    "description": "Brief description of the action item",
                    "due_date": "Due date if specified (or null)",
                    "priority": "High/Medium/Low",
                    "related_to": "Person or project related to this action",
                    "status": "Pending/In Progress/Completed"
                }}
            ]
        }}
        
        Include only clear action items where I need to take action. Prioritize recent and urgent items.
        For action items that appear in both the previous list and the new emails, update their status and details based on the latest information.
        """
    
    def _create_info_prompt(self, user_email: str, email_summaries: List[Dict], previous_insights: Dict[str, Any] = None, structured_knowledge: Dict[str, Any] = None) -> str:
        """Create a prompt for extracting important information from emails."""
        # Create concise summaries for important information
        concise_summaries = []
        for email in email_summaries[:30]:  # Limit to 30 most recent emails
            concise_summaries.append({
                'subject': email.get('subject', '')[:100],
                'sender': email.get('sender', 'Unknown'),
                'date': email.get('date', ''),
                'snippet': email.get('body', '')[:300] if 'body' in email else ''
            })
        
        # Include previous important information if available
        previous_info_text = ""
        if previous_insights and 'important_information' in previous_insights and previous_insights['important_information']:
            previous_info_text = f"""
            IMPORTANT: Here is important information identified from previous email analysis. 
            Build upon this information with the new email data:
            {json.dumps(previous_insights['important_information'], indent=2)}
            """
        
        # Include structured knowledge files if available
        structured_knowledge_text = ""
        if structured_knowledge:
            projects = structured_knowledge.get('projects', [])
            goals = structured_knowledge.get('goals', [])
            knowledge_files = structured_knowledge.get('knowledge_files', [])
            
            if knowledge_files:
                structured_knowledge_text += "\nIMPORTANT: Consider these knowledge documents when identifying important information:\n"
                for file in knowledge_files:
                    structured_knowledge_text += f"\n- Document: {file.get('filename')}\n"
                    structured_knowledge_text += f"  Category: {file.get('category')}\n"
                    structured_knowledge_text += f"  Description: {file.get('description')}\n"
                    if file.get('content'):
                        content_excerpt = file.get('content')[:500] + "..." if len(file.get('content')) > 500 else file.get('content')
                        structured_knowledge_text += f"  Content excerpt: {content_excerpt}\n"
        
            if projects:
                structured_knowledge_text += "\nRelevant projects:\n"
                for project in projects:
                    structured_knowledge_text += f"- {project.get('name')}: {project.get('description')}\n"
        
            if goals:
                structured_knowledge_text += "\nRelevant goals:\n"
                for goal in goals:
                    structured_knowledge_text += f"- {goal.get('title')}: {goal.get('description')}\n"
        
        return f"""
        Analyze the following email summaries from {user_email} to identify important information, facts, and insights.
        
        {previous_info_text}
        
        {structured_knowledge_text}
        
        Email data:
        {json.dumps(email_summaries, indent=2)}
        
        Provide a comprehensive list of important information in JSON format with the following structure:
        {{
            "important_information": [
                {{
                    "topic": "Brief topic or category",
                    "details": "Detailed information",
                    "source": "Person or organization this came from",
                    "date_received": "When this information was received",
                    "relevance": "Why this information is important"
                }}
            ]
        }}
        
        Focus on extracting key facts, announcements, decisions, or other noteworthy information.
        If a topic appears in both the previous information and the new emails, merge the details to create a more complete understanding of that topic.
        """
    
    def _get_structured_response(self, user_email: str, prompt: str, expected_key: str = None, days_back: int = 30) -> Dict[str, Any]:
        """Get a structured response from Claude based on the provided prompt.
        
        Args:
            user_email: The email of the user for context
            prompt: The prompt to send to Claude
            expected_key: The expected key in the response JSON
            days_back: Number of days back to analyze
            
        Returns:
            Dict containing the structured response from Claude
        """
        try:
            # Add system instruction to format response as JSON
            system_prompt = f"""You are an expert email analyst for {user_email}.
            
            Analyze the email data provided in the prompt to extract insights.
            Focus on emails from the past {days_back} days when available.
            
            Always respond with well-structured JSON data as requested in the prompt.
            Do not include any explanatory text outside the JSON structure.
            """
            
            # Send to Claude
            try:
                # Try the new Anthropic SDK interface
                response = self.claude_client.messages.create(
                    model="claude-3-opus-20240229",
                    max_tokens=4000,
                    temperature=0.2,
                    system=system_prompt,
                    messages=[{"role": "user", "content": prompt}]
                )
                assistant_response = response.content[0].text
            except AttributeError:
                # Fallback for older SDK versions
                logger.info("Using fallback Claude client interface")
                response = self.claude_client.completions.create(
                    model="claude-3-opus-20240229",
                    max_tokens=4000,
                    temperature=0.2,
                    system=system_prompt,
                    prompt=prompt
                )
                assistant_response = response.completion
            
            # Try to parse the response as JSON
            try:
                # Clean the response - remove markdown code blocks if present
                if assistant_response.startswith("```json"):
                    assistant_response = assistant_response.strip("```json").strip("```").strip()
                elif assistant_response.startswith("```"):
                    assistant_response = assistant_response.strip("```").strip()
                
                # Try to extract JSON from the response
                # First, try to parse the entire response as JSON
                try:
                    structured_response = json.loads(assistant_response)
                except json.JSONDecodeError:
                    # If that fails, try to find JSON in the response
                    import re
                    json_match = re.search(r'({.*})', assistant_response, re.DOTALL)
                    if json_match:
                        structured_response = json.loads(json_match.group(1))
                    else:
                        # For other JSON parsing errors
                        logger.error(f"Failed to parse Claude response as JSON: {assistant_response[:100]}...")
                        return {expected_key: [] if expected_key and expected_key != "communication_patterns" else {}} if expected_key else {"error": "Failed to parse response as JSON"}
                
                # Validate that the expected key is present
                if expected_key and expected_key not in structured_response:
                    logger.warning(f"Expected key '{expected_key}' not found in Claude's response")
                    structured_response[expected_key] = [] if expected_key != "communication_patterns" else {}
                
                return structured_response
            except Exception as e:
                logger.error(f"Error processing Claude response: {str(e)}")
                return {expected_key: [] if expected_key and expected_key != "communication_patterns" else {}} if expected_key else {"error": f"Error processing response: {str(e)}"}
                
        except Exception as e:
            logger.error(f"Error getting structured response: {str(e)}")
            return {expected_key: [] if expected_key and expected_key != "communication_patterns" else {}} if expected_key else {"error": str(e)}
    
    def scan_urgent_emails(self, user_email: str, access_token: str, hours_back: int = 24) -> Dict[str, Any]:
        """
        Scan recent emails for urgent items requiring attention.
        
        Args:
            user_email: The email of the user whose emails to scan
            access_token: OAuth access token for Gmail API
            hours_back: Number of hours back to scan (default: 24)
            
        Returns:
            Dict containing urgent emails and action items
        """
        logger.info(f"Scanning urgent emails from last {hours_back} hours for {user_email}")
        
        try:
            # Validate we have an access token
            if not access_token:
                logger.error(f"No access token provided for {user_email}")
                return {
                    "status": "error",
                    "message": "No access token provided for Gmail API",
                    "urgent_emails": []
                }
                
            # Initialize Gmail connector with the access token
            gmail = GmailConnector(access_token)
            
            # Test the connection
            if not gmail.test_connection():
                logger.error(f"Failed to connect to Gmail API for {user_email}")
                return {
                    "status": "error",
                    "message": "Failed to connect to Gmail API",
                    "urgent_emails": []
                }
            
            # Calculate days back from hours (needed for Gmail API call)
            days_back = max(1, int(hours_back / 24) + 1)  # At least 1 day, rounded up
            
            # Fetch real emails using the Gmail API
            logger.info(f"Fetching emails from Gmail API for {user_email} from last {hours_back} hours")
            email_summaries = gmail.get_recent_emails(days_back=days_back, max_results=50)
            
            if not email_summaries:
                logger.warning(f"No emails found for {user_email} in the last {days_back} days")
                return {
                    "status": "success",
                    "message": "No emails found in the specified time period",
                    "urgent_emails": []
                }
            
            # Filter emails to only include those from the last X hours
            recent_time = datetime.now() - timedelta(hours=hours_back)
            recent_emails = []
            
            for email in email_summaries:
                try:
                    # Parse the email date
                    email_date_str = email.get('date', '')
                    if email_date_str:
                        # Parse the date string (this is a simplification, might need adjustment)
                        email_date = datetime.strptime(email_date_str[:25], '%a, %d %b %Y %H:%M:%S')
                        if email_date > recent_time:
                            recent_emails.append(email)
                except Exception as e:
                    # If date parsing fails, include the email to be safe
                    logger.warning(f"Error parsing email date: {str(e)}")
                    recent_emails.append(email)
            
            logger.info(f"Found {len(recent_emails)} emails in the last {hours_back} hours")
            
            # Create a prompt for Claude to identify urgent emails
            prompt = f"""
            Please scan the following emails from the last {hours_back} hours and identify any urgent items that require my attention.
            
            Consider the following as potentially urgent:
            1. Emails marked as high priority
            2. Emails with urgent language in the subject or body
            3. Emails from key stakeholders (managers, executives, important clients)
            4. Emails mentioning deadlines within the next 48 hours
            5. Emails that are part of a rapid back-and-forth thread
            
            For each urgent email, provide:
            1. The sender and subject
            2. A brief summary of the content
            3. Why it's considered urgent
            4. Recommended action (if any)
            
            Email data:
            {json.dumps(recent_emails, indent=2)}
            
            Format the response as structured JSON with an array of "urgent_emails" objects, each containing
            "sender", "subject", "summary", "urgency_reason", and "recommended_action".
            """
            
            # Send the prompt to Claude using our structured response method
            response = self._get_structured_response(user_email, prompt, "urgent_emails", hours_back)
            
            logger.info(f"Successfully scanned urgent emails for {user_email}")
            return {
                "status": "success",
                "message": "Urgent email scan completed",
                "urgent_emails": response.get("urgent_emails", [])
            }
        except Exception as e:
            logger.error(f"Error scanning urgent emails for {user_email}: {str(e)}")
            return {
                "error": str(e),
                "status": "failed",
                "message": "Failed to scan urgent emails",
                "urgent_emails": []
            }
    
    def analyze_person(self, user_email: str, contact_email: str, access_token: str = None, days_back: int = 30) -> Dict[str, Any]:
        """
        Analyze email interactions with a specific person to build a profile.
        
        Args:
            user_email: The email of the user
            contact_email: The email of the contact to analyze
            access_token: OAuth access token for Gmail API
            days_back: Number of days back to analyze (default: 30)
            
        Returns:
            Dict containing analysis of the relationship with this person
        """
        logger.info(f"Analyzing person {contact_email} for {user_email}")
        
        try:
            # Validate we have an access token
            if not access_token:
                logger.error(f"No access token provided for {user_email}")
                return {
                    "status": "error",
                    "message": "No access token provided for Gmail API",
                    "contact_name": "",
                    "interaction_frequency": "",
                    "response_patterns": "",
                    "common_topics": [],
                    "sentiment_analysis": "",
                    "action_items": [],
                    "relationship_context": "",
                    "last_contact_date": ""
                }
                
            # Initialize Gmail connector with the access token
            gmail = GmailConnector(access_token)
            
            # Test the connection
            if not gmail.test_connection():
                logger.error(f"Failed to connect to Gmail API for {user_email}")
                return {
                    "status": "error",
                    "message": "Failed to connect to Gmail API",
                    "contact_name": "",
                    "interaction_frequency": "",
                    "response_patterns": "",
                    "common_topics": [],
                    "sentiment_analysis": "",
                    "action_items": [],
                    "relationship_context": "",
                    "last_contact_date": ""
                }
            
            # Fetch real emails using the Gmail API
            logger.info(f"Fetching emails from Gmail API for {user_email} related to {contact_email}")
            # Get emails from the last N days
            email_summaries = gmail.get_recent_emails(days_back=days_back, max_results=100)
            
            # Filter emails to only include those involving the contact
            contact_emails = []
            for email in email_summaries:
                if contact_email.lower() in email.get('sender', '').lower() or contact_email.lower() in email.get('to', '').lower():
                    contact_emails.append(email)
            
            if not contact_emails:
                logger.warning(f"No emails found between {user_email} and {contact_email} in the last {days_back} days")
                return {
                    "status": "warning",
                    "message": f"No emails found with {contact_email} in the last {days_back} days",
                    "contact_name": "",
                    "interaction_frequency": "None in the analyzed period",
                    "response_patterns": "N/A",
                    "common_topics": [],
                    "sentiment_analysis": "N/A",
                    "action_items": [],
                    "relationship_context": "No recent interactions",
                    "last_contact_date": "None in the analyzed period"
                }
            
            logger.info(f"Found {len(contact_emails)} emails between {user_email} and {contact_email}")
            
            # Create a prompt for Claude to analyze interactions with this person
            prompt = f"""
            Please analyze my email interactions with {contact_email} and provide a comprehensive profile.
            
            Include:
            1. Interaction frequency: How often we communicate and patterns over time
            2. Response times: How quickly they respond to me and vice versa
            3. Topics: Common subjects and projects we discuss
            4. Sentiment: The general tone and sentiment of our communications
            5. Action items: Any pending items or follow-ups with this person
            6. Relationship context: Their role, organization, and our relationship history
            
            Analyze the following email data:
            {json.dumps(contact_emails, indent=2)}
            
            Format the response as structured JSON with the following keys:
            "contact_name", "interaction_frequency", "response_patterns", "common_topics", 
            "sentiment_analysis", "action_items", "relationship_context", "last_contact_date"
            """
            
            # Send the prompt to Claude
            response = self._get_structured_response(user_email, prompt)
            logger.info(f"Successfully analyzed person {contact_email} for {user_email}")
            return response
        except Exception as e:
            logger.error(f"Error analyzing person {contact_email} for {user_email}: {str(e)}")
            return {
                "error": str(e),
                "status": "failed",
                "message": f"Failed to analyze person {contact_email}"
            }
    
    def identify_key_contacts(self, user_email: str, access_token: str = None, days_back: int = 30) -> Dict[str, Any]:
        """
        Identify and analyze key contacts from email communications.
        
        Args:
            user_email: The email of the user
            access_token: OAuth access token for Gmail API
            days_back: Number of days back to analyze (default: 30)
            
        Returns:
            Dict containing key contacts and relationship insights
        """
        logger.info(f"Identifying key contacts for {user_email}")
        
        try:
            # Validate we have an access token
            if not access_token:
                logger.error(f"No access token provided for {user_email}")
                return {
                    "status": "error",
                    "message": "No access token provided for Gmail API",
                    "key_contacts": []
                }
                
            # Initialize Gmail connector with the access token
            gmail = GmailConnector(access_token)
            
            # Test the connection
            if not gmail.test_connection():
                logger.error(f"Failed to connect to Gmail API for {user_email}")
                return {
                    "status": "error",
                    "message": "Failed to connect to Gmail API",
                    "key_contacts": []
                }
            
            # Fetch real emails using the Gmail API
            logger.info(f"Fetching emails from Gmail API for {user_email}")
            email_summaries = gmail.get_recent_emails(days_back=days_back, max_results=100)
            
            if not email_summaries:
                logger.warning(f"No emails found for {user_email} in the last {days_back} days")
                return {
                    "status": "warning",
                    "message": "No emails found in the analyzed period",
                    "key_contacts": []
                }
            
            logger.info(f"Successfully fetched {len(email_summaries)} emails for contact analysis")
            
            # Create a prompt for Claude to identify key contacts
            prompt = f"""
            Please analyze the following email communications from the last {days_back} days and identify my key contacts.
            
            For each key contact, provide:
            1. Their name and email address
            2. Their role or organization (if apparent)
            3. The frequency of our communication
            4. The nature of our relationship (professional, personal, etc.)
            5. Common topics or projects we discuss
            
            Email data:
            {json.dumps(email_summaries, indent=2)}
            
            Format the response as structured JSON with an array of "key_contacts" objects, 
            each containing "name", "email", "role", "communication_frequency", "relationship_type", and "common_topics"
            """
            
            # Send the prompt to Claude
            response = self._get_structured_response(user_email, prompt, "key_contacts", days_back)
            logger.info(f"Successfully identified key contacts for {user_email}")
            return {
                "status": "success",
                "message": "Key contacts identified successfully",
                "key_contacts": response.get("key_contacts", [])
            }
        except Exception as e:
            logger.error(f"Error identifying key contacts for {user_email}: {str(e)}")
            return {
                "error": str(e),
                "status": "failed",
                "message": "Failed to identify key contacts",
                "key_contacts": []
            }



================================================
FILE: personal-ai-assistant/backend/core/data_orchestrator/__init__.py
================================================



================================================
FILE: personal-ai-assistant/backend/core/trigger_engine/__init__.py
================================================



================================================
FILE: personal-ai-assistant/backend/integrations/__init__.py
================================================



================================================
FILE: personal-ai-assistant/backend/integrations/claude_native/__init__.py
================================================



================================================
FILE: personal-ai-assistant/backend/integrations/clickup/__init__.py
================================================



================================================
FILE: personal-ai-assistant/backend/integrations/gmail/gmail_connector.py
================================================
"""
Gmail Connector for accessing Gmail data via Google API.
"""

import base64
import json
import logging
import traceback
from datetime import datetime, timedelta
from email.mime.text import MIMEText
from typing import Dict, List, Any, Optional

from google.oauth2.credentials import Credentials
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError

logger = logging.getLogger(__name__)

class GmailConnector:
    """
    Connector for Gmail API to fetch and process emails.
    """
    def __init__(self, access_token: str):
        """
        Initialize the Gmail connector with an access token.
        
        Args:
            access_token: OAuth2 access token for Gmail API
        """
        self.access_token = access_token
        self.service = self._build_service()
    
    def _build_service(self):
        """Build and return a Gmail service object."""
        try:
            if not self.access_token:
                logger.error("No access token provided")
                raise ValueError("Access token is required for Gmail API access")
                
            # Create credentials object from just the access token
            # This is the simplest way to use an existing OAuth token
            credentials = Credentials(token=self.access_token)
            
            # Build the Gmail service with these credentials
            service = build('gmail', 'v1', credentials=credentials)
            logger.info("Successfully built Gmail service with provided access token")
            return service
        except Exception as e:
            logger.error(f"Error building Gmail service: {str(e)}")
            raise
    
    def test_connection(self) -> bool:
        """Test if the Gmail connection is working."""
        try:
            # Try to get user profile as a simple test
            self.service.users().getProfile(userId='me').execute()
            return True
        except Exception as e:
            logger.error(f"Gmail connection test failed: {str(e)}")
            return False
    
    def get_recent_emails(self, days_back: int = 7, max_results: int = 50) -> List[Dict[str, Any]]:
        """
        Get recent emails from the last N days.
        
        Args:
            days_back: Number of days back to fetch emails from
            max_results: Maximum number of emails to return
            
        Returns:
            List of email data dictionaries
        """
        try:
            # Test connection first to fail fast if there are authentication issues
            if not self.test_connection():
                logger.error("Gmail connection test failed. Cannot fetch emails.")
                return []
                
            # Calculate date for query
            date_from = datetime.now() - timedelta(days=days_back)
            date_str = date_from.strftime('%Y/%m/%d')
            
            # Create query
            query = f'after:{date_str}'
            
            logger.info(f"Fetching emails with query: {query}, max results: {max_results}")
            
            # Get messages matching query
            results = self.service.users().messages().list(
                userId='me',
                q=query,
                maxResults=max_results
            ).execute()
            
            messages = results.get('messages', [])
            logger.info(f"Found {len(messages)} messages matching query")
            
            # Process each message
            emails = []
            for i, message in enumerate(messages):
                if i % 10 == 0 and i > 0:
                    logger.info(f"Processed {i}/{len(messages)} messages")
                email_data = self._get_email_details(message['id'])
                if email_data:
                    emails.append(email_data)
            
            logger.info(f"Successfully processed {len(emails)} emails")
            return emails
            
        except Exception as e:
            error_message = str(e)
            logger.error(f"Error getting recent emails: {error_message}")
            logger.debug(f"Error details: {traceback.format_exc()}")
            
            # Log more specific information about the error
            if "invalid_grant" in error_message.lower():
                logger.error("OAuth token issue detected. The token may be expired or invalid.")
            elif "access_not_configured" in error_message.lower():
                logger.error("Gmail API access not properly configured. Check API enablement in Google Cloud Console.")
            elif "permission_denied" in error_message.lower():
                logger.error("Permission denied. Check that the OAuth token has the necessary Gmail scopes.")
            
            # Return empty list on error
            return []
    
    def get_urgent_emails(self, days_back: int = 3, max_results: int = 20) -> List[Dict[str, Any]]:
        """
        Get potentially urgent emails that need attention.
        
        Args:
            days_back: Number of days back to check for urgent emails
            max_results: Maximum number of emails to return
            
        Returns:
            List of urgent email data dictionaries
        """
        try:
            # Get recent emails first
            recent_emails = self.get_recent_emails(days_back=days_back, max_results=100)
            
            # Filter for potentially urgent emails
            urgent_emails = [email for email in recent_emails if self._is_potentially_urgent(email)]
            
            # Limit results
            return urgent_emails[:max_results]
            
        except Exception as e:
            logger.error(f"Error getting urgent emails: {str(e)}")
            return []
    
    def _get_email_details(self, message_id: str) -> Optional[Dict[str, Any]]:
        """
        Get details of a specific email.
        
        Args:
            message_id: ID of the message to get details for
            
        Returns:
            Dictionary with email details or None if error
        """
        try:
            # Get the message
            message = self.service.users().messages().get(
                userId='me',
                id=message_id,
                format='full'
            ).execute()
            
            # Extract headers
            headers = message['payload']['headers']
            subject = next((h['value'] for h in headers if h['name'].lower() == 'subject'), 'No Subject')
            sender = next((h['value'] for h in headers if h['name'].lower() == 'from'), 'Unknown')
            date = next((h['value'] for h in headers if h['name'].lower() == 'date'), '')
            to = next((h['value'] for h in headers if h['name'].lower() == 'to'), '')
            
            # Extract body
            body = self._get_email_body(message)
            
            # Check if unread
            is_unread = 'UNREAD' in message.get('labelIds', [])
            
            # Create email data dictionary
            email_data = {
                'id': message_id,
                'thread_id': message.get('threadId', ''),
                'subject': subject,
                'sender': sender,
                'date': date,
                'to': to,
                'body': body,
                'is_unread': is_unread,
                'labels': message.get('labelIds', [])
            }
            
            return email_data
            
        except Exception as e:
            logger.error(f"Error getting email details for {message_id}: {str(e)}")
            return None
    
    def _get_email_body(self, message: Dict[str, Any]) -> str:
        """
        Extract the body text from an email message.
        
        Args:
            message: The message object from Gmail API
            
        Returns:
            String containing the email body text
        """
        body = ""
        
        if 'payload' not in message:
            return body
            
        if 'parts' in message['payload']:
            for part in message['payload']['parts']:
                if part.get('mimeType') == 'text/plain' and 'data' in part.get('body', {}):
                    body_bytes = base64.urlsafe_b64decode(part['body']['data'])
                    body += body_bytes.decode('utf-8', errors='replace')
        elif 'body' in message['payload'] and 'data' in message['payload']['body']:
            body_bytes = base64.urlsafe_b64decode(message['payload']['body']['data'])
            body += body_bytes.decode('utf-8', errors='replace')
            
        return body
    
    def _is_potentially_urgent(self, email_data: Dict[str, Any]) -> bool:
        """Determine if an email might be urgent"""
        # Simple heuristics for urgency
        subject = email_data.get('subject', '').lower()
        body = email_data.get('body', '').lower()
        
        urgent_keywords = [
            'urgent', 'asap', 'immediate', 'deadline', 'important',
            'meeting', 'call', 'response needed', 'please respond',
            'investor', 'funding', 'contract', 'deal'
        ]
        
        # Check if unread
        if email_data.get('is_unread', False):
            # Check for urgent keywords
            for keyword in urgent_keywords:
                if keyword in subject or keyword in body:
                    return True
        
        return False



================================================
FILE: personal-ai-assistant/backend/integrations/gmail/gmail_connector_improved.py
================================================
"""
Improved Gmail Connector with better error handling and token management.
"""

import base64
import json
import logging
import traceback
from datetime import datetime, timedelta
from email.mime.text import MIMEText
from typing import Dict, List, Any, Optional

from google.oauth2.credentials import Credentials
from google.auth.transport.requests import Request
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError

logger = logging.getLogger(__name__)

class ImprovedGmailConnector:
    """
    Improved connector for Gmail API with better error handling.
    """
    def __init__(self, token_data: Dict[str, Any]):
        """
        Initialize the Gmail connector with full token data.
        
        Args:
            token_data: OAuth2 token data including access_token, refresh_token, etc.
        """
        self.token_data = token_data
        self.service = None
        self._initialize_service()
    
    def _initialize_service(self):
        """Initialize or reinitialize the Gmail service."""
        try:
            if not self.token_data or 'access_token' not in self.token_data:
                logger.error("No access token in token data")
                raise ValueError("Access token is required for Gmail API access")
            
            # Create credentials with full token data
            credentials = Credentials(
                token=self.token_data.get('access_token'),
                refresh_token=self.token_data.get('refresh_token'),
                token_uri='https://oauth2.googleapis.com/token',
                client_id=self.token_data.get('client_id'),
                client_secret=self.token_data.get('client_secret'),
                scopes=['https://www.googleapis.com/auth/gmail.readonly']
            )
            
            # Check if token needs refresh
            if hasattr(credentials, 'expired') and credentials.expired:
                logger.info("Token expired, attempting to refresh...")
                credentials.refresh(Request())
                # Update token data with new access token
                self.token_data['access_token'] = credentials.token
                logger.info("Token refreshed successfully")
            
            # Build the Gmail service
            self.service = build('gmail', 'v1', credentials=credentials)
            logger.info("Gmail service initialized successfully")
            
        except Exception as e:
            logger.error(f"Error initializing Gmail service: {str(e)}")
            logger.error(f"Token data keys: {list(self.token_data.keys()) if self.token_data else 'None'}")
            raise
    
    def test_connection(self) -> Dict[str, Any]:
        """Test if the Gmail connection is working and return detailed info."""
        try:
            # Try to get user profile
            profile = self.service.users().getProfile(userId='me').execute()
            
            # Get labels to verify read access
            labels = self.service.users().labels().list(userId='me').execute()
            
            return {
                'success': True,
                'email': profile.get('emailAddress', 'Unknown'),
                'messages_total': profile.get('messagesTotal', 0),
                'labels_count': len(labels.get('labels', [])),
                'history_id': profile.get('historyId', 'Unknown')
            }
        except HttpError as e:
            error_details = e.error_details[0] if hasattr(e, 'error_details') and e.error_details else {}
            return {
                'success': False,
                'error': str(e),
                'status_code': e.resp.status if hasattr(e, 'resp') else None,
                'reason': error_details.get('reason', 'Unknown'),
                'message': error_details.get('message', str(e))
            }
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'error_type': type(e).__name__
            }
    
    def get_recent_emails(self, days_back: int = 7, max_results: int = 50) -> Dict[str, Any]:
        """
        Get recent emails with better error handling and progress tracking.
        
        Returns:
            Dict with 'success', 'emails', and 'metadata' or 'error'
        """
        try:
            # Test connection first
            connection_test = self.test_connection()
            if not connection_test['success']:
                return {
                    'success': False,
                    'error': connection_test['error'],
                    'details': connection_test
                }
            
            # Calculate date for query
            date_from = datetime.now() - timedelta(days=days_back)
            date_str = date_from.strftime('%Y/%m/%d')
            
            # Create query
            query = f'after:{date_str}'
            
            logger.info(f"Fetching emails for {connection_test['email']} with query: {query}")
            
            # Get messages with pagination support
            all_messages = []
            page_token = None
            pages_fetched = 0
            
            while len(all_messages) < max_results:
                try:
                    results = self.service.users().messages().list(
                        userId='me',
                        q=query,
                        maxResults=min(max_results - len(all_messages), 50),  # Fetch in chunks
                        pageToken=page_token
                    ).execute()
                    
                    messages = results.get('messages', [])
                    all_messages.extend(messages)
                    pages_fetched += 1
                    
                    page_token = results.get('nextPageToken')
                    if not page_token or len(all_messages) >= max_results:
                        break
                        
                except HttpError as e:
                    logger.error(f"Error fetching message list: {str(e)}")
                    if pages_fetched == 0:
                        raise
                    break
            
            logger.info(f"Found {len(all_messages)} messages across {pages_fetched} pages")
            
            # Process each message with error handling
            emails = []
            errors = []
            
            for i, message in enumerate(all_messages[:max_results]):
                try:
                    if i % 10 == 0 and i > 0:
                        logger.info(f"Processing message {i}/{len(all_messages)}")
                    
                    email_data = self._get_email_details(message['id'])
                    if email_data:
                        emails.append(email_data)
                except Exception as e:
                    error_msg = f"Error processing message {message['id']}: {str(e)}"
                    logger.error(error_msg)
                    errors.append(error_msg)
            
            return {
                'success': True,
                'emails': emails,
                'metadata': {
                    'total_found': len(all_messages),
                    'processed': len(emails),
                    'errors': len(errors),
                    'query': query,
                    'days_back': days_back,
                    'email_address': connection_test['email']
                },
                'processing_errors': errors[:5]  # Include first 5 errors for debugging
            }
            
        except Exception as e:
            error_msg = str(e)
            logger.error(f"Error getting recent emails: {error_msg}")
            
            # Provide helpful error messages
            if "invalid_grant" in error_msg.lower():
                return {
                    'success': False,
                    'error': 'Authentication failed - token may be expired',
                    'suggestion': 'Please log out and log in again to refresh your authentication'
                }
            elif "insufficient permission" in error_msg.lower():
                return {
                    'success': False,
                    'error': 'Insufficient permissions to read Gmail',
                    'suggestion': 'Please ensure you granted Gmail read permissions during login'
                }
            else:
                return {
                    'success': False,
                    'error': error_msg,
                    'error_type': type(e).__name__
                }
    
    def _get_email_details(self, message_id: str) -> Optional[Dict[str, Any]]:
        """Get details of a specific email with better error handling."""
        try:
            # Get the message
            message = self.service.users().messages().get(
                userId='me',
                id=message_id,
                format='full'
            ).execute()
            
            # Extract headers
            headers = message['payload'].get('headers', [])
            header_dict = {h['name'].lower(): h['value'] for h in headers}
            
            # Get key headers with defaults
            subject = header_dict.get('subject', 'No Subject')
            sender = header_dict.get('from', 'Unknown Sender')
            date_str = header_dict.get('date', '')
            to = header_dict.get('to', '')
            cc = header_dict.get('cc', '')
            
            # Parse date
            email_date = None
            if date_str:
                try:
                    # Simple date parsing - might need improvement for all formats
                    email_date = datetime.strptime(date_str[:25], '%a, %d %b %Y %H:%M:%S')
                except:
                    email_date = None
            
            # Extract body
            body = self._get_email_body(message)
            
            # Get labels and check if unread
            labels = message.get('labelIds', [])
            is_unread = 'UNREAD' in labels
            is_important = 'IMPORTANT' in labels
            is_starred = 'STARRED' in labels
            
            # Create email data dictionary
            return {
                'id': message_id,
                'thread_id': message.get('threadId', ''),
                'subject': subject,
                'sender': sender,
                'date': date_str,
                'date_parsed': email_date.isoformat() if email_date else None,
                'to': to,
                'cc': cc,
                'body': body[:5000],  # Limit body size
                'body_truncated': len(body) > 5000,
                'is_unread': is_unread,
                'is_important': is_important,
                'is_starred': is_starred,
                'labels': labels,
                'snippet': message.get('snippet', '')
            }
            
        except Exception as e:
            logger.error(f"Error getting email details for {message_id}: {str(e)}")
            return None
    
    def _get_email_body(self, message: Dict[str, Any]) -> str:
        """Extract the body text from an email message."""
        body = ""
        
        def extract_body_from_part(part):
            if part.get('mimeType') == 'text/plain':
                data = part.get('body', {}).get('data', '')
                if data:
                    return base64.urlsafe_b64decode(data).decode('utf-8', errors='replace')
            elif part.get('mimeType') == 'text/html' and not body:  # Fallback to HTML if no plain text
                data = part.get('body', {}).get('data', '')
                if data:
                    html_body = base64.urlsafe_b64decode(data).decode('utf-8', errors='replace')
                    # Simple HTML tag removal
                    import re
                    return re.sub('<[^<]+?>', '', html_body)
            return ""
        
        payload = message.get('payload', {})
        
        # Handle multipart messages
        if 'parts' in payload:
            for part in payload['parts']:
                body += extract_body_from_part(part)
                
                # Handle nested parts
                if 'parts' in part:
                    for subpart in part['parts']:
                        body += extract_body_from_part(subpart)
        else:
            # Single part message
            body = extract_body_from_part(payload)
        
        return body.strip()
    
    def get_email_stats(self, days_back: int = 30) -> Dict[str, Any]:
        """Get email statistics for insights."""
        try:
            connection_test = self.test_connection()
            if not connection_test['success']:
                return connection_test
            
            # Get various email counts
            date_from = datetime.now() - timedelta(days=days_back)
            date_str = date_from.strftime('%Y/%m/%d')
            
            stats = {
                'total_emails': 0,
                'unread_emails': 0,
                'important_emails': 0,
                'sent_emails': 0,
                'email_address': connection_test['email']
            }
            
            # Count different types of emails
            queries = {
                'total': f'after:{date_str}',
                'unread': f'after:{date_str} is:unread',
                'important': f'after:{date_str} is:important',
                'sent': f'after:{date_str} in:sent'
            }
            
            for stat_name, query in queries.items():
                try:
                    result = self.service.users().messages().list(
                        userId='me',
                        q=query,
                        maxResults=1
                    ).execute()
                    
                    count = result.get('resultSizeEstimate', 0)
                    if stat_name == 'total':
                        stats['total_emails'] = count
                    elif stat_name == 'unread':
                        stats['unread_emails'] = count
                    elif stat_name == 'important':
                        stats['important_emails'] = count
                    elif stat_name == 'sent':
                        stats['sent_emails'] = count
                        
                except Exception as e:
                    logger.error(f"Error getting {stat_name} count: {str(e)}")
            
            return {
                'success': True,
                'stats': stats
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            } 


================================================
FILE: personal-ai-assistant/backend/models/__init__.py
================================================



================================================
FILE: personal-ai-assistant/backend/models/database/__init__.py
================================================



================================================
FILE: personal-ai-assistant/backend/models/database/base.py
================================================
"""
Base SQLAlchemy model for database ORM.
"""

from sqlalchemy.ext.declarative import declarative_base

Base = declarative_base()



================================================
FILE: personal-ai-assistant/backend/models/database/email_insights.py
================================================
"""
Database models for email insights and people profiles.
"""

from sqlalchemy import Column, Integer, String, Text, DateTime, ForeignKey, Boolean, JSON
from sqlalchemy.orm import relationship
import datetime

from backend.models.database.base import Base

class EmailInsight(Base):
    """
    Stores insights generated from email analysis.
    """
    __tablename__ = "email_insights"
    
    id = Column(Integer, primary_key=True, index=True)
    user_email = Column(String, index=True)
    analysis_date = Column(DateTime, default=datetime.datetime.utcnow)
    days_analyzed = Column(Integer, default=30)
    
    # Insights stored as JSON
    key_relationships = Column(JSON)
    active_projects = Column(JSON)
    communication_patterns = Column(JSON)
    action_items = Column(JSON)
    important_information = Column(JSON)
    
    # Raw response for debugging
    raw_response = Column(Text, nullable=True)
    
    # Metadata
    created_at = Column(DateTime, default=datetime.datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.datetime.utcnow, onupdate=datetime.datetime.utcnow)


class UrgentEmailAlert(Base):
    """
    Stores urgent email alerts generated from recent email scans.
    """
    __tablename__ = "urgent_email_alerts"
    
    id = Column(Integer, primary_key=True, index=True)
    user_email = Column(String, index=True)
    scan_date = Column(DateTime, default=datetime.datetime.utcnow)
    hours_scanned = Column(Integer, default=24)
    
    # Alert data
    urgent_emails = Column(JSON)
    priority_level = Column(String)  # high, medium, low
    summary = Column(Text)
    
    # Status flags
    is_read = Column(Boolean, default=False)
    is_actioned = Column(Boolean, default=False)
    
    # Metadata
    created_at = Column(DateTime, default=datetime.datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.datetime.utcnow, onupdate=datetime.datetime.utcnow)


class PersonProfile(Base):
    """
    Stores profiles of people based on email interactions.
    """
    __tablename__ = "person_profiles"
    
    id = Column(Integer, primary_key=True, index=True)
    user_email = Column(String, index=True)
    contact_email = Column(String, index=True)
    contact_name = Column(String)
    
    # Profile data
    interaction_frequency = Column(JSON)
    response_patterns = Column(JSON)
    common_topics = Column(JSON)
    sentiment_analysis = Column(JSON)
    action_items = Column(JSON)
    relationship_context = Column(JSON)
    last_contact_date = Column(DateTime, nullable=True)
    
    # Metadata
    created_at = Column(DateTime, default=datetime.datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.datetime.utcnow, onupdate=datetime.datetime.utcnow)



================================================
FILE: personal-ai-assistant/backend/models/database/insights_storage.py
================================================
"""
Database models for storing email insights and intelligence data.
This creates persistent storage for your Chief of Staff AI system.
"""

from sqlalchemy import Column, Integer, String, Text, DateTime, JSON, Boolean, ForeignKey
from sqlalchemy.orm import relationship
from datetime import datetime

from models.database.base import Base

class UserIntelligence(Base):
    """Stores user-specific business intelligence and insights"""
    __tablename__ = "user_intelligence"
    __table_args__ = {'extend_existing': True}
    
    id = Column(Integer, primary_key=True)
    user_email = Column(String, unique=True, index=True)
    
    # Different knowledge repositories as per your architecture
    general_business_knowledge = Column(JSON, default={})  # General business context
    personal_knowledge = Column(JSON, default={})  # User-specific knowledge
    contacts_knowledge = Column(JSON, default={})  # People and relationships
    personal_goals = Column(JSON, default={})  # Goals and objectives
    tactical_notifications = Column(JSON, default=[])  # Real-time action items
    
    # Email analysis results
    last_email_analysis = Column(JSON, default={})
    email_insights_cache = Column(JSON, default={})
    
    # Relationships to structured knowledge models - using string references to avoid circular imports
    projects = relationship("Project", back_populates="user_intelligence", cascade="all, delete-orphan", lazy="dynamic")
    goals = relationship("Goal", back_populates="user_intelligence", cascade="all, delete-orphan", lazy="dynamic")
    knowledge_files = relationship("KnowledgeFile", back_populates="user_intelligence", cascade="all, delete-orphan", lazy="dynamic")
    
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)


class EmailSyncStatus(Base):
    """Tracks email sync operations and results"""
    __tablename__ = "email_sync_status"
    __table_args__ = {'extend_existing': True}
    
    id = Column(Integer, primary_key=True)
    user_email = Column(String, index=True)
    sync_type = Column(String)  # 'full', 'incremental', 'urgent'
    status = Column(String)  # 'pending', 'processing', 'completed', 'failed'
    progress = Column(Integer, default=0)
    
    # Sync results
    emails_processed = Column(Integer, default=0)
    insights_generated = Column(JSON, default={})
    error_message = Column(Text, nullable=True)
    
    started_at = Column(DateTime, default=datetime.utcnow)
    completed_at = Column(DateTime, nullable=True)


class ContactIntelligence(Base):
    """Stores intelligence about individual contacts"""
    __tablename__ = "contact_intelligence"
    __table_args__ = {'extend_existing': True}
    
    id = Column(Integer, primary_key=True)
    user_email = Column(String, index=True)
    contact_email = Column(String, index=True)
    contact_name = Column(String)
    
    # Relationship intelligence
    relationship_strength = Column(String)  # 'strong', 'medium', 'weak'
    interaction_frequency = Column(JSON)  # Pattern data
    communication_style = Column(JSON)  # Preferences and patterns
    topics_discussed = Column(JSON)  # Common topics
    
    # Context and history
    first_interaction = Column(DateTime)
    last_interaction = Column(DateTime)
    total_interactions = Column(Integer, default=0)
    
    # AI-generated insights
    relationship_summary = Column(Text)
    action_items = Column(JSON, default=[])
    
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)


================================================
FILE: personal-ai-assistant/backend/models/database/structured_knowledge.py
================================================
import os
import uuid
from datetime import datetime
from typing import List, Optional, Dict, Any

from sqlalchemy import Column, String, Text, Integer, Boolean, DateTime, ForeignKey, JSON
from sqlalchemy.orm import relationship

from models.database.base import Base


class Project(Base):
    """Model for storing user-defined projects and initiatives."""
    __tablename__ = "projects"
    __table_args__ = {'extend_existing': True}

    id = Column(String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
    user_email = Column(String(255), ForeignKey("user_intelligence.user_email"), nullable=False)
    name = Column(String(255), nullable=False)
    description = Column(Text, nullable=True)
    status = Column(String(50), default="active")  # active, planning, on_hold, completed
    priority = Column(String(50), nullable=True)  # high, medium, low
    stakeholders = Column(JSON, default=list)  # List of stakeholder names
    keywords = Column(JSON, default=list)  # Keywords for matching emails to this project
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)

    # Relationship to UserIntelligence
    user_intelligence = relationship("UserIntelligence", back_populates="projects")

    def to_dict(self) -> Dict[str, Any]:
        """Convert project to dictionary for API responses."""
        return {
            "id": self.id,
            "name": self.name,
            "description": self.description,
            "status": self.status,
            "priority": self.priority,
            "stakeholders": self.stakeholders,
            "keywords": self.keywords,
            "created_at": self.created_at.isoformat() if self.created_at else None,
            "updated_at": self.updated_at.isoformat() if self.updated_at else None
        }


class Goal(Base):
    """Model for storing user-defined personal and professional goals."""
    __tablename__ = "goals"
    __table_args__ = {'extend_existing': True}

    id = Column(String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
    user_email = Column(String(255), ForeignKey("user_intelligence.user_email"), nullable=False)
    title = Column(String(255), nullable=False)
    description = Column(Text, nullable=True)
    category = Column(String(50), default="professional")  # professional, personal, learning, financial, other
    timeframe = Column(String(50), default="medium_term")  # short_term, medium_term, long_term
    metrics = Column(Text, nullable=True)  # Success metrics
    keywords = Column(JSON, default=list)  # Keywords for matching emails to this goal
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)

    # Relationship to UserIntelligence
    user_intelligence = relationship("UserIntelligence", back_populates="goals")

    def to_dict(self) -> Dict[str, Any]:
        """Convert goal to dictionary for API responses."""
        return {
            "id": self.id,
            "title": self.title,
            "description": self.description,
            "category": self.category,
            "timeframe": self.timeframe,
            "metrics": self.metrics,
            "keywords": self.keywords,
            "created_at": self.created_at.isoformat() if self.created_at else None,
            "updated_at": self.updated_at.isoformat() if self.updated_at else None
        }


class KnowledgeFile(Base):
    """Model for storing uploaded knowledge base files."""
    __tablename__ = "knowledge_files"
    __table_args__ = {'extend_existing': True}

    id = Column(String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
    user_email = Column(String(255), ForeignKey("user_intelligence.user_email"), nullable=False)
    filename = Column(String(255), nullable=False)
    original_filename = Column(String(255), nullable=False)
    file_path = Column(String(512), nullable=False)
    file_size = Column(Integer, nullable=False)  # Size in bytes
    file_type = Column(String(100), nullable=False)  # MIME type
    description = Column(Text, nullable=True)
    category = Column(String(50), default="general")  # general, product, marketing, etc.
    is_processed = Column(Boolean, default=False)  # Whether the file has been processed for knowledge extraction
    content_extracted = Column(Text, nullable=True)  # Extracted text content from the file
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)

    # Relationship to UserIntelligence
    user_intelligence = relationship("UserIntelligence", back_populates="knowledge_files")

    def to_dict(self) -> Dict[str, Any]:
        """Convert file to dictionary for API responses."""
        return {
            "id": self.id,
            "filename": self.original_filename,
            "file_size": self.file_size,
            "file_type": self.file_type,
            "description": self.description,
            "category": self.category,
            "is_processed": self.is_processed,
            "created_at": self.created_at.isoformat() if self.created_at else None,
            "updated_at": self.updated_at.isoformat() if self.updated_at else None
        }



================================================
FILE: personal-ai-assistant/backend/models/schemas/__init__.py
================================================



================================================
FILE: personal-ai-assistant/backend/services/__init__.py
================================================



================================================
FILE: personal-ai-assistant/backend/services/email_intelligence_service.py
================================================
"""
Service layer for email intelligence operations.
"""

import logging
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
from sqlalchemy.orm import Session

from backend.core.claude_integration.email_intelligence import EmailIntelligence
from backend.models.database.email_insights import EmailInsight, UrgentEmailAlert, PersonProfile

logger = logging.getLogger(__name__)

class EmailIntelligenceService:
    def __init__(self, db: Session, claude_client):
        """
        Initialize the Email Intelligence Service.
        
        Args:
            db: Database session
            claude_client: Claude client instance
        """
        self.db = db
        self.email_intelligence = EmailIntelligence(claude_client)
    
    def run_business_intelligence_sync(self, user_email: str, days_back: int = 30) -> Dict[str, Any]:
        """
        Run the business intelligence sync to analyze emails from the last N days.
        
        Args:
            user_email: The email of the user
            days_back: Number of days back to analyze
            
        Returns:
            Dict containing analysis results
        """
        logger.info(f"Running business intelligence sync for {user_email}")
        
        try:
            # Get analysis from Claude
            analysis = self.email_intelligence.analyze_recent_emails(user_email, days_back)
            
            # Save to database
            email_insight = EmailInsight(
                user_email=user_email,
                days_analyzed=days_back,
                key_relationships=analysis.get("key_relationships", {}),
                active_projects=analysis.get("active_projects", {}),
                communication_patterns=analysis.get("communication_patterns", {}),
                action_items=analysis.get("action_items", {}),
                important_information=analysis.get("important_information", {}),
                raw_response=str(analysis)
            )
            
            self.db.add(email_insight)
            self.db.commit()
            self.db.refresh(email_insight)
            
            logger.info(f"Business intelligence sync completed for {user_email}")
            return {"status": "success", "insight_id": email_insight.id, "data": analysis}
            
        except Exception as e:
            logger.error(f"Error in business intelligence sync for {user_email}: {str(e)}")
            self.db.rollback()
            return {"status": "error", "message": str(e)}
    
    def scan_for_urgent_emails(self, user_email: str, hours_back: int = 24) -> Dict[str, Any]:
        """
        Scan for urgent emails that need attention.
        
        Args:
            user_email: The email of the user
            hours_back: Number of hours back to scan
            
        Returns:
            Dict containing urgent email alerts
        """
        logger.info(f"Scanning for urgent emails for {user_email}")
        
        try:
            # Get urgent emails from Claude
            urgent_data = self.email_intelligence.scan_urgent_emails(user_email, hours_back)
            
            # Only create alert if there are urgent emails
            if urgent_data.get("urgent_emails") and len(urgent_data["urgent_emails"]) > 0:
                # Save to database
                alert = UrgentEmailAlert(
                    user_email=user_email,
                    hours_scanned=hours_back,
                    urgent_emails=urgent_data.get("urgent_emails", []),
                    priority_level=urgent_data.get("priority_level", "low"),
                    summary=urgent_data.get("summary", "")
                )
                
                self.db.add(alert)
                self.db.commit()
                self.db.refresh(alert)
                
                logger.info(f"Urgent email scan completed for {user_email}, found {len(urgent_data.get('urgent_emails', []))} urgent emails")
                return {"status": "success", "alert_id": alert.id, "data": urgent_data}
            else:
                logger.info(f"No urgent emails found for {user_email}")
                return {"status": "success", "message": "No urgent emails found", "data": urgent_data}
            
        except Exception as e:
            logger.error(f"Error in urgent email scan for {user_email}: {str(e)}")
            self.db.rollback()
            return {"status": "error", "message": str(e)}
    
    def update_person_profile(self, user_email: str, contact_email: str) -> Dict[str, Any]:
        """
        Create or update a profile for a person based on email interactions.
        
        Args:
            user_email: The email of the user
            contact_email: The email of the contact to analyze
            
        Returns:
            Dict containing the person profile
        """
        logger.info(f"Updating person profile for {contact_email}")
        
        try:
            # Get person analysis from Claude
            profile_data = self.email_intelligence.analyze_person(user_email, contact_email)
            
            # Check if profile already exists
            existing_profile = self.db.query(PersonProfile).filter(
                PersonProfile.user_email == user_email,
                PersonProfile.contact_email == contact_email
            ).first()
            
            if existing_profile:
                # Update existing profile
                existing_profile.contact_name = profile_data.get("contact_name", existing_profile.contact_name)
                existing_profile.interaction_frequency = profile_data.get("interaction_frequency", existing_profile.interaction_frequency)
                existing_profile.response_patterns = profile_data.get("response_patterns", existing_profile.response_patterns)
                existing_profile.common_topics = profile_data.get("common_topics", existing_profile.common_topics)
                existing_profile.sentiment_analysis = profile_data.get("sentiment_analysis", existing_profile.sentiment_analysis)
                existing_profile.action_items = profile_data.get("action_items", existing_profile.action_items)
                existing_profile.relationship_context = profile_data.get("relationship_context", existing_profile.relationship_context)
                
                if profile_data.get("last_contact_date"):
                    try:
                        existing_profile.last_contact_date = datetime.fromisoformat(profile_data["last_contact_date"])
                    except (ValueError, TypeError):
                        pass
                
                self.db.commit()
                self.db.refresh(existing_profile)
                profile_id = existing_profile.id
                
            else:
                # Create new profile
                last_contact_date = None
                if profile_data.get("last_contact_date"):
                    try:
                        last_contact_date = datetime.fromisoformat(profile_data["last_contact_date"])
                    except (ValueError, TypeError):
                        pass
                
                new_profile = PersonProfile(
                    user_email=user_email,
                    contact_email=contact_email,
                    contact_name=profile_data.get("contact_name", ""),
                    interaction_frequency=profile_data.get("interaction_frequency", {}),
                    response_patterns=profile_data.get("response_patterns", {}),
                    common_topics=profile_data.get("common_topics", {}),
                    sentiment_analysis=profile_data.get("sentiment_analysis", {}),
                    action_items=profile_data.get("action_items", {}),
                    relationship_context=profile_data.get("relationship_context", {}),
                    last_contact_date=last_contact_date
                )
                
                self.db.add(new_profile)
                self.db.commit()
                self.db.refresh(new_profile)
                profile_id = new_profile.id
            
            logger.info(f"Person profile updated for {contact_email}")
            return {"status": "success", "profile_id": profile_id, "data": profile_data}
            
        except Exception as e:
            logger.error(f"Error updating person profile for {contact_email}: {str(e)}")
            self.db.rollback()
            return {"status": "error", "message": str(e)}
    
    def update_key_contacts(self, user_email: str) -> Dict[str, Any]:
        """
        Identify and update profiles for key contacts.
        
        Args:
            user_email: The email of the user
            
        Returns:
            Dict containing key contacts data
        """
        logger.info(f"Updating key contacts for {user_email}")
        
        try:
            # Get key contacts from Claude
            contacts_data = self.email_intelligence.identify_key_contacts(user_email)
            
            # Process each key contact
            processed_contacts = []
            for contact in contacts_data.get("key_contacts", []):
                if contact.get("email"):
                    # Update or create profile for this contact
                    result = self.update_person_profile(user_email, contact["email"])
                    processed_contacts.append({
                        "email": contact["email"],
                        "name": contact.get("name", ""),
                        "profile_id": result.get("profile_id"),
                        "status": result.get("status")
                    })
            
            logger.info(f"Updated {len(processed_contacts)} key contacts for {user_email}")
            return {
                "status": "success", 
                "processed_contacts": processed_contacts,
                "key_contacts": contacts_data.get("key_contacts", [])
            }
            
        except Exception as e:
            logger.error(f"Error updating key contacts for {user_email}: {str(e)}")
            return {"status": "error", "message": str(e)}
    
    def get_latest_business_intelligence(self, user_email: str) -> Dict[str, Any]:
        """
        Get the latest business intelligence for a user.
        
        Args:
            user_email: The email of the user
            
        Returns:
            Dict containing the latest business intelligence
        """
        try:
            latest_insight = self.db.query(EmailInsight).filter(
                EmailInsight.user_email == user_email
            ).order_by(EmailInsight.created_at.desc()).first()
            
            if latest_insight:
                return {
                    "status": "success",
                    "insight_id": latest_insight.id,
                    "analysis_date": latest_insight.analysis_date,
                    "days_analyzed": latest_insight.days_analyzed,
                    "key_relationships": latest_insight.key_relationships,
                    "active_projects": latest_insight.active_projects,
                    "communication_patterns": latest_insight.communication_patterns,
                    "action_items": latest_insight.action_items,
                    "important_information": latest_insight.important_information
                }
            else:
                return {"status": "not_found", "message": "No business intelligence found for this user"}
                
        except Exception as e:
            logger.error(f"Error getting latest business intelligence for {user_email}: {str(e)}")
            return {"status": "error", "message": str(e)}
    
    def get_pending_urgent_alerts(self, user_email: str) -> List[Dict[str, Any]]:
        """
        Get pending urgent email alerts for a user.
        
        Args:
            user_email: The email of the user
            
        Returns:
            List of pending urgent alerts
        """
        try:
            alerts = self.db.query(UrgentEmailAlert).filter(
                UrgentEmailAlert.user_email == user_email,
                UrgentEmailAlert.is_read == False
            ).order_by(UrgentEmailAlert.created_at.desc()).all()
            
            return [
                {
                    "alert_id": alert.id,
                    "scan_date": alert.scan_date,
                    "priority_level": alert.priority_level,
                    "summary": alert.summary,
                    "urgent_emails": alert.urgent_emails
                }
                for alert in alerts
            ]
                
        except Exception as e:
            logger.error(f"Error getting pending urgent alerts for {user_email}: {str(e)}")
            return []
    
    def mark_alert_as_read(self, alert_id: int) -> Dict[str, Any]:
        """
        Mark an urgent email alert as read.
        
        Args:
            alert_id: The ID of the alert to mark as read
            
        Returns:
            Dict containing the result of the operation
        """
        try:
            alert = self.db.query(UrgentEmailAlert).filter(UrgentEmailAlert.id == alert_id).first()
            
            if alert:
                alert.is_read = True
                self.db.commit()
                return {"status": "success", "message": "Alert marked as read"}
            else:
                return {"status": "not_found", "message": "Alert not found"}
                
        except Exception as e:
            logger.error(f"Error marking alert as read: {str(e)}")
            self.db.rollback()
            return {"status": "error", "message": str(e)}
    
    def get_person_profile(self, user_email: str, contact_email: str) -> Dict[str, Any]:
        """
        Get the profile for a specific person.
        
        Args:
            user_email: The email of the user
            contact_email: The email of the contact
            
        Returns:
            Dict containing the person profile
        """
        try:
            profile = self.db.query(PersonProfile).filter(
                PersonProfile.user_email == user_email,
                PersonProfile.contact_email == contact_email
            ).first()
            
            if profile:
                return {
                    "status": "success",
                    "profile_id": profile.id,
                    "contact_name": profile.contact_name,
                    "contact_email": profile.contact_email,
                    "interaction_frequency": profile.interaction_frequency,
                    "response_patterns": profile.response_patterns,
                    "common_topics": profile.common_topics,
                    "sentiment_analysis": profile.sentiment_analysis,
                    "action_items": profile.action_items,
                    "relationship_context": profile.relationship_context,
                    "last_contact_date": profile.last_contact_date.isoformat() if profile.last_contact_date else None,
                    "last_updated": profile.updated_at.isoformat()
                }
            else:
                return {"status": "not_found", "message": "Person profile not found"}
                
        except Exception as e:
            logger.error(f"Error getting person profile: {str(e)}")
            return {"status": "error", "message": str(e)}



================================================
FILE: personal-ai-assistant/backend/services/intelligence_service.py
================================================
"""
Service layer for managing email intelligence and insights.
Handles storage, retrieval, and processing of Chief of Staff data.
"""

import json
import logging
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
from sqlalchemy.orm import Session
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

from models.database.insights_storage import Base, UserIntelligence, EmailSyncStatus, ContactIntelligence
from core.claude_integration.email_intelligence import EmailIntelligence
from services.structured_knowledge_service import StructuredKnowledgeService
from anthropic import Anthropic

logger = logging.getLogger(__name__)

# Create a shared engine and metadata
_engine = None
_SessionLocal = None

def get_engine(database_url: str):
    global _engine
    if _engine is None:
        _engine = create_engine(database_url)
        Base.metadata.create_all(_engine)
    return _engine

def get_session_local(database_url: str):
    global _SessionLocal
    if _SessionLocal is None:
        engine = get_engine(database_url)
        _SessionLocal = sessionmaker(bind=engine)
    return _SessionLocal

class IntelligenceService:
    """Service for managing user intelligence and insights"""
    
    def __init__(self, database_url: str, claude_client: Anthropic):
        """Initialize the intelligence service with database and Claude client"""
        self.engine = get_engine(database_url)
        self.SessionLocal = get_session_local(database_url)
        self.claude_client = claude_client
        self.email_intelligence = EmailIntelligence(claude_client)
        self.structured_knowledge_service = StructuredKnowledgeService(self.SessionLocal)
    
    def process_and_store_email_insights(self, user_email: str, access_token: str, days_back: int = 30, force_full_sync: bool = False) -> Dict[str, Any]:
        """
        Process emails and store insights in appropriate knowledge repositories.
        This is the main entry point for email sync operations.
        
        Args:
            user_email: The email address of the user
            access_token: Google OAuth access token
            days_back: Number of days to look back for emails
            force_full_sync: If True, forces a full sync even if a previous sync exists
        """
        session = self.SessionLocal()
        try:
            # Check if we have a previous sync for this user
            user_intel = session.query(UserIntelligence).filter_by(user_email=user_email).first()
            last_sync = None
            sync_type = 'full'
            
            if user_intel and user_intel.email_insights_cache and not force_full_sync:
                # Get the last sync time from the cache
                cache = user_intel.email_insights_cache
                if 'generated_at' in cache:
                    last_sync = datetime.fromisoformat(cache['generated_at'])
                    sync_type = 'incremental'
                    logger.info(f"Found previous sync at {last_sync}, performing incremental sync")
            
            if not last_sync:
                logger.info("No previous sync found or full sync forced, performing full sync")
        
            # Create or update sync status
            sync_status = EmailSyncStatus(
                user_email=user_email,
                sync_type=sync_type,
                status='processing',
                progress=10
            )
            session.add(sync_status)
            session.commit()
            
            # Get or create user intelligence record
            user_intel = session.query(UserIntelligence).filter_by(user_email=user_email).first()
            if not user_intel:
                user_intel = UserIntelligence(user_email=user_email)
                session.add(user_intel)
            
            # Analyze emails using EmailIntelligence
            logger.info(f"Analyzing emails for {user_email}")
            sync_status.progress = 30
            session.commit()
            
            # If we have a last sync time, only analyze emails since then
            if sync_type == 'incremental' and last_sync:
                # Calculate days since last sync
                days_since_last_sync = (datetime.utcnow() - last_sync).days + 1  # +1 for overlap
                actual_days_back = min(days_back, days_since_last_sync)
                
                # Get existing insights to provide context for incremental analysis
                existing_insights = None
                if user_intel and user_intel.email_insights_cache:
                    existing_insights = user_intel.email_insights_cache
                    
                    # Log summary of existing insights for debugging
                    relationship_count = len(existing_insights.get('key_relationships', []))
                    project_count = len(existing_insights.get('active_projects', []))
                    action_count = len(existing_insights.get('action_items', []))
                    info_count = len(existing_insights.get('important_information', []))
                    
                    logger.info(f"Providing previous insights as context for incremental analysis: "
                              f"{relationship_count} relationships, {project_count} projects, "
                              f"{action_count} action items, {info_count} information items")
                
                # Get structured knowledge to enhance email analysis
                structured_knowledge = self._get_structured_knowledge_context(user_email)
                
                insights = self.email_intelligence.analyze_recent_emails(
                    user_email, 
                    access_token, 
                    actual_days_back, 
                    previous_insights=existing_insights,
                    structured_knowledge=structured_knowledge
                )
            else:
                logger.info(f"Performing full sync for the last {days_back} days")
                # Get structured knowledge to enhance email analysis
                structured_knowledge = self._get_structured_knowledge_context(user_email)
                
                insights = self.email_intelligence.analyze_recent_emails(
                    user_email, 
                    access_token, 
                    days_back,
                    structured_knowledge=structured_knowledge
                )
            
            # Process and categorize insights into knowledge repositories
            if insights.get('status') == 'success' or insights.get('key_relationships'):
                # 1. Update contacts knowledge
                contacts_knowledge = user_intel.contacts_knowledge or {}
                for relationship in insights.get('key_relationships', []):
                    if isinstance(relationship, dict):
                        contact_email = relationship.get('email', 'unknown')
                        contacts_knowledge[contact_email] = {
                            'name': relationship.get('name'),
                            'role': relationship.get('role'),
                            'importance': relationship.get('importance'),
                            'recent_interactions': relationship.get('recent_interactions'),
                            'last_updated': datetime.utcnow().isoformat()
                        }
                        
                        # Also create/update ContactIntelligence record
                        self._update_contact_intelligence(session, user_email, relationship)
                
                user_intel.contacts_knowledge = contacts_knowledge
                sync_status.progress = 50
                session.commit()
                
                # 2. Update general business knowledge
                business_knowledge = user_intel.general_business_knowledge or {}
                for project in insights.get('active_projects', []):
                    if isinstance(project, dict):
                        project_name = project.get('name', 'Unknown Project')
                        business_knowledge[project_name] = {
                            'description': project.get('description'),
                            'status': project.get('status'),
                            'priority': project.get('priority'),
                            'stakeholders': project.get('key_stakeholders', []),
                            'last_updated': datetime.utcnow().isoformat()
                        }
                
                user_intel.general_business_knowledge = business_knowledge
                sync_status.progress = 70
                session.commit()
                
                # 3. Extract tactical notifications (urgent action items)
                tactical_items = []
                for action in insights.get('action_items', []):
                    if isinstance(action, dict):
                        tactical_items.append({
                            'description': action.get('description'),
                            'deadline': action.get('deadline'),
                            'priority': action.get('priority', 'Medium'),
                            'context': action.get('context'),
                            'created_at': datetime.utcnow().isoformat(),
                            'status': 'pending'
                        })
                
                user_intel.tactical_notifications = tactical_items
                
                # Log summary of new insights for comparison
                relationship_count = len(insights.get('key_relationships', []))
                project_count = len(insights.get('active_projects', []))
                action_count = len(insights.get('action_items', []))
                info_count = len(insights.get('important_information', []))
                
                logger.info(f"Storing new augmented insights: "
                          f"{relationship_count} relationships, {project_count} projects, "
                          f"{action_count} action items, {info_count} information items")
                
                # 4. Store the complete analysis for quick retrieval
                user_intel.last_email_analysis = insights
                
                # Store the insights directly (not nested under 'insights' key)
                # This is important for the cumulative knowledge building to work correctly
                user_intel.email_insights_cache = insights
                
                # Add metadata to the insights
                insights['generated_at'] = datetime.utcnow().isoformat()
                insights['days_analyzed'] = days_back if sync_type == 'full' else actual_days_back
                
                # Update sync status
                sync_status.status = 'completed'
                sync_status.progress = 100
                sync_status.emails_processed = len(insights.get('key_relationships', []))
                
                # Initialize insights_generated with default values to avoid NoneType errors
                sync_status.insights_generated = {
                    'relationships': len(insights.get('key_relationships', [])) if insights.get('key_relationships') else 0,
                    'projects': len(insights.get('active_projects', [])) if insights.get('active_projects') else 0,
                    'action_items': len(insights.get('action_items', [])) if insights.get('action_items') else 0,
                    'important_info': len(insights.get('important_information', [])) if insights.get('important_information') else 0
                }
                sync_status.completed_at = datetime.utcnow()
                
                session.commit()
                
                logger.info(f"Successfully processed and stored insights for {user_email}")
                return {
                    'status': 'success',
                    'sync_id': sync_status.id,
                    'insights_summary': sync_status.insights_generated
                }
            else:
                # Handle error case
                sync_status.status = 'failed'
                sync_status.error_message = insights.get('message', 'Unknown error')
                sync_status.completed_at = datetime.utcnow()
                session.commit()
                
                return {
                    'status': 'error',
                    'message': insights.get('message', 'Failed to analyze emails')
                }
                
        except Exception as e:
            logger.error(f"Error processing email insights: {str(e)}")
            if 'sync_status' in locals():
                sync_status.status = 'failed'
                sync_status.error_message = str(e)
                sync_status.completed_at = datetime.utcnow()
                session.commit()
            
            return {
                'status': 'error',
                'message': str(e)
            }
        finally:
            session.close()
    
    def get_user_insights(self, user_email: str) -> Dict[str, Any]:
        """Retrieve stored insights for a user"""
        session = self.SessionLocal()
        try:
            user_intel = session.query(UserIntelligence).filter_by(user_email=user_email).first()
            
            if not user_intel or not user_intel.email_insights_cache:
                return {
                    'status': 'no_data',
                    'message': 'No insights available. Please sync your emails first.'
                }
            
            # Return the cached insights - now stored directly, not nested under 'insights' key
            insights = user_intel.email_insights_cache
            
            # Add metadata if not already present
            if 'cached_at' not in insights and 'generated_at' in insights:
                insights['cached_at'] = insights['generated_at']
            
            return insights
            
        finally:
            session.close()
    
    def get_tactical_notifications(self, user_email: str) -> List[Dict[str, Any]]:
        """Get pending tactical notifications/action items for a user"""
        session = self.SessionLocal()
        try:
            user_intel = session.query(UserIntelligence).filter_by(user_email=user_email).first()
            
            if not user_intel:
                return []
            
            # Filter for pending items only
            notifications = user_intel.tactical_notifications or []
            pending = [n for n in notifications if n.get('status') == 'pending']
            
            return pending
            
        finally:
            session.close()
    
    def get_contact_intelligence(self, user_email: str, contact_email: str) -> Dict[str, Any]:
        """Get intelligence about a specific contact"""
        session = self.SessionLocal()
        try:
            contact = session.query(ContactIntelligence).filter_by(
                user_email=user_email,
                contact_email=contact_email
            ).first()
            
            if not contact:
                return {'status': 'not_found'}
            
            return {
                'name': contact.contact_name,
                'email': contact.contact_email,
                'relationship_strength': contact.relationship_strength,
                'interaction_frequency': contact.interaction_frequency,
                'topics_discussed': contact.topics_discussed,
                'last_interaction': contact.last_interaction.isoformat() if contact.last_interaction else None,
                'action_items': contact.action_items,
                'summary': contact.relationship_summary
            }
            
        finally:
            session.close()
    
    def _update_contact_intelligence(self, session: Session, user_email: str, relationship: Dict[str, Any]) -> None:
        """Create or update a ContactIntelligence record"""
        contact_email = relationship.get('email', 'unknown')
        if contact_email == 'unknown':
            return
            
        # Check if contact already exists
        contact = session.query(ContactIntelligence).filter_by(
            user_email=user_email,
            contact_email=contact_email
        ).first()
        
        if not contact:
            contact = ContactIntelligence(
                user_email=user_email,
                contact_email=contact_email
            )
            session.add(contact)
        
        # Update contact data
        contact.name = relationship.get('name')
        contact.role = relationship.get('role')
        contact.importance = relationship.get('importance')
        contact.recent_interactions = relationship.get('recent_interactions')
        contact.last_updated = datetime.utcnow()
        
    def _get_structured_knowledge_context(self, user_email: str) -> Dict[str, Any]:
        """Gather structured knowledge to enhance email analysis"""
        # Get projects, goals, and knowledge files
        projects = self.structured_knowledge_service.get_projects(user_email)
        goals = self.structured_knowledge_service.get_goals(user_email)
        knowledge_files = self.structured_knowledge_service.get_knowledge_files(user_email)
        
        # Extract content from knowledge files
        knowledge_content = []
        for file in knowledge_files:
            if file.content_extracted:
                knowledge_content.append({
                    'filename': file.original_filename,
                    'content': file.content_extracted,
                    'category': file.category
                })
        
        return {
            'projects': projects,
            'goals': goals,
            'knowledge_files': knowledge_content
        }


================================================
FILE: personal-ai-assistant/backend/services/structured_knowledge_service.py
================================================
"""
Service for managing structured knowledge components (projects, goals, files).
"""

import os
import uuid
import logging
from typing import List, Dict, Any, Optional
from datetime import datetime
from werkzeug.utils import secure_filename

from sqlalchemy.orm import Session

from models.database.structured_knowledge import Project, Goal, KnowledgeFile
from models.database.insights_storage import UserIntelligence

logger = logging.getLogger(__name__)

ALLOWED_EXTENSIONS = {'pdf', 'doc', 'docx', 'txt', 'md', 'ppt', 'pptx', 'xls', 'xlsx'}
UPLOAD_FOLDER = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 'uploads')

# Ensure upload directory exists
os.makedirs(UPLOAD_FOLDER, exist_ok=True)


class StructuredKnowledgeService:
    """Service for managing structured knowledge components."""

    def __init__(self, session_local):
        """Initialize with database session factory."""
        self.SessionLocal = session_local

    def _get_user_intelligence(self, session: Session, user_email: str) -> UserIntelligence:
        """Get or create UserIntelligence record for a user."""
        user_intel = session.query(UserIntelligence).filter_by(user_email=user_email).first()
        if not user_intel:
            user_intel = UserIntelligence(user_email=user_email)
            session.add(user_intel)
            session.commit()
        return user_intel

    # Project management methods
    def get_projects(self, user_email: str) -> List[Dict[str, Any]]:
        """Get all projects for a user."""
        session = self.SessionLocal()
        try:
            projects = session.query(Project).filter_by(user_email=user_email).all()
            return [project.to_dict() for project in projects]
        finally:
            session.close()

    def get_project(self, user_email: str, project_id: str) -> Optional[Dict[str, Any]]:
        """Get a specific project by ID."""
        session = self.SessionLocal()
        try:
            project = session.query(Project).filter_by(user_email=user_email, id=project_id).first()
            return project.to_dict() if project else None
        finally:
            session.close()

    def create_project(self, user_email: str, project_data: Dict[str, Any]) -> Dict[str, Any]:
        """Create a new project."""
        session = self.SessionLocal()
        try:
            # Ensure user exists
            self._get_user_intelligence(session, user_email)
            
            # Create project
            project = Project(
                user_email=user_email,
                name=project_data.get('name'),
                description=project_data.get('description'),
                status=project_data.get('status', 'active'),
                priority=project_data.get('priority'),
                stakeholders=project_data.get('stakeholders', []),
                keywords=project_data.get('keywords', [])
            )
            session.add(project)
            session.commit()
            session.refresh(project)
            
            logger.info(f"Created project {project.id} for user {user_email}")
            return project.to_dict()
        finally:
            session.close()

    def update_project(self, user_email: str, project_id: str, project_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Update an existing project."""
        session = self.SessionLocal()
        try:
            project = session.query(Project).filter_by(user_email=user_email, id=project_id).first()
            if not project:
                return None
            
            # Update fields
            if 'name' in project_data:
                project.name = project_data['name']
            if 'description' in project_data:
                project.description = project_data['description']
            if 'status' in project_data:
                project.status = project_data['status']
            if 'priority' in project_data:
                project.priority = project_data['priority']
            if 'stakeholders' in project_data:
                project.stakeholders = project_data['stakeholders']
            if 'keywords' in project_data:
                project.keywords = project_data['keywords']
            
            project.updated_at = datetime.utcnow()
            session.commit()
            session.refresh(project)
            
            logger.info(f"Updated project {project_id} for user {user_email}")
            return project.to_dict()
        finally:
            session.close()

    def delete_project(self, user_email: str, project_id: str) -> bool:
        """Delete a project."""
        session = self.SessionLocal()
        try:
            project = session.query(Project).filter_by(user_email=user_email, id=project_id).first()
            if not project:
                return False
            
            session.delete(project)
            session.commit()
            
            logger.info(f"Deleted project {project_id} for user {user_email}")
            return True
        finally:
            session.close()

    # Goal management methods
    def get_goals(self, user_email: str) -> List[Dict[str, Any]]:
        """Get all goals for a user."""
        session = self.SessionLocal()
        try:
            goals = session.query(Goal).filter_by(user_email=user_email).all()
            return [goal.to_dict() for goal in goals]
        finally:
            session.close()

    def get_goal(self, user_email: str, goal_id: str) -> Optional[Dict[str, Any]]:
        """Get a specific goal by ID."""
        session = self.SessionLocal()
        try:
            goal = session.query(Goal).filter_by(user_email=user_email, id=goal_id).first()
            return goal.to_dict() if goal else None
        finally:
            session.close()

    def create_goal(self, user_email: str, goal_data: Dict[str, Any]) -> Dict[str, Any]:
        """Create a new goal."""
        session = self.SessionLocal()
        try:
            # Ensure user exists
            self._get_user_intelligence(session, user_email)
            
            # Create goal
            goal = Goal(
                user_email=user_email,
                title=goal_data.get('title'),
                description=goal_data.get('description'),
                category=goal_data.get('category', 'professional'),
                timeframe=goal_data.get('timeframe', 'medium_term'),
                metrics=goal_data.get('metrics'),
                keywords=goal_data.get('keywords', [])
            )
            session.add(goal)
            session.commit()
            session.refresh(goal)
            
            logger.info(f"Created goal {goal.id} for user {user_email}")
            return goal.to_dict()
        finally:
            session.close()

    def update_goal(self, user_email: str, goal_id: str, goal_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Update an existing goal."""
        session = self.SessionLocal()
        try:
            goal = session.query(Goal).filter_by(user_email=user_email, id=goal_id).first()
            if not goal:
                return None
            
            # Update fields
            if 'title' in goal_data:
                goal.title = goal_data['title']
            if 'description' in goal_data:
                goal.description = goal_data['description']
            if 'category' in goal_data:
                goal.category = goal_data['category']
            if 'timeframe' in goal_data:
                goal.timeframe = goal_data['timeframe']
            if 'metrics' in goal_data:
                goal.metrics = goal_data['metrics']
            if 'keywords' in goal_data:
                goal.keywords = goal_data['keywords']
            
            goal.updated_at = datetime.utcnow()
            session.commit()
            session.refresh(goal)
            
            logger.info(f"Updated goal {goal_id} for user {user_email}")
            return goal.to_dict()
        finally:
            session.close()

    def delete_goal(self, user_email: str, goal_id: str) -> bool:
        """Delete a goal."""
        session = self.SessionLocal()
        try:
            goal = session.query(Goal).filter_by(user_email=user_email, id=goal_id).first()
            if not goal:
                return False
            
            session.delete(goal)
            session.commit()
            
            logger.info(f"Deleted goal {goal_id} for user {user_email}")
            return True
        finally:
            session.close()

    # File management methods
    def allowed_file(self, filename: str) -> bool:
        """Check if file type is allowed."""
        return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

    def get_knowledge_files(self, user_email: str) -> List[Dict[str, Any]]:
        """Get all knowledge files for a user."""
        session = self.SessionLocal()
        try:
            files = session.query(KnowledgeFile).filter_by(user_email=user_email).all()
            return [file.to_dict() for file in files]
        finally:
            session.close()

    def get_knowledge_file(self, user_email: str, file_id: str) -> Optional[Dict[str, Any]]:
        """Get a specific knowledge file by ID."""
        session = self.SessionLocal()
        try:
            file = session.query(KnowledgeFile).filter_by(user_email=user_email, id=file_id).first()
            return file.to_dict() if file else None
        finally:
            session.close()

    def upload_knowledge_file(self, user_email: str, file, description: str = None, category: str = 'general') -> Optional[Dict[str, Any]]:
        """Upload and store a knowledge file."""
        if not file or not self.allowed_file(file.filename):
            return None
        
        session = self.SessionLocal()
        try:
            # Ensure user exists
            self._get_user_intelligence(session, user_email)
            
            # Generate secure filename and path
            original_filename = file.filename
            filename = secure_filename(original_filename)
            unique_filename = f"{uuid.uuid4()}_{filename}"
            file_path = os.path.join(UPLOAD_FOLDER, unique_filename)
            
            # Save file
            file.save(file_path)
            file_size = os.path.getsize(file_path)
            file_type = file.content_type or 'application/octet-stream'
            
            # Create database record
            knowledge_file = KnowledgeFile(
                user_email=user_email,
                filename=unique_filename,
                original_filename=original_filename,
                file_path=file_path,
                file_size=file_size,
                file_type=file_type,
                description=description,
                category=category
            )
            session.add(knowledge_file)
            session.commit()
            session.refresh(knowledge_file)
            
            logger.info(f"Uploaded knowledge file {knowledge_file.id} for user {user_email}")
            return knowledge_file.to_dict()
        except Exception as e:
            logger.error(f"Error uploading file: {str(e)}")
            return None
        finally:
            session.close()

    def delete_knowledge_file(self, user_email: str, file_id: str) -> bool:
        """Delete a knowledge file."""
        session = self.SessionLocal()
        try:
            file = session.query(KnowledgeFile).filter_by(user_email=user_email, id=file_id).first()
            if not file:
                return False
            
            # Delete file from filesystem
            if os.path.exists(file.file_path):
                os.remove(file.file_path)
            
            # Delete database record
            session.delete(file)
            session.commit()
            
            logger.info(f"Deleted knowledge file {file_id} for user {user_email}")
            return True
        except Exception as e:
            logger.error(f"Error deleting file: {str(e)}")
            return False
        finally:
            session.close()

    def process_knowledge_file(self, user_email: str, file_id: str) -> bool:
        """Process a knowledge file to extract content and insights."""
        # This would integrate with Claude or another text extraction service
        # For now, we'll just mark the file as processed
        session = self.SessionLocal()
        try:
            file = session.query(KnowledgeFile).filter_by(user_email=user_email, id=file_id).first()
            if not file:
                return False
            
            # TODO: Implement actual content extraction based on file type
            # For now, just mark as processed
            file.is_processed = True
            file.updated_at = datetime.utcnow()
            session.commit()
            
            logger.info(f"Marked knowledge file {file_id} as processed for user {user_email}")
            return True
        finally:
            session.close()

    # Integration with email insights
    def get_structured_knowledge_for_insights(self, user_email: str) -> Dict[str, Any]:
        """Get all structured knowledge for a user to enhance email insights."""
        session = self.SessionLocal()
        try:
            projects = session.query(Project).filter_by(user_email=user_email).all()
            goals = session.query(Goal).filter_by(user_email=user_email).all()
            
            # Format data for integration with Claude prompts
            structured_knowledge = {
                "projects": [
                    {
                        "name": p.name,
                        "description": p.description,
                        "status": p.status,
                        "priority": p.priority,
                        "stakeholders": p.stakeholders,
                        "keywords": p.keywords
                    } for p in projects
                ],
                "goals": [
                    {
                        "title": g.title,
                        "description": g.description,
                        "category": g.category,
                        "timeframe": g.timeframe,
                        "metrics": g.metrics,
                        "keywords": g.keywords
                    } for g in goals
                ]
            }
            
            return structured_knowledge
        finally:
            session.close()



================================================
FILE: personal-ai-assistant/backend/tasks/__init__.py
================================================



================================================
FILE: personal-ai-assistant/backend/tasks/email_intelligence_tasks.py
================================================
"""
Scheduled tasks for email intelligence operations.
"""

import logging
from typing import Dict, List, Any
from datetime import datetime, timedelta
from sqlalchemy.orm import Session

from backend.models.database.database import SessionLocal
from backend.services.email_intelligence_service import EmailIntelligenceService
from backend.core.claude_integration.claude_client import ClaudeClient
from backend.models.database.user import User

logger = logging.getLogger(__name__)

def run_daily_business_intelligence_sync():
    """
    Daily task to run business intelligence sync for all users.
    This analyzes emails from the last 30 days to build business context.
    """
    logger.info("Starting daily business intelligence sync")
    
    db = SessionLocal()
    try:
        # Get all active users
        users = db.query(User).filter(User.is_active == True).all()
        
        # Initialize Claude client
        claude_client = ClaudeClient()
        service = EmailIntelligenceService(db, claude_client)
        
        # Process each user
        for user in users:
            try:
                logger.info(f"Running business intelligence sync for {user.email}")
                result = service.run_business_intelligence_sync(user.email, days_back=30)
                
                if result["status"] == "success":
                    logger.info(f"Business intelligence sync completed for {user.email}")
                else:
                    logger.error(f"Business intelligence sync failed for {user.email}: {result.get('message', 'Unknown error')}")
                    
            except Exception as e:
                logger.error(f"Error in business intelligence sync for {user.email}: {str(e)}")
                continue
                
        logger.info("Daily business intelligence sync completed")
        
    except Exception as e:
        logger.error(f"Error in daily business intelligence sync: {str(e)}")
    finally:
        db.close()


def run_hourly_urgent_email_scan():
    """
    Hourly task to scan for urgent emails for all users.
    This checks emails from the last 6 hours for urgent items.
    """
    logger.info("Starting hourly urgent email scan")
    
    db = SessionLocal()
    try:
        # Get all active users
        users = db.query(User).filter(User.is_active == True).all()
        
        # Initialize Claude client
        claude_client = ClaudeClient()
        service = EmailIntelligenceService(db, claude_client)
        
        # Process each user
        for user in users:
            try:
                logger.info(f"Scanning urgent emails for {user.email}")
                result = service.scan_for_urgent_emails(user.email, hours_back=6)
                
                if result["status"] == "success":
                    if result.get("alert_id"):
                        logger.info(f"Urgent email scan completed for {user.email}, found urgent emails")
                    else:
                        logger.info(f"Urgent email scan completed for {user.email}, no urgent emails found")
                else:
                    logger.error(f"Urgent email scan failed for {user.email}: {result.get('message', 'Unknown error')}")
                    
            except Exception as e:
                logger.error(f"Error in urgent email scan for {user.email}: {str(e)}")
                continue
                
        logger.info("Hourly urgent email scan completed")
        
    except Exception as e:
        logger.error(f"Error in hourly urgent email scan: {str(e)}")
    finally:
        db.close()


def run_weekly_people_intelligence_update():
    """
    Weekly task to update people intelligence for all users.
    This identifies key contacts and updates their profiles.
    """
    logger.info("Starting weekly people intelligence update")
    
    db = SessionLocal()
    try:
        # Get all active users
        users = db.query(User).filter(User.is_active == True).all()
        
        # Initialize Claude client
        claude_client = ClaudeClient()
        service = EmailIntelligenceService(db, claude_client)
        
        # Process each user
        for user in users:
            try:
                logger.info(f"Updating key contacts for {user.email}")
                result = service.update_key_contacts(user.email)
                
                if result["status"] == "success":
                    logger.info(f"People intelligence update completed for {user.email}, processed {len(result.get('processed_contacts', []))} contacts")
                else:
                    logger.error(f"People intelligence update failed for {user.email}: {result.get('message', 'Unknown error')}")
                    
            except Exception as e:
                logger.error(f"Error in people intelligence update for {user.email}: {str(e)}")
                continue
                
        logger.info("Weekly people intelligence update completed")
        
    except Exception as e:
        logger.error(f"Error in weekly people intelligence update: {str(e)}")
    finally:
        db.close()



================================================
FILE: personal-ai-assistant/backend/tests/__init__.py
================================================



================================================
FILE: personal-ai-assistant/backend/tests/test_email_intelligence.py
================================================
"""
Tests for the email intelligence module.
"""

import unittest
from unittest.mock import MagicMock, patch
import json

from backend.core.claude_integration.email_intelligence import EmailIntelligence


class TestEmailIntelligence(unittest.TestCase):
    """Test cases for the EmailIntelligence class."""
    
    def setUp(self):
        """Set up test fixtures."""
        self.mock_claude_client = MagicMock()
        self.mock_claude_client.client = MagicMock()
        self.email_intelligence = EmailIntelligence(self.mock_claude_client)
        
        # Sample response data
        self.sample_response = {
            "key_relationships": [
                {"name": "John Doe", "email": "john@example.com", "interaction_frequency": "high"}
            ],
            "active_projects": ["Project Alpha", "Project Beta"],
            "communication_patterns": {"peak_time": "morning", "response_time": "fast"},
            "action_items": ["Follow up with John", "Review proposal"],
            "important_information": ["Deadline on Friday", "Meeting scheduled for Thursday"]
        }
        
        # Mock Claude response
        mock_content = MagicMock()
        mock_content.text = json.dumps(self.sample_response)
        self.mock_claude_client.client.messages.create.return_value = MagicMock(
            content=[mock_content]
        )
    
    def test_analyze_recent_emails(self):
        """Test analyzing recent emails."""
        result = self.email_intelligence.analyze_recent_emails("user@example.com", 30)
        
        # Verify Claude client was called with correct parameters
        self.mock_claude_client.client.messages.create.assert_called_once()
        call_args = self.mock_claude_client.client.messages.create.call_args[1]
        
        self.assertEqual(call_args["model"], "claude-4-sonnet-20250514")
        self.assertEqual(call_args["max_tokens"], 4000)
        
        # Check that messages parameter contains our prompt
        messages = call_args["messages"]
        self.assertEqual(len(messages), 1)
        self.assertEqual(messages[0]["role"], "user")
        self.assertIn("analyze my emails from the last 30 days", messages[0]["content"])
        
        # Check that system prompt mentions native Gmail integration
        system_prompt = call_args["system"]
        self.assertIn("NATIVE ACCESS to their Gmail", system_prompt)
        
        # Verify result matches our sample response
        self.assertEqual(result, self.sample_response)
    
    def test_scan_urgent_emails(self):
        """Test scanning for urgent emails."""
        result = self.email_intelligence.scan_urgent_emails("user@example.com", 24)
        
        # Verify Claude client was called
        self.mock_claude_client.client.messages.create.assert_called_once()
        call_args = self.mock_claude_client.client.messages.create.call_args[1]
        
        # Check that messages parameter contains our prompt
        messages = call_args["messages"]
        self.assertIn("scan my emails from the last 24 hours", messages[0]["content"])
        
        # Verify result matches our sample response
        self.assertEqual(result, self.sample_response)
    
    @patch('backend.core.claude_integration.email_intelligence.json.loads')
    def test_error_handling(self, mock_json_loads):
        """Test error handling when Claude response is not valid JSON."""
        # Make json.loads raise an exception
        mock_json_loads.side_effect = json.JSONDecodeError("Invalid JSON", "", 0)
        
        # Set up a non-JSON response from Claude
        mock_content = MagicMock()
        mock_content.text = "This is not valid JSON"
        self.mock_claude_client.client.messages.create.return_value = MagicMock(
            content=[mock_content]
        )
        
        # Call the method and check the result
        result = self.email_intelligence.analyze_recent_emails("user@example.com")
        
        # Verify error handling
        self.assertEqual(result["error"], "Failed to parse response as JSON")
        self.assertIn("raw_response", result)


if __name__ == '__main__':
    unittest.main()



================================================
FILE: personal-ai-assistant/backend/tests/fixtures/__init__.py
================================================



================================================
FILE: personal-ai-assistant/backend/tests/integration/__init__.py
================================================



================================================
FILE: personal-ai-assistant/backend/tests/unit/__init__.py
================================================



================================================
FILE: personal-ai-assistant/backend/utils/__init__.py
================================================



================================================
FILE: personal-ai-assistant/docs/current_status_summary.md
================================================
# Current Status Summary

## Issues Fixed

### 1. ✅ Chat API Error (HTML instead of JSON)
**Problem**: The `/api/chat` endpoint was missing from `backend/main.py`, causing the chat feature to return HTML error pages instead of JSON.

**Solution**: Added the complete `/api/chat` endpoint with Claude integration. The chat now:
- Returns proper JSON responses
- Integrates with Claude API
- Uses email insights context when available
- Handles errors gracefully

### 2. ✅ Flask App Syntax Error
**Problem**: The `backend/main.py` file had syntax errors and duplicate code.

**Solution**: 
- Fixed indentation issues
- Removed duplicate route definitions
- Restored proper file structure

### 3. ⚠️ Email Insights Not Showing
**Current Status**: The email sync appears to complete successfully, but insights aren't displaying.

**Debug Findings**:
- `sync_status` is empty (no email_insights stored)
- Session files exist and are recent
- EmailIntelligence module loads correctly
- All required methods are present

**Possible Causes**:
1. The sync process might be failing silently
2. Claude API might be rejecting requests due to token limits
3. Session data might not be persisting between requests

## Next Steps to Fix Insights

1. **Check Flask Logs**: Look at the terminal where Flask is running for any error messages during sync

2. **Manual Sync Test**: 
   - Login with Gmail OAuth
   - Go to Settings
   - Click "Sync Emails"
   - Watch the progress bar
   - Check Flask logs for errors

3. **Verify Claude API**: The token limit fix has been applied, limiting to 30 emails and truncating content

4. **Browser Console**: Check for JavaScript errors when viewing /email-insights

## How to Test

1. **Restart Flask**:
   ```bash
   pkill -f "python3 backend/main.py"
   python3 backend/main.py
   ```

2. **Login and Sync**:
   - Visit http://127.0.0.1:8080/login
   - Complete Gmail OAuth
   - Go to Settings
   - Click "Sync Emails"
   - Wait for completion
   - Visit Email Insights

3. **Test Chat**:
   - Visit http://127.0.0.1:8080/chat
   - Send a message
   - Should get AI response (not error)

## Architecture Notes

The app uses:
- Flask with session-based authentication
- Gmail OAuth for email access
- Claude API for AI analysis
- Background threads for email sync
- Global `sync_status` variable for progress tracking

The sync flow:
1. User clicks "Sync Emails"
2. Background thread starts
3. Fetches emails via Gmail API
4. Sends to Claude for analysis (limited to 30 emails)
5. Stores results in `sync_status`
6. User redirected to insights page
7. Insights copied from `sync_status` to session 


================================================
FILE: personal-ai-assistant/docs/gmail_integration_status.md
================================================
# Gmail Integration Status Report

## Issue Summary
The project was experiencing issues with Gmail email ingestion and insights generation, along with a syntax error in the main application file.

## Issues Resolved

### 1. Syntax Error in backend/main.py
**Problem**: The file had a corrupted structure with:
- An orphaned `except` block without matching `try`
- Duplicate route definitions
- Incorrect indentation

**Solution**: 
- Restored from backup and cleaned up duplicate code
- Fixed indentation issues
- Removed orphaned code blocks
- App now starts successfully

### 2. Gmail OAuth Token Management
**Current Implementation**:
- Basic `GmailConnector` only uses access token
- Tokens expire after 1 hour
- No automatic refresh mechanism

**Improved Solution Created**:
- Created `gmail_connector_improved.py` with:
  - Automatic token refresh
  - Better error messages
  - Detailed connection testing
  - Email statistics functionality

### 3. Error Handling
**Issues**:
- Silent failures when token expires
- Unclear error messages for users
- No guidance on fixing OAuth issues

**Solutions Provided**:
- Created troubleshooting guide
- Added debug scripts
- Improved error messages in the improved connector

## Current Status

### ✅ Working
- Flask application runs without errors
- OAuth flow properly configured with Gmail scopes
- Environment variables set correctly
- Basic Gmail integration structure in place
- Claude integration for insights generation

### ⚠️ Needs Implementation
1. **Token Refresh**: Update `email_intelligence.py` to use `ImprovedGmailConnector`
2. **Better Error UI**: Show user-friendly errors on the frontend
3. **Session Management**: Better handling of insights storage between threads
4. **Progress Tracking**: Real progress updates during email sync

## Recommended Next Steps

### 1. Implement Token Refresh (Priority: High)
```python
# In backend/core/claude_integration/email_intelligence.py
# Replace line 62:
from backend.integrations.gmail.gmail_connector_improved import ImprovedGmailConnector
gmail = ImprovedGmailConnector(session['google_oauth_token'])
```

### 2. Test the Full Flow
1. Clear Flask session: `rm -rf flask_session/*`
2. Start app: `python3 backend/main.py`
3. Login at http://127.0.0.1:8080/login
4. Sync emails from Settings
5. View insights

### 3. Monitor for Issues
- Check logs for token expiry errors
- Verify Gmail API is enabled in Google Cloud Console
- Ensure test users are added if app is in testing mode

## Debug Tools Created
1. **test_gmail_integration.py** - Tests all components
2. **debug_gmail_oauth.py** - Debugs OAuth token issues
3. **gmail_integration_troubleshooting.md** - Comprehensive guide
4. **gmail_connector_improved.py** - Better Gmail connector implementation

## Known Limitations
- OAuth tokens expire after 1 hour (need refresh implementation)
- Gmail API rate limits may affect large email volumes
- Claude API rate limits for insights generation
- Session data not shared between threads (needs Redis or database) 


================================================
FILE: personal-ai-assistant/docs/gmail_integration_troubleshooting.md
================================================
# Gmail Integration Troubleshooting Guide

## Overview
This guide helps resolve common issues with Gmail email ingestion and insights generation in the AI Chief of Staff application.

## Common Issues and Solutions

### 1. "OAuth token issue detected" Error

**Symptoms:**
- Error message: "OAuth token issue detected. The token may be expired or invalid."
- Unable to fetch emails after previously working

**Solutions:**
1. **Re-authenticate:**
   - Visit http://127.0.0.1:8080/logout
   - Visit http://127.0.0.1:8080/login
   - Complete the OAuth flow again
   - Ensure you see Gmail permissions in the consent screen

2. **Check token expiry:**
   - OAuth tokens expire after 1 hour
   - The app should auto-refresh, but if not working, re-login

### 2. "Gmail API access not properly configured" Error

**Symptoms:**
- Error during email sync
- Cannot connect to Gmail API

**Solutions:**
1. **Enable Gmail API in Google Cloud Console:**
   - Go to [Google Cloud Console](https://console.cloud.google.com)
   - Select your project
   - Go to "APIs & Services" > "Library"
   - Search for "Gmail API"
   - Click "Enable"

2. **Configure OAuth Consent Screen:**
   - In Google Cloud Console, go to "APIs & Services" > "OAuth consent screen"
   - Fill out all required fields
   - Add your email as a test user if app is in testing mode
   - Add the following scopes:
     - `openid`
     - `email`
     - `profile`
     - `https://www.googleapis.com/auth/gmail.readonly`

3. **Verify Redirect URIs:**
   - In "APIs & Services" > "Credentials"
   - Click on your OAuth 2.0 Client ID
   - Add these Authorized redirect URIs:
     - `http://127.0.0.1:8080/login/google/authorized`
     - `http://localhost:8080/login/google/authorized`

### 3. No Emails Found / Empty Insights

**Symptoms:**
- Sync completes but no emails are shown
- Insights page shows empty results

**Solutions:**
1. **Check email date range:**
   - Default is 30 days back
   - Change in Settings page if needed
   - Ensure your Gmail has emails in that timeframe

2. **Verify Gmail permissions:**
   - During login, ensure you granted Gmail read access
   - Check the consent screen shows Gmail permissions

3. **Check email fetching:**
   ```python
   # Run test_gmail_integration.py to verify basic connectivity
   python3 test_gmail_integration.py
   ```

### 4. Claude Integration Issues

**Symptoms:**
- Emails fetch successfully but no insights generated
- Error in insight generation

**Solutions:**
1. **Verify Claude API key:**
   ```bash
   # Check if ANTHROPIC_API_KEY is set
   echo $ANTHROPIC_API_KEY | wc -c
   # Should show > 100 characters
   ```

2. **Check Claude model availability:**
   - Current model: `claude-3-opus-20240229`
   - May need to update if model deprecated

3. **Rate limiting:**
   - Claude has rate limits
   - Wait a few minutes and try again

## Debugging Steps

### 1. Enable Debug Logging
```bash
export FLASK_ENV=development
export FLASK_DEBUG=1
python3 backend/main.py
```

### 2. Test Gmail Connection Manually
```python
# Create test_token.txt with your access token
# Then run:
python3 debug_gmail_oauth.py
```

### 3. Check Browser Console
- Open Developer Tools (F12)
- Check Console tab for JavaScript errors
- Check Network tab for failed API calls

### 4. Verify Environment Variables
```bash
# All should return values
echo $ANTHROPIC_API_KEY
echo $GOOGLE_CLIENT_ID
echo $GOOGLE_CLIENT_SECRET
```

### 5. Test with Fresh Session
```bash
# Clear Flask session
rm -rf flask_session/*

# Restart app
python3 backend/main.py

# Login fresh
```

## Code Fixes

### Issue: Token Not Refreshing
If tokens aren't auto-refreshing, use the improved Gmail connector:

```python
# Replace in backend/core/claude_integration/email_intelligence.py
from backend.integrations.gmail.gmail_connector_improved import ImprovedGmailConnector

# Update initialization to pass full token data
gmail = ImprovedGmailConnector(session['google_oauth_token'])
```

### Issue: Better Error Messages
The improved connector provides:
- Detailed error messages
- Success/failure status
- Email statistics
- Processing metadata

## Verification Tests

### 1. Basic Connectivity Test
```bash
python3 test_gmail_integration.py
```
Expected output:
- ✓ All environment variables set
- ✓ Claude client initialized
- ✓ GmailConnector imported
- ✓ EmailIntelligence initialized

### 2. OAuth Flow Test
```bash
python3 test_oauth.py
```
Should display OAuth URL with correct scopes

### 3. Full Integration Test
1. Start the app: `python3 backend/main.py`
2. Login at http://127.0.0.1:8080/login
3. Check Settings page shows "Gmail Connected"
4. Click "Sync Emails"
5. Check progress updates
6. View insights at Email Insights page

## Contact Support
If issues persist after trying these solutions:
1. Check logs in `backend/logs/` directory
2. Save error messages and timestamps
3. Note which step fails in the process
4. Check if issue is consistent or intermittent 


================================================
FILE: personal-ai-assistant/scripts/run.sh
================================================
#!/bin/bash
source venv/bin/activate
python backend/main.py



================================================
FILE: personal-ai-assistant/scripts/setup.sh
================================================
#!/bin/bash

echo "📦 Setting up virtual environment..."

# Create and activate virtual environment
python3 -m venv venv
source venv/bin/activate

# Upgrade pip and install dependencies
pip install --upgrade pip
pip install -r requirements.txt

# Create .env from example if it doesn't exist
if [ ! -f .env ]; then
    cp .env.example .env
    echo "📝 Created .env file - please edit with your API keys!"
fi

# Create user_data directory
mkdir -p user_data

echo "✅ Setup complete!"
echo ""
echo "Next steps:"
echo "1. Edit .env with your API keys"
echo "2. Run: source venv/bin/activate" 
echo "3. Run: python backend/main.py"



================================================
FILE: personal-ai-assistant/specs_and_more/all_milestones.txt
================================================
Chief of staff AI - milestones




Implementation Strategy

Phase 1 - Smart Data Router (4-6 weeks): Build the core prompt analysis engine that can understand intent and route to appropriate data sources. Start with basic email/calendar integration.

Phase 2 - Trigger System (3-4 weeks): Add the proactive monitoring with simple time-based triggers. Users can create their first saved searches.

Phase 3 - Learning Engine (6-8 weeks): Implement the pattern recognition that makes data fetching smarter over time based on user behavior.

Phase 4 - Advanced Intelligence (ongoing): Continuously add new data sources and improve the semantic understanding.

Immediate Validation Approach

Want to test this concept right now? You could:

1. Define Your First Triggers:
     - "Weekly investor follow-up review"
    - "Daily strategic priority optimization"
    - "Urgent email response alerts"

2. Test with Real Data:
     - Give me access to your email/calendar
    - I'll simulate these triggers manually
    - Show you exactly what insights would be generated

3. Refine the Prompts:
     - Iterate on what data points are most valuable
    - Optimize the trigger frequency and conditions
    - Define the action-oriented output format you prefer

This would let you validate the core value proposition and define the exact prompt templates before building anything. The beauty is that once you nail the prompt formulas that work for you, scaling to other users becomes a matter of helping them create their own personalized trigger sets.

Would you like to start with defining and testing a few key triggers for your specific business context?



================================================
FILE: personal-ai-assistant/specs_and_more/architecture_milestone_1.txt
================================================
AI Chief of staff - architecture milestone 1




personal-ai-assistant/
├── README.md # Project overview, Heroku deployment instructions
├── Procfile # Heroku process configuration
├── runtime.txt # Python version specification for Heroku
├── requirements.txt # Python dependencies
├── package.json # Node.js dependencies for frontend build
├── .env.example # Environment variables template
├── .gitignore # Git ignore patterns
├── app.json # Heroku app configuration for review apps
├── release-tasks.sh # Heroku release phase tasks (migrations, etc.)
│
├── backend/
│ ├── __init__.py
│ ├── main.py # FastAPI application entry point
│ ├── config/
│ │ ├── __init__.py
│ │ ├── settings.py # Heroku-optimized configuration
│ │ ├── database.py # PostgreSQL connection (Heroku Postgres)
│ │ └── redis_config.py # Redis connection (Heroku Redis)
│ │
│ ├── core/
│ │ ├── __init__.py
│ │ ├── prompt_intelligence/
│ │ │ ├── __init__.py
│ │ │ ├── intent_classifier.py # Lightweight NLP for prompt classification
│ │ │ ├── entity_extractor.py # Extract business entities from prompts
│ │ │ ├── context_mapper.py # Map prompts to Claude's available integrations
│ │ │ └── prompt_optimizer.py # Optimize prompts for Claude's capabilities
│ │ │
│ │ ├── claude_integration/
│ │ │ ├── __init__.py
│ │ │ ├── claude_client.py # Main Claude API client with all integrations
│ │ │ ├── workspace_handler.py # Leverage Claude's Google Workspace access
│ │ │ ├── email_intelligence.py # Email analysis via Claude's Gmail integration
│ │ │ ├── calendar_intelligence.py # Calendar analysis via Claude's integration
│ │ │ ├── prompt_builder.py # Build context-rich prompts for Claude
│ │ │ └── response_processor.py # Process and structure Claude's responses
│ │ │
│ │ ├── trigger_engine/
│ │ │ ├── __init__.py
│ │ │ ├── trigger_manager.py # Manage user-created triggers
│ │ │ ├── heroku_scheduler.py # Heroku Scheduler integration for triggers
│ │ │ ├── executor.py # Execute triggers via Claude
│ │ │ └── notification_service.py # Multi-channel notification delivery
│ │ │
│ │ └── data_orchestrator/
│ │ ├── __init__.py
│ │ ├── smart_fetcher.py # Orchestrate data requests to Claude
│ │ ├── context_builder.py # Build comprehensive context for Claude
│ │ ├── cache_manager.py # Redis-based intelligent caching
│ │ └── data_synthesizer.py # Combine Claude responses with external data
│ │
│ ├── integrations/
│ │ ├── __init__.py
│ │ ├── base_connector.py # Abstract base for non-Claude integrations
│ │ ├── clickup/
│ │ │ ├── __init__.py
│ │ │ ├── clickup_connector.py # ClickUp API integration
│ │ │ ├── task_analyzer.py # Task prioritization logic
│ │ │ └── data_formatter.py # Format ClickUp data for Claude context
│ │ │
│ │ ├── external_apis/
│ │ │ ├── __init__.py
│ │ │ ├── webhook_handler.py # Handle webhooks from external services
│ │ │ └── api_client.py # Generic external API client
│ │ │
│ │ └── claude_native/
│ │ ├── __init__.py
│ │ ├── 
│ │ ├── calendar_proxy.py # Proxy to Claude's Calendar integration
│ │ ├── drive_proxy.py # Proxy to Claude's Drive integration (if available)
│ │ └── integration_registry.py # Registry of all Claude's native integrations
│ │
│ ├── api/
│ │ ├── __init__.py
│ │ ├── routes/
│ │ │ ├── __init__.py
│ │ │ ├── triggers.py # Trigger CRUD operations
│ │ │ ├── insights.py # Retrieve insights and chat with Claude
│ │ │ ├── integrations.py # Manage external integrations
│ │ │ ├── auth.py # User authentication
│ │ │ ├── chat.py # Direct chat interface with Claude
│ │ │ └── health.py # Health checks for Heroku
│ │ │
│ │ ├── middleware/
│ │ │ ├── __init__.py
│ │ │ ├── auth_middleware.py # JWT token validation
│ │ │ ├── rate_limiter.py # API rate limiting
│ │ │ └── cors_middleware.py # CORS for frontend
│ │ │
│ │ └── dependencies.py # FastAPI dependencies
│ │
│ ├── models/
│ │ ├── __init__.py
│ │ ├── database/
│ │ │ ├── __init__.py
│ │ │ ├── user.py # User model
│ │ │ ├── trigger.py # Trigger configurations
│ │ │ ├── insight.py # Generated insights cache
│ │ │ ├── conversation.py # Chat history with Claude
│ │ │ ├── integration_config.py # External integration settings
│ │ │ └── base.py # SQLAlchemy base
│ │ │
│ │ ├── schemas/
│ │ │ ├── __init__.py
│ │ │ ├── trigger_schemas.py # Trigger API schemas
│ │ │ ├── insight_schemas.py # Insight response schemas
│ │ │ ├── chat_schemas.py # Chat interface schemas
│ │ │ └── user_schemas.py # User management schemas
│ │ │
│ │ └── enums.py # Application enums
│ │
│ ├── services/
│ │ ├── __init__.py
│ │ ├── user_service.py # User management logic
│ │ ├── trigger_service.py # Trigger business logic
│ │ ├── insight_service.py # Insight generation via Claude
│ │ ├── chat_service.py # Chat interface with Claude
│ │ ├── integration_service.py # External integration management
│ │ └── notification_service.py # Notification delivery
│ │
│ ├── utils/
│ │ ├── __init__.py
│ │ ├── logger.py # Heroku-optimized logging
│ │ ├── encryption.py # Data encryption utilities
│ │ ├── date_utils.py # Date/time utilities
│ │ ├── text_processing.py # Text processing helpers
│ │ ├── heroku_utils.py # Heroku-specific utilities
│ │ └── validators.py # Input validation
│ │
│ ├── tasks/
│ │ ├── __init__.py
│ │ ├── trigger_